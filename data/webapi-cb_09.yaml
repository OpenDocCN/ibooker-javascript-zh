- en: Chapter 9\. The Web Speech API
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第九章。Web Speech API
- en: Introduction
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: In the age of smart devices and assistants, your voice has become another commonly
    used input method. Whether you’re dictating a text message or asking for tomorrow’s
    weather forecast, speech recognition and synthesis are becoming useful tools in
    app development. With the Web Speech API, you can make your app speak or listen
    for a user’s voice input.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在智能设备和助手的时代，您的语音已成为另一种常用的输入方式。无论您是在口述短信还是询问明天的天气预报，语音识别和合成正在成为应用开发中有用的工具。使用
    Web Speech API，您可以让您的应用发出声音或监听用户的语音输入。
- en: Speech Recognition
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语音识别
- en: The Web Speech API brings speech *recognition* to the browser. Once the user
    gives you permission to use the microphone, it listens for speech. When it recognizes
    a series of words, it triggers an event with the recognized content.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Web Speech API 将语音*识别*带到浏览器中。一旦用户允许使用麦克风，它将监听语音。当它识别到一系列单词时，它将触发包含识别内容的事件。
- en: Note
  id: totrans-5
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Speech recognition may not be supported by all browsers yet. See [CanIUse](https://oreil.ly/SGLlc)
    for the latest compatibility data.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管不是所有浏览器都支持语音识别。查看[CanIUse](https://oreil.ly/SGLlc)获取最新的兼容性数据。
- en: You’ll need the user’s permission before you can start listening for speech.
    Due to privacy settings, the first time you attempt to listen, the user is prompted
    to grant your app permission to use the microphone (see [Figure 9-1](#microphonePermission)).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始监听语音之前，您需要用户的许可。由于隐私设置，第一次尝试监听时，用户将被提示授予您的应用使用麦克风的权限（参见[图 9-1](#microphonePermission)）。
- en: '![A microphone permission request in Chrome](assets/wacb_0901.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![在 Chrome 中的麦克风权限请求](assets/wacb_0901.png)'
- en: Figure 9-1\. A microphone permission request in Chrome
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-1。在 Chrome 中的麦克风权限请求
- en: Some browsers, such as Chrome, use an external server for analyzing the captured
    audio to recognize speech. This means speech recognition won’t work when you’re
    offline, and it might also raise privacy concerns.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 一些浏览器，如 Chrome，使用外部服务器分析捕获的音频以识别语音。这意味着在离线时语音识别将无法工作，并且可能引起隐私问题。
- en: Speech Synthesis
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语音合成
- en: The Web Speech API also provides speech *synthesis*. Given some text, it can
    create a synthesized voice that speaks the text. The browser has a set of built-in
    voices that it can use to speak your content. Once you have selected a voice appropriate
    for the target language, you can customize the voice’s pitch and speaking rate.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Web Speech API 还提供语音*合成*。给定一些文本，它可以创建一个合成的语音来朗读文本。浏览器有一组内置的语音可以用来朗读您的内容。一旦选择了适合目标语言的语音，您可以自定义语音的音调和说话速度。
- en: You can combine speech recognition and synthesis to create conversational voice
    user interfaces. They can listen for a question or command and speak the output
    or feedback.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以结合语音识别和语音合成来创建对话式语音用户界面。它们可以监听问题或命令，并朗读输出或反馈。
- en: Browser Support
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 浏览器支持
- en: At the time of writing, support for the Web Speech API is somewhat limited.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写时，对 Web Speech API 的支持有些有限。
- en: The specification for this API also adds a few other pieces that enhance speech
    recognition and synthesis once they are supported in browsers.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 API 的规范还添加了一些其他功能，一旦它们在浏览器中得到支持，将增强语音识别和合成的功能。
- en: The first of these is custom grammar, which lets you fine-tune speech recognition
    by specifying words and phrases that you want to recognize. For example, if you
    were designing a calculator with voice commands, your custom grammar would include
    digits (“one,” “two,” etc.) and calculator operations (“plus,” “minus,” etc.).
    Using a custom grammar helps guide the speech recognition engine to capture the
    words your application is looking for.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 其中之一是自定义语法，它允许您通过指定要识别的单词和短语来微调语音识别。例如，如果您设计了一个带有语音命令的计算器，您的自定义语法将包括数字（“one”，“two”
    等）和计算器操作（“plus”，“minus” 等）。使用自定义语法有助于引导语音识别引擎捕捉您的应用程序所需的单词。
- en: The SpeechSynthesis API supports Speech Synthesis Markup Language (SSML). SSML
    is an XML language that customizes speech synthesis. You can switch between male
    and female voices or specify that the browser should read something letter by
    letter. At the time of writing, SSML markup is parsed and understood—the engine
    won’t speak the markup tags—but browsers currently ignore most instructions.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: SpeechSynthesis API 支持语音合成标记语言（SSML）。SSML 是一种定制语音合成的 XML 语言。您可以在男性和女性之间切换语音，或指定浏览器按字母读取内容。在撰写时，SSML
    标记被解析和理解，但引擎不会朗读标记标签，但当前大多数浏览器会忽略大多数指令。
- en: Adding Dictation to a Text Field
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加到文本字段的口述
- en: Problem
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You want to recognize spoken text and add it to a text field’s content, allowing
    the user to dictate the text field’s contents.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 您希望识别口述文本并将其添加到文本字段的内容中，允许用户口述文本字段的内容。
- en: Solution
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Use the `SpeechRecognition` interface to listen for speech. When speech is recognized,
    extract the recognized text and append it to the text field (see [Example 9-1](#example9-1)).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`SpeechRecognition`接口来监听语音。当语音被识别时，提取识别的文本并追加到文本字段中（参见[示例 9-1](#example9-1)）。
- en: Example 9-1\. Adding basic dictation to a text field
  id: totrans-24
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-1\. 向文本字段添加基本口述
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Discussion
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: At the time of writing, in the WebKit browsers that support it, the `SpeechRecognition`
    constructor is prefixed as `webkitSpeechRecognition`. In unsupported browsers,
    neither `SpeechRecognition` nor `webkitSpeechRecognition` are defined, so it’s
    important to check the browser support before continuing.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，WebKit浏览器支持它，`SpeechRecognition`构造函数前缀为`webkitSpeechRecognition`。在不支持的浏览器中，`SpeechRecognition`和`webkitSpeechRecognition`都未定义，所以在继续之前检查浏览器支持是很重要的。
- en: To future-proof the code, the example checks for either the prefixed version
    (`webkitSpeechRecognition`) as well as the standard `SpeechRecognition` version.
    This way, you won’t have to change the code to accommodate browsers that implement
    the API in the future.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使代码具有未来的兼容性，示例检查了前缀版本（`webkitSpeechRecognition`）以及标准的`SpeechRecognition`版本。这样，您就不必更改代码以适应将来实现API的浏览器。
- en: Next, the `startDictation` function creates a `SpeechRecognition` object and
    sets its `continuous` flag to `true`. By default, no further recognition is performed
    once a result is recognized. Setting the `continuous` flag tells the speech recognition
    engine to continue listening and to deliver additional results.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，`startDictation`函数创建一个`SpeechRecognition`对象，并将其`continuous`标志设置为`true`。默认情况下，一旦识别到结果，不会执行进一步的识别。设置`continuous`标志告诉语音识别引擎继续监听并提供额外的结果。
- en: When the recognition engine recognizes some speech, it triggers a `result` event.
    This event has a `results` property that is an array-like object (actually a `SpeechRecognitionResultList`
    object) containing the results.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当识别引擎识别到一些语音时，会触发一个`result`事件。此事件有一个`results`属性，是一个类似数组的对象（实际上是一个`SpeechRecognitionResultList`对象），包含结果。
- en: When operating in continuous mode, as this example does, the `results` list
    contains all results that the recognition engine recognized. The first time the
    user speaks and some speech is recognized, this has a single result. When the
    user speaks again and the browser recognizes some more words, there are *two*
    results—the original result and the new one that was just recognized. If you set
    `continuous` to `false` (the default), the engine only recognizes one phrase,
    then no further `result` events are triggered.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当以连续模式运行时，像这个示例一样，`results`列表包含识别引擎识别到的所有结果。用户第一次讲话并识别到一些语音时，这有一个单一的结果。当用户再次讲话并且浏览器识别到更多单词时，会有*两个*结果——原始结果和刚刚识别到的新结果。如果将`continuous`设置为`false`（默认），则引擎只识别一个短语，然后不再触发进一步的`result`事件。
- en: Helpfully, the event also has a `resultIndex` property that points to the index
    within the list of the new result that triggered this event.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 有用的是，事件还有一个`resultIndex`属性，指向触发此事件的新结果列表中的索引。
- en: The result object is another array-like object (a `SpeechRecognitionAlternative`
    object). When you create a `SpeechRecognition` object, you can give it the property
    `maxAlternatives`. The browser presents a list of possible matches for the recognized
    speech, each with a confidence value. However, the default `maxAlternatives` value
    is 1, so this dictation code only ever has one `SpeechRecognitionAlternative`
    object in the list.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 结果对象是另一个类似数组的对象（`SpeechRecognitionAlternative`对象）。当创建`SpeechRecognition`对象时，可以给它设置`maxAlternatives`属性。浏览器会呈现一系列可能的匹配识别语音的选项，每个都带有置信度值。然而，默认的`maxAlternatives`值为1，因此这段口述代码只有一个`SpeechRecognitionAlternative`对象在列表中。
- en: Finally, this object has a `transcript` property that is the actual phrase that
    the engine recognized. You can take this value and append it to the text field’s
    current value.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，此对象有一个`transcript`属性，即引擎识别的实际短语。您可以获取此值并将其追加到文本字段的当前值中。
- en: Calling `start` on the recognition object begins listening for speech, emitting
    events when it hears something. The `startDictation` function then returns the
    recognition object, so that you can stop recognition once the user is finished
    dictating.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 调用识别对象上的`start`方法开始侦听语音，当听到声音时触发事件。然后`startDictation`函数返回识别对象，以便您在用户完成口述后停止识别。
- en: 'Like with any API, it’s also important to handle any errors that occur. With
    speech recognition, some common errors you might face are:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 与任何API一样，处理任何可能发生的错误也很重要。在语音识别中，您可能面临的一些常见错误包括：
- en: Permission error
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 权限错误
- en: If the user did not grant permission to use the microphone. The event has an
    `error` property of `not-allowed`.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果用户未授权使用麦克风。事件的`error`属性为`not-allowed`。
- en: Network error
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 网络错误
- en: If the browser couldn’t reach the speech recognition service. This has an `error`
    of `network`.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果浏览器无法访问语音识别服务。此错误为`network`。
- en: Hardware error
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 硬件错误
- en: If the browser was unable to access the microphone. This has an error code of
    `audio-capture`.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果浏览器无法访问麦克风。此错误代码为`audio-capture`。
- en: Creating a Promise Helper for Speech Recognition
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建语音识别的Promise辅助工具
- en: Problem
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You want to encapsulate speech recognition into a single function call.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 您希望将语音识别封装成单个函数调用。
- en: Solution
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Wrap the speech recognition call in a new `Promise` inside a helper function.
    Within the helper function, create a new `SpeechRecognition` object and listen
    for speech. You can resolve the `Promise` when the browser recognizes some speech
    (see [Example 9-2](#code_promiseHelper)).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在辅助函数内部的新`Promise`中包装语音识别调用。在辅助函数内部，创建一个新的`SpeechRecognition`对象并侦听语音。当浏览器识别到一些语音时，您可以解析`Promise`（参见[示例 9-2](#code_promiseHelper)）。
- en: Example 9-2\. A `Promise` helper for speech recognition
  id: totrans-48
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-2\. 用于语音识别的`Promise`辅助工具
- en: '[PRE1]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Discussion
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: The `captureSpeech` helper does not use `continuous` mode. This means you can
    only use it to listen for a single speech recognition event. If you want to capture
    additional speech after the returned `Promise` resolves, you need to call `captureSpeech`
    again and wait on the new `Promise`.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '`captureSpeech`辅助工具不使用`continuous`模式。这意味着您只能使用它来监听单个语音识别事件。如果希望在返回的`Promise`解析后捕获额外的语音，请再次调用`captureSpeech`并等待新的`Promise`。'
- en: You might notice that [Example 9-2](#code_promiseHelper) doesn’t return the
    `Promise` directly. Instead, it calls `finally` on that `Promise` to stop the
    speech recognition engine regardless of the outcome. The `captureSpeech` function
    lets you quickly recognize speech by just waiting on a `Promise` (see [Example 9-3](#example9-3)).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能注意到，[示例 9-2](#code_promiseHelper)没有直接返回`Promise`。相反，它在该`Promise`上调用`finally`来停止语音识别引擎，无论结果如何。`captureSpeech`函数让您只需等待一个`Promise`就可以快速识别语音（参见[示例 9-3](#example9-3)）。
- en: Example 9-3\. Using the `captureSpeech` helper
  id: totrans-53
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-3\. 使用`captureSpeech`辅助工具
- en: '[PRE2]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Getting the Available Voices
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取可用语音
- en: Problem
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You want to determine what speech synthesis voices are available in the current
    browser.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 您想确定当前浏览器中可用的语音合成语音。
- en: Solution
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Query the voice list by calling `speechSynthesis.getVoices`, and then listen
    for the `voiceschanged` event if necessary, as shown in [Example 9-4](#code_getVoices).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 通过调用`speechSynthesis.getVoices`查询语音列表，然后根据需要侦听`voiceschanged`事件，如[示例 9-4](#code_getVoices)所示。
- en: Example 9-4\. Getting the list of available speech synthesis voices
  id: totrans-60
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-4\. 获取可用语音合成语音列表
- en: '[PRE3]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Discussion
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: Some browsers, such as Chrome, load the list of voices asynchronously. If you
    call `getVoices` before the list is ready, you’ll get an empty array back. The
    `speech` `Synthesis` object triggers a `voiceschanged` event when the list is
    ready.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 某些浏览器（如Chrome）异步加载语音列表。如果在列表准备好之前调用`getVoices`，您将得到一个空数组。`speech` `Synthesis`对象在列表准备好时会触发`voiceschanged`事件。
- en: Other browsers, including Firefox, have the voice list available right away.
    In these browsers, the `voiceschanged` event never fires. The code in [Example 9-4](#code_getVoices)
    handles both cases.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 其他浏览器，包括Firefox，立即提供语音列表。在这些浏览器中，`voiceschanged`事件从未触发。[示例 9-4](#code_getVoices)中的代码处理了这两种情况。
- en: Note
  id: totrans-65
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Each voice has a `lang` property that specifies the voice’s language. When speaking
    text, the voice uses the pronunciation rules for its language. Make sure you use
    a voice with the correct language for the text you’re synthesizing. Otherwise,
    the pronunciation won’t sound right.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 每个语音都有一个`lang`属性，指定语音的语言。在朗读文本时，语音使用其语言的发音规则。确保使用与合成文本语言相匹配的语音。否则，发音将不正确。
- en: Synthesizing Speech
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 合成语音
- en: Problem
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You want your app to speak some text to the user.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 您希望您的应用向用户朗读一些文本。
- en: Solution
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Create a `SpeechSynthesisUtterance` and pass it to the `speechSynthesis.speak`
    method (see [Example 9-5](#example9-5)).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个`SpeechSynthesisUtterance`并将其传递给`speechSynthesis.speak`方法（参见[示例 9-5](#example9-5)）。
- en: Example 9-5\. Speaking some text with the Web Speech API
  id: totrans-72
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-5\. 使用 Web Speech API 朗读一些文本
- en: '[PRE4]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Discussion
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: An utterance is the set of words you want the browser to speak. It’s created
    with a `SpeechSynthesisUtterance` object.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 话语是您希望浏览器朗读的一组单词。它使用`SpeechSynthesisUtterance`对象创建。
- en: Note
  id: totrans-76
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Browsers will only permit speech synthesis once the user has interacted with
    the page in some way. This is to stop a page from speaking immediately upon loading.
    As such, the `speakText` helper function will not speak anything until there is
    some user activity on the page.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 浏览器只会在用户与页面进行交互后才允许语音合成。这是为了防止页面加载时立即开始朗读。因此，`speakText`辅助函数在页面上有用户活动之前不会发出任何声音。
- en: This speaks the text with the default voice. If you want to use a different
    supported system voice, you can use the technique from [“Getting the Available
    Voices”](#recipe_getVoices) to get the array of available voices. You can set
    the utterance’s `voice` property to one of the voice objects from this array,
    as shown in [Example 9-6](#example9-6).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 使用默认语音朗读文本。如果要使用不同的支持系统语音，可以使用[“获取可用语音”](#recipe_getVoices)中的技术获取可用语音数组。您可以将话语的`voice`属性设置为该数组中的一个语音对象，如[示例 9-6](#example9-6)所示。
- en: Example 9-6\. Using another voice
  id: totrans-79
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-6\. 使用另一个语音
- en: '[PRE5]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Customizing Speech Synthesis Parameters
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自定义语音合成参数
- en: Problem
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You want to speed up, slow down, or adjust the pitch of the spoken text.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 您希望加快、减慢或调整朗读文本的音调。
- en: Solution
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: When creating a `SpeechSynthesisUtterance`, use the `rate` and `pitch` properties
    to customize the speaking voice (see [Example 9-7](#example9-7)).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 创建`SpeechSynthesisUtterance`时，请使用`rate`和`pitch`属性来自定义朗读语音（参见[示例 9-7](#example9-7)）。
- en: Example 9-7\. Customizing speech output
  id: totrans-86
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-7\. 自定义语音输出
- en: '[PRE6]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Discussion
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: The `pitch` option is a float number that can have a value between 0 and 2\.
    Lower values result in a lower pitch, and higher values result in a higher pitch.
    Lowering the pitch does not affect the speaking rate. Depending on the browser
    or voice being used, the range of supported pitch values may be limited.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '`pitch`选项是一个浮点数，其值可以在0到2之间。较低的值会导致较低的音调，较高的值会导致较高的音调。降低音调不会影响说话速率。根据使用的浏览器或语音，支持的音调值范围可能会受到限制。'
- en: To speed up or slow down the speaking rate, you can adjust the `rate` property.
    Each voice has a default speaking rate, which is represented by a `rate` of 1\.
    The value of `rate` has a multiplier effect. If you set `rate` to 0.5, it is half
    of the default speaking rate. Similarly, if you set `rate` to 1.5, it is 50% faster
    than the default rate. The specification defines the valid range as 0.1 to 10,
    but browsers and voices typically limit this to a smaller range.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 要加快或减慢语音的速率，您可以调整`rate`属性。每个语音都有一个默认的朗读速率，用`rate`值表示为1。`rate`的值具有乘法效应。如果将`rate`设置为0.5，则为默认朗读速率的一半。类似地，如果将`rate`设置为1.5，则比默认速率快50%。规范定义了有效范围为0.1到10，但浏览器和语音通常将其限制在较小的范围内。
- en: Automatically Pausing Speech
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动暂停语音
- en: Problem
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: When your app is speaking, you want to pause speech when you switch to another
    tab so that it doesn’t interfere with the usage of the other tab. You also want
    to stop speaking when leaving the page.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 当您的应用正在朗读时，您希望在切换到另一个标签时暂停语音，以免干扰其他标签的使用。同时，当离开页面时也希望停止朗读。
- en: Solution
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Listen for the `visibilitychange` event and check the `document.visibilityState`
    property. When the page becomes hidden, pause speech synthesis. When it becomes
    visible again, resume speaking (see [Example 9-8](#code_pauseSpeech)).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 监听`visibilitychange`事件并检查`document.visibilityState`属性。当页面变为隐藏状态时，暂停语音合成。当再次变为可见状态时，恢复朗读（参见[示例 9-8](#code_pauseSpeech)）。
- en: Example 9-8\. Pausing speech when the page becomes hidden
  id: totrans-96
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-8\. 当页面变为隐藏状态时暂停语音
- en: '[PRE7]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Discussion
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: By default, if you switch to another tab while the Web Speech API is speaking
    some text, it continues speaking. This might be what you expect—after all, the
    same thing happens if you are streaming audio or video then change to another
    tab; you’ll continue to hear the audio from the other tab.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，如果在 Web 语音 API 正在播放某些文本时切换到另一个标签页，它会继续播放。这可能是您预期的行为 — 毕竟，如果您正在播放音频或视频然后切换到另一个标签页，您会继续听到来自其他标签页的音频。
- en: When you switch tabs, the `visibilitychange` event fires. The event itself doesn’t
    have any information about the visibility state, but you can get that by checking
    the `document.visibilityState` property. [Example 9-8](#code_pauseSpeech) pauses
    the speech when you switch to another tab. When you switch back, it continues
    where it left off.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 当您切换标签页时，会触发`visibilitychange`事件。事件本身并不提供任何关于可见状态的信息，但您可以通过检查`document.visibilityState`属性来获取。[示例 9-8](#code_pauseSpeech)在您切换到另一个标签页时暂停语音播放。当您切换回来时，它会继续之前的播放位置。
- en: Some browsers keep playing the speech even when you navigate away from the page
    or perform a full page refresh. Leaving or refreshing the page also triggers the
    `visibilitychange` event, so the code in [Example 9-8](#code_pauseSpeech) correctly
    stops the speech in these cases as well.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 有些浏览器即使在您离开页面或执行完整页面刷新时也会继续播放语音。离开或刷新页面也会触发`visibilitychange`事件，因此在[示例 9-8](#code_pauseSpeech)中的代码也能正确停止这些情况下的语音播放。
