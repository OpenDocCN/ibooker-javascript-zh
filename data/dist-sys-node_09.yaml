- en: Chapter 8\. Resilience
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章\. 弹性
- en: This chapter focuses on *application resilience*, which is the ability to survive
    situations that might otherwise lead to failure. Unlike other chapters that focused
    on services external to the Node.js process, this one mostly looks within the
    process.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章重点讨论*应用程序的弹性*，即在可能导致失败的情况下仍能维持正常运行的能力。与专注于Node.js进程外部服务的其他章节不同，这一章大多数情况下着眼于进程内部。
- en: Applications should be resilient to certain types of failure. For example, there
    are many options available to a downstream service like *web-api* when it is unable
    to communicate with an upstream service like *recipe-api*. Perhaps it should retry
    the outgoing request, or maybe it should respond to the incoming request with
    an error. But in any case, crashing isn’t the best option. Similarly, if a connection
    to a stateful database is lost, the application should probably try to reconnect
    to it, while replying to incoming requests with an error. On the other hand, if
    a connection to a caching service is dropped, then the best action might be to
    reply to the client as usual, albeit in a slower, “degraded” manner.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序应对某些类型的故障具备弹性。例如，像*web-api*这样的下游服务在无法与*recipe-api*这样的上游服务通信时，有许多可用的选项。也许它应该重试传出请求，或者可能应该用错误响应来回应传入请求。但无论如何，崩溃都不是最佳选择。同样，如果与有状态数据库的连接丢失，应用程序可能应该尝试重新连接，同时用错误响应来回应传入请求。另一方面，如果与缓存服务的连接断开，则最佳操作可能是像往常一样回应客户端，尽管速度较慢，以“降级”的方式。
- en: In many cases it is necessary for an application to crash. If a failure occurs
    that an engineer doesn’t anticipate—often global to the process and not associated
    with a single request—then the application can potentially enter a compromised
    state. In these situations it’s best to log the stack trace, leaving evidence
    behind for an engineer, and then exit. Due to the ephemeral nature of applications,
    it’s important that they remain stateless—doing so allows future instances to
    pick up where the last one left off.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，应用程序崩溃是必要的。如果发生了工程师没有预料到的故障——通常是全局性的进程问题，而不是与单个请求相关的——那么应用程序可能会进入受损状态。在这些情况下，最好记录堆栈跟踪，留下工程师的证据，然后退出。由于应用程序的短暂性质，它们保持无状态非常重要——这样做允许将来的实例从上次停下的地方继续进行。
- en: Speaking of crashing, there are a number of ways that an application can exit,
    intentionally or otherwise. It’s worth looking at these before diving into the
    ways the application can be kept alive and healthy.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 谈到崩溃，应用程序可以有多种方式退出，无论是有意还是无意。在深入探讨应用程序如何保持存活和健康之前，了解这些方式是值得的。
- en: The Death of a Node.js Process
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Node.js 进程的死亡
- en: There are many ways that a Node.js process can be terminated, and unfortunately,
    Node.js is sometimes helpless to prevent some of them. For example, a native module
    running compiled C++ code could cause a segfault, the process could receive the
    *SIGKILL* signal, or someone could trip over the server’s power cord. It’s important
    to build systems that are resilient to such problems. However, as for the Node.js
    process itself, it can’t do much about its own termination in such situations.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Node.js 进程可以被终止的方式有很多种，不幸的是，有时Node.js对一些情况无能为力。例如，运行编译的C++代码的本地模块可能会导致段错误，进程可能会收到*SIGKILL*信号，或者有人可能会绊倒服务器的电源线。建立能够抵御此类问题的系统至关重要。然而，对于Node.js进程本身，在这些情况下它无法做太多事情以防止自身的终止。
- en: The `process` global is an `EventEmitter` instance, and when the process exits
    it will usually emit an `exit` event. This event can be listened for to perform
    final cleanup and logging work. Only synchronous work can be executed when this
    event is triggered. The event won’t always be called when a process terminates,
    like in a catastrophic event such as running out of memory.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 全局变量 `process` 是一个 `EventEmitter` 实例，当进程退出时通常会触发 `exit` 事件。可以监听此事件以执行最终的清理和日志记录工作。当触发此事件时只能执行同步工作。在像内存耗尽这样的灾难性事件中，进程终止时不一定会调用此事件。
- en: When it comes to intentionally terminating a process from within (or preventing
    termination), there are a few options available. [Table 8-1](#table_process_exits)
    contains a list of some of these situations.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到从内部有意终止进程（或阻止终止）时，有几种可用的选项。[表格 8-1](#table_process_exits) 包含了一些这些情况的列表。
- en: Table 8-1\. Node.js termination from within
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 8-1\. Node.js 内部终止
- en: '| Operation | Example |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| 操作 | 示例 |'
- en: '| --- | --- |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Manual process exit | `process.exit(1)` |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| 手动进程退出 | `process.exit(1)` |'
- en: '| Uncaught exception | `throw new Error()` |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| 未捕获的异常 | `throw new Error()` |'
- en: '| Unhandled promise rejection^([a](ch08.html#idm46291180529912)) | `Promise.reject()`
    |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| 未处理的承诺拒绝^([a](ch08.html#idm46291180529912)) | `Promise.reject()` |'
- en: '| Ignored error event | `EventEmitter#emit(''error'')` |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| 忽略错误事件 | `EventEmitter#emit(''error'')` |'
- en: '| Unhandled signals | `$ kill <PROCESS_ID>` without a signal handler |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 未处理的信号 | `$ kill <PROCESS_ID>` 没有信号处理程序 |'
- en: '| ^([a](ch08.html#idm46291180529912-marker)) As of Node.js v14.8, the `--unhandled-rejections=strict`
    flag must be provided for this to crash a process. Future versions of Node.js
    will crash by default. |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| ^([a](ch08.html#idm46291180529912-marker)) 从 Node.js v14.8 开始，必须提供 `--unhandled-rejections=strict`
    标志才能使进程崩溃。未来版本的 Node.js 将默认崩溃。 |'
- en: Most of the entries in this list deal directly with failure scenarios, such
    as uncaught exceptions, unhandled rejections, and error events. Signals received
    from external processes are another interesting situation. However, only one of
    these has to do with cleanly and intentionally exiting the process.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 此列表中的大多数条目直接处理失败场景，例如未捕获的异常、未处理的拒绝和错误事件。来自外部进程的信号接收是另一种有趣的情况。但是，这些情况中只有一个与干净且有意退出进程有关。
- en: Process Exit
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进程退出
- en: The `process.exit(code)` method is the most basic mechanism for terminating
    a process and is useful in many scenarios where an error isn’t necessarily involved.
    For example, when building a CLI utility, the `process.exit()` may be relied on
    to terminate a process once it has completed its given task. It’s almost like
    an overpowered `return` statement.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '`process.exit(code)` 方法是终止进程的最基本机制，在许多场景中非常有用，即使没有错误。例如，在构建 CLI 实用程序时，可能会依赖
    `process.exit()` 来在完成给定任务后终止进程。这几乎像是一个功能强大的 `return` 语句。'
- en: The `code` argument^([1](ch08.html#idm46291180517368)) is a numeric *exit status
    code* within the range of 0 and 255\. By convention, a 0 means that the application
    terminated in a healthy manner, and any nonzero number means that an error occurred.
    There isn’t necessarily a standard for defining what the different nonzero exit
    values represent (as opposed to HTTP, which has well-defined numeric status codes).
    Instead, it’s usually up to the application to document what the different exit
    status codes mean. For example, if an application requires a set of environment
    variables that happen to be missing, it might exit with a 1, and if expects to
    find a configuration file that is missing, it might exit with a 2.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '`code` 参数^([1](ch08.html#idm46291180517368)) 是在 0 和 255 范围内的数值 *退出状态码*。按照惯例，0
    表示应用程序以健康的方式终止，任何非零数字表示发生了错误。不像 HTTP 有定义良好的数值状态码，没有必要为不同的非零退出值定义标准（相对于 HTTP 而言）。相反，通常由应用程序来记录不同的退出状态码的含义。例如，如果应用程序需要一组环境变量，而这些环境变量恰好缺失，则可能会退出并返回
    1；如果期望找到缺失的配置文件，则可能退出并返回 2。'
- en: 'No messages are printed to stdout or *stderr* by default when `process.exit()`
    is called. Instead, the process just ends. For that reason, you may want to emit
    a final message before the program ends so that someone running the application
    has an idea of what went wrong. As an example of this, run the following code:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 当调用 `process.exit()` 时，默认情况下不会打印任何消息到 stdout 或 *stderr*。相反，进程只是结束。因此，您可能希望在程序结束之前发出最后一条消息，以便运行应用程序的人了解出了什么问题。例如，运行以下代码：
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In this case, you should only see the number 42 printed. The number is printed
    for you by your shell, but the Node.js process doesn’t print anything. But what
    went wrong? A quick look at the logs won’t provide any help.^([2](ch08.html#idm46291180506840))
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，您应该只会看到打印的数字 42。这个数字是由您的 shell 打印的，但是 Node.js 进程不会打印任何内容。但是出了什么问题呢？快速查看日志不会提供任何帮助。^([2](ch08.html#idm46291180506840))
- en: 'Here is an example of a more verbose approach that an application might employ
    if it needs to exit at startup when misconfigured:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个应用程序可能采用的更详细的方法的示例，如果在配置错误时需要在启动时退出：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In this case, the application prints a message to *stderr*, which makes the
    life of whoever is running the process easier. The process then exits with a status
    code of 1, which is useful for conveying to a machine that the process has failed.
    When `process.exit()` is encountered, none of the code that follows it will run.
    It effectively terminates the current stack much like a `return` statement would
    (in fact, your IDE may highlight code following this line as dead-code).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，应用程序向 *stderr* 打印一条消息，这使得运行进程的人的生活更轻松。然后，进程以状态码 1 退出，这对于向机器传达进程失败的情况非常有用。当遇到
    `process.exit()` 时，其后的所有代码都不会运行。它有效地终止了当前的堆栈，就像 `return` 语句一样（实际上，您的 IDE 可能会将此行后面的代码标记为死代码）。
- en: Tip
  id: totrans-28
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: The `process.exit()` method is very powerful. While it does have its purpose
    within Node.js application code, an npm package should almost never make use of
    it. Consumers of libraries expect to be able to handle errors in their own way.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '`process.exit()` 方法非常强大。虽然它在 Node.js 应用程序代码中有其用途，但几乎不应该在 npm 包中使用。库的使用者期望能够以自己的方式处理错误。'
- en: 'Status codes are used in a lot of situations. For example, when unit tests
    run as part of continuous integration, a nonzero exit status informs the test
    runner (such as Travis CI) that the test suite has failed. Of course, it would
    be tedious to have to manually go through and add `process.exit(1)` calls all
    over a test suite. Thankfully, test suite runners handle that for you. In fact,
    any time an application throws an error that doesn’t get caught, it will default
    to producing an exit status of 1\. The following example shows this happening:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 状态码在许多情况下都被使用。例如，在持续集成的单元测试运行时，非零的退出状态通知测试运行器（如 Travis CI）测试套件已失败。当然，手动在整个测试套件中添加
    `process.exit(1)` 调用会很麻烦。幸运的是，测试套件运行器会为您处理这一切。事实上，任何时候应用程序抛出未被捕获的错误时，默认会产生退出状态
    1。以下示例展示了这种情况：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In this case, you should see a stack trace printed, followed by the number 1
    on a line of its own. Thrown errors warrant a bit more discussion.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，您应该看到打印的堆栈跟踪，然后在其自己的行上看到数字 1。抛出的错误需要更多讨论。
- en: Exceptions, Rejections, and Emitted Errors
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 异常、拒绝和已发出的错误
- en: Using `process.exit()` is nice for early startup errors, but sometimes you need
    something more contextual. For example, when a runtime error happens in the middle
    of an application’s lifetime, like during a request handler, something bad happening
    probably isn’t a foreseeable error like missing configuration. Instead, it’s likely
    due to some untested logic branch or an otherwise weird edge case. When this happens,
    the application owner needs to know where the problem happened. That is where
    the `Error` object comes in.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 对于早期启动错误，使用 `process.exit()` 是很好的，但有时您需要更多上下文信息。例如，在应用程序生命周期中间发生运行时错误，比如在请求处理程序中，发生的问题可能不是可预见的错误，比如缺少配置。相反，它可能是由于某些未经测试的逻辑分支或其他怪异边缘情况。当这种情况发生时，应用程序所有者需要知道问题发生的位置。这就是
    `Error` 对象发挥作用的地方。
- en: 'Before discussing errors too much, it’s useful to define a few terms—especially
    since they’re often conflated:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论错误之前，定义一些术语是有用的，特别是因为它们经常被混淆：
- en: Error
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 错误
- en: '`Error` is a global object available in all JavaScript environments. When an
    `Error` is instantiated it has some metadata attached to it, such as the name
    of the error, a message, and a stack trace string. This metadata is provided as
    properties on the resulting object. Merely instantiating an `Error` isn’t that
    big of a deal (though there’s some performance impact when it comes to generating
    the stack trace) and doesn’t yet affect control flow—that happens later when it
    is thrown. It’s common to “subclass” an error by extending from it and creating
    more specific errors.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '`Error` 是在所有 JavaScript 环境中可用的全局对象。当实例化 `Error` 时，会附加一些元数据，如错误的名称、消息和堆栈跟踪字符串。这些元数据作为结果对象的属性提供。仅仅实例化
    `Error` 并不是件大事（虽然在生成堆栈跟踪时会有一些性能影响），并且尚未影响控制流程—这是稍后抛出时发生的事情。通常通过扩展 `Error` 来“子类化”错误，从而创建更具体的错误类型。'
- en: Throw
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 抛出
- en: The `throw` keyword creates and throws an exception. When one of these is encountered,
    the current function will stop being executed. The exception is then “bubbled
    up” through the functions that called your function. When this happens, JavaScript
    looks for any try/catch statements that have wrapped any of the shallower function
    calls. If one is encountered, the `catch` branch is called. If none are encountered,
    the exception is then considered uncaught.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`throw` 关键字创建并抛出一个异常。当遇到其中之一时，当前函数将停止执行。异常然后通过调用你的函数的函数“冒泡”上升。这时候，JavaScript
    会寻找包裹了浅层函数调用的任何 try/catch 语句。如果找到了一个，那么 `catch` 分支就会被调用。如果没有找到，那么该异常就被认为是未捕获的。'
- en: Exception
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 异常
- en: An `Exception` is something that has been thrown. Technically you can throw
    anything, even a string or `undefined`. That said it’s considered bad form to
    throw anything that isn’t an instance of, or extended from, the `Error` class.
    This also applies when it comes to rejecting promises, providing error arguments
    to callbacks, or emitting errors.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`Exception` 是被抛出的一种东西。技术上你可以抛出任何东西，甚至是一个字符串或者 `undefined`。尽管如此，抛出任何不是 `Error`
    类的实例或者其子类的东西通常被认为是不合适的。这也适用于拒绝 promises、提供错误参数给回调函数或者发出错误时。'
- en: Rejection
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 拒绝
- en: A Rejection is what happens when a promise fails or when an exception is thrown
    within an `async` function. The concept is similar in nature to an exception,
    but it does need to be handled in slightly different ways, so it deserves a name
    of its own.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 当 promise 失败或在 `async` 函数内抛出异常时，会发生拒绝。这个概念在本质上与异常相似，但需要以稍微不同的方式处理，因此它值得有自己的名称。
- en: Error swallowing
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 错误吞噬
- en: Capturing an error and completely disregarding the outcome, including not logging
    the error to the console, is considered “swallowing an error.”
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 捕获错误并完全忽视其结果，包括不将错误记录到控制台，被认为是“吞噬错误”。
- en: When an exception is thrown or a promise is rejected, it needs to be handled
    in some manner. When completely ignored it leads to an application crash—for example,
    an uncaught error will crash a Node.js process. Swallowing errors is universally
    a bad practice and will come back to bite you. However, checking if a specific
    anticipated error is thrown before swallowing it isn’t necessarily the end of
    the world.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 当抛出异常或拒绝 promise 时，需要以某种方式处理它们。如果完全忽略它们，将导致应用程序崩溃——例如，未捕获的错误将使 Node.js 进程崩溃。吞噬错误是普遍被认为是一种不良实践，并将会给你带来麻烦。然而，在吞噬之前检查是否抛出了特定预期的错误，并不一定是世界末日。
- en: 'Consider the following example of a swallowed error:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑下面的吞噬错误的示例：
- en: '[PRE3]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In this case, the *some-library* author has decided to throw an innocuous error,
    one that doesn’t actually affect the operation of the library. Perhaps it throws
    an error when the first database host it tries to connect to cannot be reached,
    even though the second host that it can connect to is reached. In this case, the
    catch branch is swallowing that connection fallback error. Unfortunately, it’s
    also throwing any other error that the `lib.start()` method might be throwing.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，*some-library* 的作者决定抛出一个无害的错误，即使这个错误实际上并不影响库的操作。也许它在尝试连接的第一个数据库主机无法访问时抛出错误，尽管它可以连接到第二个主机。在这种情况下，catch
    分支就吞噬了连接回退错误。不幸的是，它也抛出了 `lib.start()` 方法可能抛出的任何其他错误。
- en: For example, you might find that when the *some-library* gets upgraded, it begins
    throwing another error, one that is a big deal. This usually leads to hours of
    debugging before finally finding the source of the underlying issue. For this
    reason, swallowing all errors is bad.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你可能会发现当 *some-library* 升级后，它开始抛出另一个错误，一个很大的问题。通常这会导致数小时的调试，最终找到潜在问题的源头。因此，吞噬所有错误是不好的。
- en: 'To swallow only a specific error, you might instead change the code to look
    like this:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 要只吞噬特定的错误，你可以改变代码，使其看起来像这样：
- en: '[PRE4]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In this case, the exception is only swallowed if it is a specific error instance,
    otherwise it is rethrown again. This particular example assumes that a library
    author was thoughtful enough to export subclassed error instances. Unfortunately
    this often isn’t the case (not to mention `instanceof` checks can be tricky with
    a complex npm package hierarchy). Sometimes a library author might subclass errors
    but not export them. In those cases, you can check the `.name` field, for example
    by using `e.name === 'ConnectionFallback'`.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，异常仅在它是特定错误实例时被吞噬，否则会再次抛出。这个特定的例子假设库作者足够 thoughtful 以导出子类化的错误实例。不幸的是，这种情况经常不是这样（更不用说`instanceof`检查在复杂的npm包层次结构中可能会很棘手）。有时库作者可能会子类化错误但不导出它们。在这些情况下，您可以检查`.name`字段，例如使用`e.name
    === 'ConnectionFallback'`。
- en: Another convention—popularized by Node.js itself—for differentiating errors
    works by providing a `.code` property, which is a string named in a documented
    and consistent manner and that shouldn’t change between releases. An example of
    this is the *ERR_INVALID_URI* error code, and even though the human-readable message
    of the string may change, the error code should not. This pattern unfortunately
    isn’t that popular yet amongst package authors either, though when a package surfaces
    a Node.js-produced error, the `.code` property should be present.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种约定——由Node.js本身推广用于区分错误的方法是提供一个`.code`属性，这是一个以文档化和一致方式命名的字符串，不应在发布之间更改。这种模式在包作者中并不那么流行，尽管当一个包暴露了一个Node.js产生的错误时，`.code`属性应该是存在的。
- en: The most common approach for targeting specific errors is to parse the actual
    `.message` field. When doing this, your application will need to inspect text
    meant for human consumption—for example, using `e.message.startsWith('Had to fallback')`.
    This is unfortunately quite error prone! Error messages often have typos, and
    well-meaning contributors make PRs to fix them all the time. Such updates are
    usually released as a Semver patch release and may then break an application that
    inspects the error message string.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 针对特定错误的最常见方法是解析实际的`.message`字段。这样做时，您的应用程序将需要检查人类可读的文本，例如使用`e.message.startsWith('Had
    to fallback')`。不幸的是，这种方法非常容易出错！错误消息经常有拼写错误，而善意的贡献者会不断提交PR以修复它们。这些更新通常作为Semver补丁发布，可能会破坏检查错误消息字符串的应用程序。
- en: Warning
  id: totrans-56
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Unfortunately, there’s currently no perfect solution to the error-differentiation
    problem in the Node.js ecosystem. As a package author, always be intentional with
    the errors you provide and try to export error subclasses or provide a `.code`
    property. As a module consumer, offer pull requests for libraries that provide
    multiple errors in the same operation without a mechanism to programmatically
    differentiate them.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，在Node.js生态系统中，目前没有完美的解决方案来区分错误问题。作为包作者，始终要有意识地提供错误，并尝试导出错误子类或提供`.code`属性。作为模块消费者，为提供在同一操作中提供多个错误的库提交拉取请求，但没有程序化区分这些错误的机制。
- en: 'When the error is thrown and remains uncaught, the stack trace for the error
    is printed to the console and the process exits with a status of 1\. Here’s what
    an uncaught exception looks like:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 当错误被抛出并且未被捕获时，错误的堆栈跟踪将被打印到控制台，并且进程以状态1退出。以下是未捕获异常的样子：
- en: '[PRE5]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This output has been truncated, but the stack trace suggests that the error
    was thrown at line 1, column 7 of a file located at */tmp/error.js*.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 此输出已被截断，但堆栈跟踪表明错误发生在位于*/tmp/error.js*文件的第1行第7列。
- en: There is a way to globally intercept any uncaught exceptions and run a function.
    The global `process` object is an instance of the `EventEmitter` class. One of
    the many events it can emit is the `uncaughtException` event. If this event is
    listened for, the callback function will be invoked and the process itself will
    no longer automatically exit. This is useful for logging information about a failure
    before exiting a process, but by no means should you use it to swallow errors
    globally! Errors should always be dealt with contextually by wrapping appropriate
    function calls in try/catch statements.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 有一种方法可以全局拦截任何未捕获的异常并运行函数。全局`process`对象是`EventEmitter`类的一个实例。它可以发出的众多事件之一是`uncaughtException`事件。如果监听此事件，则回调函数将被调用，并且进程本身不再自动退出。这对于在退出进程之前记录有关失败的信息非常有用，但绝不应该全局使用它来吞噬错误！错误应始终通过在适当的函数调用中使用try/catch语句进行上下文处理。
- en: 'The following is an example of how the handler might be used to log a final
    distress message:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是处理程序可能用于记录最终警告消息的示例：
- en: '[PRE6]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In this case, the `logger` module represents a library that sends logs over
    the network. Here, the exception is caught; the log message is transmitted; and
    once it has been sent, the error is printed to the console and the process exits.
    Presumably, calling `process.exit()` immediately after calling `logger.send()`
    might result in the process being killed before the message can be transmitted,
    which is why the callback needs to be awaited for. While this is one way to help
    ensure asynchronous messages are sent before terminating a process, it is unfortunate
    that the application may still be allowed to process other tasks, since whatever
    caused the first uncaught exception might be repeated.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，`logger` 模块代表一个通过网络发送日志的库。在这里，异常被捕获；日志消息被传输；一旦发送完成，错误将打印到控制台并退出进程。假设在调用
    `logger.send()` 后立即调用 `process.exit()` 可能导致消息在传输之前终止进程，这就是为什么需要等待回调的原因。虽然这是确保异步消息在终止进程之前发送的一种方式，但遗憾的是，应用程序可能仍然允许处理其他任务，因为导致第一个未捕获异常的原因可能会重复。
- en: 'Promise rejections are similar to exceptions. Promise rejections can happen
    in one of two ways. The first way is by calling `Promise.reject()` directly, or
    by otherwise throwing an error within a promise chain (like in a `.then()` function).
    The other way to cause a promise rejection is by throwing while inside of an `async`
    function (within an `async` function, the JavaScript language changes the semantics
    of `throw` statements). The following two examples both result in equivalent promise
    rejections (albeit with slightly different stack traces):'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Promise 拒绝类似于异常。Promise 拒绝可以通过两种方式之一发生。第一种方式是直接调用 `Promise.reject()`，或者在 promise
    链中（比如在 `.then()` 函数中）抛出错误。引起 Promise 拒绝的另一种方式是在 `async` 函数内部抛出错误（在 `async` 函数内部，JavaScript
    语言改变了 `throw` 语句的语义）。以下两个示例都会导致等效的 Promise 拒绝（尽管堆栈跟踪略有不同）：
- en: '[PRE7]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'A slightly different error message is printed when a promise rejection happens.
    As of Node.js v14.8, a warning is displayed with it:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个 Promise 被拒绝时，打印的错误消息略有不同。截至 Node.js v14.8，它会显示一个警告：
- en: '[PRE8]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Unlike uncaught exceptions, unhandled promise rejections do not cause the process
    to crash in Node.js v14\. In Node.js v15 and above, this will cause the process
    to exit. This behavior can be enabled in v14 by running the Node.js binary with
    the `--unhandled-rejections=strict` flag.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 不同于未捕获的异常，Node.js v14 中的未处理的 Promise 拒绝不会导致进程崩溃。在 Node.js v15 及以上版本中，这将导致进程退出。可以通过在
    v14 中运行 Node.js 二进制文件时使用 `--unhandled-rejections=strict` 标志来启用此行为。
- en: 'Similar to uncaught exceptions, unhandled rejections can also be listened for
    using the `process` event emitter. Here’s an example of how it’s done:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 与未捕获的异常类似，未处理的拒绝也可以通过 `process` 事件发射器监听。以下是它的使用示例：
- en: '[PRE9]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Much like with the `uncaughtException` event, it’s important to not allow the
    process to continue running since it is likely in an invalid state. Consider running
    your Node.js processes with the flag enabled today to help future-proof your application.
    If you do encounter these uncaught rejection warnings while running an application
    in development, you should definitely track them down and fix them to prevent
    production bugs.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 就像 `uncaughtException` 事件一样，不允许进程继续运行非常重要，因为它可能处于无效状态。考虑今天使用该标志运行您的 Node.js
    进程，以帮助未来保护您的应用程序。如果在开发中运行应用程序时遇到这些未捕获的拒绝警告，您应该绝对跟踪它们并修复它们，以防止生产中的错误。
- en: Node.js and the npm package ecosystem are both going through a transitional
    phase. Node.js was built with the callback pattern in mind for asynchronous activities,
    having the first argument of the callback be an error. It’s now adapting the promise/async
    function pattern. Applications you build today will have to deal with both patterns.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Node.js 和 npm 包生态系统都在经历过渡阶段。Node.js 最初是以回调模式为异步活动设计的，回调的第一个参数是一个错误。现在它正在适应 Promise/async
    函数模式。今天构建的应用程序将不得不处理这两种模式。
- en: The `EventEmitter` class, available at `require('events').EventEmitter`, is
    extended by and used by many other classes, both those provided by core Node.js
    modules, as well as packages available on npm. Event emitters are so popular and
    follow a different-enough pattern than the other errors covered in this section
    that they’re worth their own consideration.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '`EventEmitter` 类可以通过 `require(''events'').EventEmitter` 获取，并且被许多其他类扩展和使用，包括核心
    Node.js 模块以及在 npm 上可用的包。事件发射器非常受欢迎，并且遵循一种与本节中其他错误不同的模式，因此值得单独考虑。'
- en: Instances of `EventEmitter` that emit an `error` event without having a listener
    will cause the process to terminate. When this happens, the base `EventEmitter`
    code either throws the event argument or, if it’s missing, it will throw an `Error`
    with a code of *ERR_UNHANDLED_ERROR*.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 `EventEmitter` 的实例在没有监听器的情况下发出 `error` 事件，将导致进程终止。在这种情况下，基础的 `EventEmitter`
    代码会抛出事件参数，或者如果参数丢失，则会抛出带有错误码 *ERR_UNHANDLED_ERROR* 的 `Error`。
- en: 'When an `EventEmitter` instance throws such an error, the following message
    will be displayed in the console before the process exits:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个 `EventEmitter` 实例抛出这样的错误时，在进程退出之前，控制台将显示以下消息：
- en: '[PRE10]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The appropriate way to handle these errors is to listen for `error` events,
    similar to how you would catch errors in other situations.^([3](ch08.html#idm46291180061896))
    Just like with thrown exceptions and promise rejections, the argument used when
    emitting an error, such as with `EventEmitter#emit('error', arg)`, should be an
    instance of the `Error` class. This is again so that the caller can get contextual
    information about the failure.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 处理这些错误的适当方式是监听 `error` 事件，类似于在其他情况下捕获错误。^([3](ch08.html#idm46291180061896))
    就像处理抛出的异常和 promise 拒绝一样，当发出错误时使用的参数（例如 `EventEmitter#emit('error', arg)`）应该是 `Error`
    类的实例。这样调用者可以获取有关失败的上下文信息。
- en: Signals
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 信号
- en: '*Signals* are a mechanism provided by the operating system to allow programs
    to receive short “messages” from the kernel or from other programs. And by short,
    I mean really short. A signal is just a small number that is being sent, and there
    are only a few dozen of them available. While signals are represented as a number
    under the hood, they’re usually referred to by a string name. For example, *SIGINT*
    and *SIGKILL* are two of the more commonly encountered signals.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '*信号* 是操作系统提供的一种机制，允许程序接收来自内核或其他程序的短“消息”。说是短，真的很短。信号只是一个发送的小数字，可用的信号种类不多。虽然信号在内部是以数字表示的，但通常使用字符串名称来引用它们。例如，*SIGINT*
    和 *SIGKILL* 是其中两个比较常见的信号。'
- en: Signals can be used for multiple reasons, though they are most commonly used
    to tell a process that it needs to terminate. Different platforms support different
    sets of signals, and the numeric values can even change between OS, which is why
    the string version of a signal is used. Run the `**kill -l**` command to get a
    list of the signals recognized by your current machine.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 信号可以用于多种原因，尽管它们最常用于告知进程需要终止。不同的平台支持不同的信号集合，甚至在操作系统之间，数字值也可能会变化，这就是为什么使用信号的字符串版本。运行
    `**kill -l**` 命令可以获取当前机器识别的信号列表。
- en: '[Table 8-2](#table_signals) contains a list of the more universal signals and
    what they’re used for.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[Table 8-2](#table_signals) 包含了更通用的信号列表及其用途。'
- en: Table 8-2\. Common signals
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8-2\. 常见信号
- en: '| Name | Number | Handleable | Node.js default | Signal purpose |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 数字 | 可处理 | Node.js 默认 | 信号目的 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| `SIGHUP` | 1 | Yes | Terminate | Parent terminal has been closed |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| `SIGHUP` | 1 | 是 | 终止 | 父终端已关闭 |'
- en: '| `SIGINT` | 2 | Yes | Terminate | Terminal trying to interrupt, à la Ctrl
    + C |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| `SIGINT` | 2 | 是 | 终止 | 终端尝试中断，如 Ctrl + C |'
- en: '| `SIGQUIT` | 3 | Yes | Terminate | Terminal trying to quit, à la Ctrl + D
    |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| `SIGQUIT` | 3 | 是 | 终止 | 终端尝试退出，如 Ctrl + D |'
- en: '| `SIGKILL` | 9 | No | Terminate | Process is being forcefully killed |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| `SIGKILL` | 9 | 否 | 终止 | 进程正在被强制杀死 |'
- en: '| `SIGUSR1` | 10 | Yes | Start Debugger | User-defined signal 1 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| `SIGUSR1` | 10 | 是 | 启动调试器 | 用户定义信号 1 |'
- en: '| `SIGUSR2` | 12 | Yes | Terminate | User-defined signal 2 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| `SIGUSR2` | 12 | 是 | 终止 | 用户定义信号 2 |'
- en: '| `SIGTERM` | 12 | Yes | Terminate | Represents a graceful termination |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| `SIGTERM` | 12 | 是 | 终止 | 表示优雅终止 |'
- en: '| `SIGSTOP` | 19 | No | Terminate | Process is being forcefully stopped |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| `SIGSTOP` | 19 | 否 | 终止 | 进程正在被强制停止 |'
- en: When a program receives a signal, it usually gets a choice on how to handle
    it. The two signals *SIGKILL* and *SIGSTOP* cannot be handled at all, as conveyed
    by the *Handleable* column. Any program that receives either of those two signals
    will be terminated, regardless of what language it’s written in. Node.js also
    comes with some default actions for the remaining signals, as listed in the *Node.js
    default* column. Most of them cause the process to terminate, however the *SIGUSR1*
    signal tells Node.js to start the debugger.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 当程序接收到信号时，通常可以选择如何处理它。两个信号 *SIGKILL* 和 *SIGSTOP* 无法处理，如 *可处理* 列所示。任何接收到这两个信号的程序将被终止，无论它用什么语言编写。Node.js
    也为其余信号提供了一些默认操作，如 *Node.js 默认* 列中所列。其中大多数导致进程终止，但 *SIGUSR1* 信号告诉 Node.js 启动调试器。
- en: Node.js makes it straightforward to handle these signals when they’re received.
    Just like how you handle uncaught exceptions and unhandled rejections, the `process`
    emitter also emits events named after the signal being received. To prove this,
    create a new file named */tmp/signals.js* and add the content in [Example 8-1](#ex_signal_handlers)
    to the file.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 当接收到信号时，Node.js 可以很容易地处理这些信号。就像处理未捕获的异常和未处理的拒绝一样，`process` 发射器还会发出以接收到的信号命名的事件。为了证明这一点，在你的终端中创建一个名为
    */tmp/signals.js* 的新文件，并将内容添加到 [示例 8-1](#ex_signal_handlers) 中。
- en: Example 8-1\. */tmp/signals.js*
  id: totrans-96
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-1\. */tmp/signals.js*
- en: '[PRE11]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Execute the file in a terminal window. It prints a message with the process
    ID and then sits there for up to five minutes before terminating. Once you start
    the program, try to terminate the process by using the Ctrl + C keyboard shortcut.
    Try as you might, you won’t be able to terminate the process! When you use the
    Ctrl + C shortcut, your terminal sends the *SIGINT* signal to the process. The
    default action of exiting the process has now been replaced by your new signal
    handler, one that merely prints the name of the signal it has received. Take note
    of the process ID printed on your screen and switch to a new terminal window.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在终端窗口中执行该文件。它会打印一个带有进程 ID 的消息，然后在终止前最多保持五分钟。一旦启动程序，请尝试使用 Ctrl + C 键盘快捷键终止进程。无论你怎么尝试，都无法终止进程！当你使用
    Ctrl + C 快捷键时，你的终端会向进程发送 *SIGINT* 信号。现在退出进程的默认操作已被你的新信号处理程序替换，它只会打印接收到的信号名称。注意屏幕上打印的进程
    ID，并切换到新的终端窗口。
- en: 'In this new terminal window, you’re going to execute a command that will send
    a signal to your process. Run the following command to send the *SIGHUP* signal
    to your process:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个新的终端窗口中，你将执行一个命令，向你的进程发送一个信号。运行以下命令向你的进程发送 *SIGHUP* 信号：
- en: '[PRE12]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The `kill` command is a convenient utility that sends signals to processes.
    Since signals were originally used to kill processes, the name sort of stuck around
    and the `kill` command is what we use today.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '`kill` 命令是一个方便的实用程序，用于向进程发送信号。由于信号最初是用来杀死进程的，这个名字有点残留了下来，`kill` 命令就是我们今天使用的命令。'
- en: 'At it turns out, Node.js processes are also capable of sending signals to other
    processes. And, as an homage to the convention of referring to signals as *kill*,
    the method used to send signals is available as `process.kill()`. Run the following
    command in your terminal to run a simple Node.js one-liner before exiting:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，Node.js 进程还能够向其他进程发送信号。并且，作为将信号称为 *kill* 的传统的一种致敬，用于发送信号的方法被命名为 `process.kill()`。在退出之前，在你的终端中运行以下命令以运行一个简单的
    Node.js 单行命令：
- en: '[PRE13]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Again, you should see the *SIGHUP* message printed in the console of the first
    application you’re running.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 再次在你运行的第一个应用程序的控制台中看到 *SIGHUP* 消息。
- en: 'Now that you’re done experimenting with signals, you’re ready to terminate
    the original process. Run the following command in your second terminal window:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经完成了信号的实验，可以准备终止原始进程了。在你的第二个终端窗口中运行以下命令：
- en: '[PRE14]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This command will send the *SIGKILL* signal to your process, terminating it
    immediately. The `-9` argument tells the `kill` command to use the numeric version
    of the signal. *SIGKILL* is universally the ninth signal, so this command should
    be fairly portable and will work pretty much everywhere. Recall that the *SIGKILL*
    command can’t have a signal handler installed for it. In fact, if you were to
    attempt to listen for that event on the `process` event emitter, the following
    error would be thrown:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令将向您的进程发送*SIGKILL*信号，立即终止它。 `-9`参数告诉`kill`命令使用信号的数字版本。*SIGKILL*通常是第九个信号，因此这个命令应该在几乎所有地方都能正常工作。请注意，*SIGKILL*命令不能为其安装信号处理程序。事实上，如果您试图在`process`事件发射器上监听该事件，将会抛出以下错误：
- en: '[PRE15]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: As a practical application of signals, if an application receives a signal,
    it can begin shutting itself down in a graceful manner. This can include refusing
    to handle new connections, transmitting a shutdown metric, and closing database
    connections. When a Kubernetes pod is terminated, Kubernetes both stops sending
    requests to the pod and sends it the *SIGTERM* signal. Kubernetes also starts
    a 30 second timer. During this time, the application can then do whatever work
    is necessary to gracefully shutdown. Once the process is done, it should terminate
    itself so that the pod will go down. However, if the pod doesn’t terminate itself,
    Kubernetes will then send it the *SIGKILL* signal, forcefully closing the application.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 作为信号的实际应用，如果应用程序接收到信号，它可以以优雅的方式开始关闭自身。这可能包括拒绝处理新连接、传输关闭度量和关闭数据库连接。当Kubernetes
    pod被终止时，Kubernetes停止向该pod发送请求，并发送*SIGTERM*信号。Kubernetes还启动一个30秒的计时器。在此期间，应用程序可以执行必要的工作以优雅地关闭。一旦进程完成，它应该终止自身，以便pod将会下降。但是，如果pod未终止自身，Kubernetes将会向其发送*SIGKILL*信号，强制关闭应用程序。
- en: Building Stateless Services
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建无状态服务
- en: It’s important that state be kept out of Node.js services due to the ephemeral
    nature of containers, and the fact that you and I write buggy code. If state isn’t
    kept outside of application code, then that state can be lost forever. This can
    lead to inconsistent data, poor user experience, and, in the wrong situations,
    even financial loss.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 由于容器的瞬时性质和您和我的编写的错误代码，将状态保持在Node.js服务之外非常重要。如果状态不在应用代码之外保持，则该状态可能永远丢失。这可能导致数据不一致，用户体验差，甚至在错误的情况下可能导致财务损失。
- en: '*Single Source of Truth* is a philosophy that there is a single location that
    any particular piece of data must call home. If this data is ever kept in two
    separate locations, then those two sources may diverge (for example, if an update
    action succeeds in one place but then fails in another). If this data only exists
    within an application process and that process crashes, then the only copy of
    the data has just been lost.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '*唯一真相源*是一种哲学，即任何特定数据必须有一个唯一的位置作为其归属地。如果这些数据存储在两个不同的位置，那么这两个来源可能会分歧（例如，在一个地方成功更新操作，但在另一个地方失败）。如果这些数据仅存在于应用程序进程中，并且该进程崩溃，那么数据的唯一副本也就刚刚丢失了。'
- en: Keeping all state out of a process is impossible, but keeping the source of
    truth from the process is achievable. There is one caveat, though, and that is
    if a client tries to modify state by contacting a service and some sort of fault
    happens that leads to the loss of data. In that case, the service needs to respond
    to the client with an appropriate error. When this happens, the responsibility
    of that modified state is then shifted back to the client. This might result in
    an error being displayed to the user, prompting them to click the “Save” button
    again.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 保持进程中的所有状态不可避免，但是将真相源头从进程中隔离是可行的。然而，有一个警告，即如果客户端尝试通过联系服务来修改状态，并且发生导致数据丢失的某种故障，那么服务就需要用适当的错误回应客户端。当这种情况发生时，修改后的状态的责任就转移到了客户端身上。这可能会导致向用户显示错误，并提示他们再次点击“保存”按钮。
- en: 'It can be difficult to identify situations where the only source of truth is
    located inside of an application process, or situations where a process crash
    can lead to data inconsistency. Consider a situation where a Node.js process receives
    a request and needs to notify two upstream services, *Data store #1* and *Data
    store #2*, that an account balance has been reduced. [Figure 8-1](#fig_hidden_state)
    is a digram of how the Node.js application might do this.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '很难确定只有应用程序进程内部是唯一真实的信息源的情况，或者进程崩溃可能导致数据不一致的情况。考虑一个Node.js进程接收请求并需要通知两个上游服务，*数据存储
    #1* 和 *数据存储 #2*，账户余额已经减少。[图8-1](#fig_hidden_state)是Node.js应用程序可能执行此操作的示意图。'
- en: '![A service touches two data stores. It modifies data in one store but then
    crashes before modifying data in the second store. The two stores are no longer
    in sync. The service was technically stateful after all.](assets/dsnj_0801.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![一个服务触及两个数据存储。它在一个存储中修改数据，但在修改第二个存储中的数据之前崩溃了。这两个存储现在不再同步。这个服务在技术上终究是有状态的。](assets/dsnj_0801.png)'
- en: Figure 8-1\. Hidden state
  id: totrans-116
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-1\. 隐藏状态
- en: 'The equivalent application code for this situation might look like this:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况下的等效应用程序代码可能如下所示：
- en: '[PRE16]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: In the happy path, the application receives a request, notifies the first service,
    notifies the second service, and finally responds to the client that the operation
    was a success. In the sad path, the application notifies the first service and
    then crashes before notifying the second service. The client receives a failure
    response and knows that something bad happened. However, the system has been left
    in an inconsistent state.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在正常路径中，应用程序接收请求，通知第一个服务，通知第二个服务，最后向客户端响应操作成功。在悲伤的路径中，应用程序通知第一个服务，然后在通知第二个服务之前崩溃。客户端收到失败响应并知道发生了一些不好的事情。然而，系统留下了不一致的状态。
- en: In this case, the Node.js application was, albeit temporarily, the only entity
    knowledgeable about the state of the system. Once the process crashed, the two
    backend services were left in an inconsistent state. Managing situations like
    these can be a very difficult task. I encourage you to read Martin Kleppmann’s
    *Designing Data-Intensive Applications* for more information about distributed
    transactions.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，Node.js 应用程序，尽管是暂时的，是唯一知晓系统状态的实体。一旦进程崩溃，两个后端服务就会处于不一致状态。管理这类情况可能是一个非常困难的任务。我鼓励您阅读Martin
    Kleppmann的《设计数据密集型应用》以获取有关分布式事务的更多信息。
- en: Avoiding Memory Leaks
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 避免内存泄漏
- en: 'Maintaining state within an application process is not only risky for the data,
    but it can also be risky for the process. Imagine a service that declares a singleton
    Map instance for storing account information. Such an application might have code
    that looks like this:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用程序进程内维护状态不仅对数据风险高，对进程本身也是风险。想象一个声明用于存储账户信息的单例Map实例的服务。这样的应用程序可能会有以下代码：
- en: '[PRE17]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Why might an application be built this way? Well, it’s extremely fast. Writing
    a data change to an in-memory data structure will always be orders of magnitude
    faster than writing to an external service. It’s also very easy to make mutable
    globals like this in Node.js.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么可能构建这样的应用程序？嗯，它非常快。将数据变更写入内存数据结构始终比写入外部服务快数个数量级。在Node.js中创建可变全局变量也非常容易。
- en: What sort of problems might arise with this example? The first is that of persistence.
    When an application restarts, how will the data be transferred to a new process?
    One way would be to listen for the `SIGTERM` signal and then to write the content
    to the filesystem. As you saw previously, filesystems aren’t easily persisted
    between container restarts, though it is possible. There are also other situations
    that cause a process to terminate, as you saw in [“The Death of a Node.js Process”](#ch_resilience_sec_death).
    Even if the application sends a representation of the map to another service when
    it suspects termination, there’s no guarantee that the external service is still
    reachable.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例可能会出现哪些问题呢？首先是持久性问题。当应用程序重新启动时，数据将如何传输到新的进程？一种方法是监听`SIGTERM`信号，然后将内容写入文件系统。正如您之前看到的，文件系统在容器重新启动之间不容易持久化，尽管这是可能的。还有其他导致进程终止的情况，正如您在[“Node.js
    进程的死亡”](#ch_resilience_sec_death)中所见。即使应用程序在怀疑终止时向另一个服务发送地图的表示，也不能保证外部服务仍然可达。
- en: Another problem with this approach is that it’s a potential memory leak. The
    `accounts` Map has an unbounded size and may grow until the process consumes all
    of the free memory of the host! For example, there might be a bug where the `account_id`
    value changes slightly, leading to each `set()` call to insert a new record. Or
    an attacker might make many fake accounts to fill the value.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的另一个问题是潜在的内存泄漏。`accounts`映射具有无界大小，并且可能增长，直到进程消耗主机的所有空闲内存！例如，可能会存在一个错误，`account_id`值轻微更改，导致每个`set()`调用插入一个新记录。或者攻击者可能会创建许多假帐户来填充值。
- en: 'Most potential memory leaks won’t be as easy to spot as this one. Here’s a
    vastly simplified example of a memory leak in the `cls-hooked` package,^([4](ch08.html#idm46291179692920))
    a package that receives over 400,000 downloads every week:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数潜在的内存泄漏不像这个例子那么容易发现。这里有一个极为简化的例子，来自每周下载量超过`400,000`的`cls-hooked`包[^4]：
- en: '[PRE18]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This package provides an implementation of continuation local storage, specifically
    to maintain a “session” object, identified by a “namespace,” between asynchronous
    callbacks. For example, a session can be created when an HTTP request is received,
    information about the user making the request can be added to the session object,
    and then, once an asynchronous database call finishes, the session can be looked
    up again.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 此包提供了继续本地存储的实现，特别是在异步回调之间维护“会话”对象，由“命名空间”标识。例如，当接收到HTTP请求时可以创建会话，将请求用户的信息添加到会话对象中，然后，在异步数据库调用完成时，可以再次查找会话。
- en: The global that maintains state in this case is `process.namespace`. The memory
    leak is that the namespace identifiers are never deleted from the global; instead
    they are set to `null`. Different applications use this package in different ways,
    but if an application creates a new namespace for each incoming HTTP request,
    it ends up resulting in a memory increase linear to the traffic rate.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下维护状态的全局变量是`process.namespace`。内存泄漏的问题在于命名空间标识符从全局变量中永远不会被删除；而是被设置为`null`。不同的应用程序以不同的方式使用这个包，但是如果一个应用程序为每个传入的HTTP请求创建一个新的命名空间，那么它最终会导致内存线性增长到流量速率。
- en: Bounded In-Process Caches
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**有界进程缓存**'
- en: One type of state that is acceptable to store within an application process
    is cached data. A cache represents a copy of data that is either expensive to
    calculate (CPU cost) or expensive to retrieve (network request time). In this
    situation a cache is intentionally *not* the source of truth. A cache stores data
    as key/value pairs where the key is a unique identifier for the cache’s resource
    and the value is the resource itself, serialized or otherwise. This type of data
    can be stored within a process because the source of truth is still safe after
    the process terminates.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 一个应用程序进程内可以接受存储的状态类型是缓存数据。缓存表示数据的副本，计算起来可能很昂贵（CPU成本），或者检索起来可能很昂贵（网络请求时间）。在这种情况下，缓存故意*不*是真相来源。缓存将数据存储为键/值对，其中键是缓存资源的唯一标识符，值是资源本身，经过序列化或其他方式。这种类型的数据可以存储在进程内，因为真相来源在进程终止后仍然安全。
- en: When dealing with a cache, an application first determines what data to look
    up. For example, this data might be an account with an identifier of 123\. Once
    the identifier has been determined, the application will then consult with the
    cache. If the cache does contain the resource, such as `account:123`, then that
    resource is used and the application continues with the data. This situation is
    referred to as a *cache hit*. Looking up data from an in-process cache takes microseconds.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 处理缓存时，应用程序首先确定要查找的数据。例如，这些数据可能是具有标识符`123`的帐户。确定标识符后，应用程序将与缓存进行协商。如果缓存包含资源，如`account:123`，则使用该资源，并继续处理数据。这种情况称为*缓存命中*。从进程内缓存中查找数据仅需微秒。
- en: However, if the resource doesn’t exist within the cache, then the application
    needs to perform the slower lookup of the data, potentially taking seconds of
    time. This is referred to as a *cache miss*. When this happens, the application
    performs whatever slow calculation or network request is needed. Once the result
    is obtained, the application then sets the value in the cache and continues with
    the newly required resource. When the resource is needed again, it consults the
    cache again.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果资源在缓存中不存在，则应用程序需要执行较慢的数据查找，可能需要几秒钟的时间。这被称为*缓存未命中*。当发生这种情况时，应用程序执行所需的任何缓慢计算或网络请求。一旦获取结果，应用程序然后将值设置在缓存中，并继续使用新需要的资源。当再次需要资源时，它再次查询缓存。
- en: Caches should only be used in situations where performance requirements can’t
    be attained without them. Caches add an additional layer of complexity to an application.
    A cache also introduces the situation where the copy of the data in the cache
    may be outdated from the source of truth. For example, the `account:123` resource
    may have been modified to have a balance of 0, even though the cached version
    still contains a balance of 100.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 只有在无法满足性能要求时才应使用缓存。缓存给应用程序增加了额外的复杂性。缓存还引入了这样一种情况，即缓存中的数据副本可能已经过时，与真相源不符。例如，`account:123`资源可能已被修改为余额为0，尽管缓存版本仍然包含100的余额。
- en: Knowing when to update or remove entries from a cache is a topic known as *cache
    invalidation*. There isn’t a perfect solution to this problem, only philosophical
    ones. It often becomes a business question of what sort of tolerance the product
    can have with regards to an outdated cache. Is it okay to display a slightly out-of-date
    account balance? Possibly yes. Is it okay to allow a player to spend more coins
    than they have in their account? Probably not.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 知道何时更新或从缓存中删除条目是一种称为*缓存失效*的主题。对于这个问题，并没有完美的解决方案，只有哲学上的解决方案。通常，这成为一个业务问题，即产品对于过期缓存的容忍度。显示稍有过时的账户余额可以吗？可能可以。允许玩家花费超过其账户中的硬币可以吗？可能不行。
- en: While cache invalidation philosophy is something specific to each organization,
    the requirement to avoid memory leaks is more universal. It’s safe to assume that
    a cache should never grow so much that it causes a process to crash.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管缓存失效的哲学因组织而异，但避免内存泄漏的要求更为普遍。可以肯定的是，缓存不应该增长到导致进程崩溃的程度。
- en: Applications run in environments where there is a finite amount of memory available.
    A host machine will always have a maximum amount of physical RAM that it has available.
    Containers and virtual machines then have a smaller piece of that memory available.
    When a Node.js process consumes too much memory, it will either fail to get access
    to more memory, or a supervising process like Docker may terminate the process
    once a threshold has been reached. Memory is measured in the number of bytes being
    consumed, not the number of records being cached, so it’s good to use a tool that
    limits in-process cache size based on some semblance of the byte requirements
    of the data.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序在有限内存环境中运行。主机机器总是有其可用的物理RAM的最大限制。容器和虚拟机则有更少的可用内存。当Node.js进程消耗过多内存时，要么无法获得更多内存，要么像Docker这样的监督进程可能会在达到阈值后终止进程。内存是以消耗的字节数来衡量的，而不是缓存记录的数量，因此最好使用一种工具，根据数据的字节需求限制进程内缓存大小。
- en: The `lru-cache` package is a popular tool for doing just that. It is a key/value
    store that can be configured to use the length of strings or buffers that are
    inserted into the cache to loosely approximate the memory requirements of those
    entries.^([5](ch08.html#idm46291179566392)) With this package, you can set values,
    get values, and perform your own lookup if a value is missing. The package even
    accepts an expiration time so that entries older than a certain amount of time
    will be removed. The LRU in the name stands for *Least Recently Used*. This is
    a common cache practice for evicting keys that haven’t been accessed in a while—which
    hopefully means keys where cache misses don’t result in too high of a performance
    loss.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '`lru-cache`包是一个用于执行此操作的流行工具。它是一个键/值存储，可以配置为使用插入到缓存中的字符串或缓冲区的长度来粗略估算这些条目的内存需求。^([5](ch08.html#idm46291179566392))
    使用这个包，你可以设置值，获取值，并在值丢失时执行自己的查找。该包甚至接受一个过期时间，以便删除超过一定时间的条目。名称中的LRU代表*Least Recently
    Used*，这是一种常见的缓存实践，用于驱逐长时间未访问的键，希望这些键的缓存未命中不会导致性能损失过高。'
- en: Now that you’re familiar with some of the philosophies behind in-memory caches,
    you’re ready to work with one of your own. Create a new file named *caching/server.js*
    and add the content from [Example 8-2](#ex_lru_cache) to it. This file will serve
    as a mini-proxy to the GitHub API for looking up account details.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你对内存缓存背后的一些理念有了一定了解，你可以准备使用你自己的内存缓存。创建一个名为*caching/server.js*的新文件，并将[Example 8-2](#ex_lru_cache)中的内容添加到其中。这个文件将作为一个迷你代理用于
    GitHub API 查找账户详情。
- en: Example 8-2\. *caching/server.js*
  id: totrans-141
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-2\. *caching/server.js*
- en: '[PRE19]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[![1](assets/1.png)](#co_resilience_CO1-1)'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_resilience_CO1-1)'
- en: The cache will store approximately 4kb of data for up to 10 minutes.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 缓存将保存大约 4kb 的数据，最多达到 10 分钟。
- en: '[![2](assets/2.png)](#co_resilience_CO1-2)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_resilience_CO1-2)'
- en: The cache is always consulted before making a request.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在发出请求之前，总是先查询缓存。
- en: '[![3](assets/3.png)](#co_resilience_CO1-3)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_resilience_CO1-3)'
- en: The cache is updated whenever data is retrieved.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 每当检索数据时，缓存都会被更新。
- en: 'Initialize the npm project, install the dependencies, and run the server in
    a terminal window. In another terminal window, run the following `curl` commands:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在终端窗口中初始化npm项目，安装依赖项，并运行服务器。在另一个终端窗口中运行以下`curl`命令：
- en: '[PRE20]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Note
  id: totrans-151
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: At the time of this writing, each response from the GitHub API is about 1.2
    KB. If things have changed much in the future, you may need to configure the server
    to have a larger LRU size. Try to set it to be large enough to hold at least two
    results. Also, be careful to not get rate-limited by the GitHub API. When that
    happens, you’ll get failed responses.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，GitHub API的每个响应约为1.2 KB。如果未来有所改变，可能需要配置服务器以具有更大的LRU大小。尝试设置足够大，以至少容纳两个结果。此外，小心不要受到GitHub
    API的速率限制。当发生这种情况时，你将收到失败的响应。
- en: When you run the first command, you should see a *cache miss* message displayed
    in the server terminal window. The command takes about 200ms to complete on my
    machine. This is because the *server.js* application is making an outgoing network
    request to the GitHub servers. When you make the second request, you should see
    the same thing happen, with another *cache miss* message and a request that likely
    takes 200ms to complete. However, when you run the third command, you should see
    something a little different, specifically a *cache hit* message, and the response
    should be much faster (in my case, 20ms).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行第一个命令时，你应该在服务器终端窗口看到一个*cache miss*消息。该命令在我的机器上大约需要 200ms 完成。这是因为*server.js*应用正在向GitHub服务器发出网络请求。当你发出第二个请求时，你应该看到同样的情况发生，另一个*cache
    miss*消息，并且可能需要 200ms 完成的请求。然而，当你运行第三个命令时，你应该看到一些不同的东西，具体来说是一个*cache hit*消息，响应应该更快（在我的情况下，是20ms）。
- en: Next, substitute your username in one of those URLs and make another request.
    Then, use some other entries like *express* and *fastify*. Finally, circle back
    to the original *tlhunter* account again. This time, you should see that the request
    resulted in another *cache miss*. This is because `lru-cache` evicted the original
    *tlhunter* entry from the cache since newer entries replaced it and the cache
    had become full.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在这些网址中的一个中替换你的用户名并发起另一个请求。然后，使用一些其他条目，如*express*和*fastify*。最后，再回到最初的*tlhunter*账户。这时，你应该会看到请求导致了另一个*cache
    miss*。这是因为`lru-cache`从缓存中删除了原始的*tlhunter*条目，由于新条目替换了它，并且缓存已满。
- en: There are a few shortcomings with this solution. One problem is surfaced when
    the GitHub API returns an error. When this happens, the error response will get
    inserted into the cache—ideally, no entry would be inserted when this happens.
    Another possible shortcoming (depending on how you look at it) is that the cache
    stores the JSON representation of the resource, not parsed object. This results
    in redundant `JSON.parse()` calls being made each time the entry is retrieved
    from the cache. Storing the JSON string in the cache library does make it easier
    to calculate memory usage (string length). It also prevents accidental mutation
    of the cached objects.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 此解决方案存在一些缺陷。一个问题是当 GitHub API 返回错误时会暴露出来。发生这种情况时，错误响应将被插入到缓存中，理想情况下，当这种情况发生时不应插入任何条目。另一个可能的缺点（取决于你的观点）是，缓存存储了资源的
    JSON 表示形式，而不是解析后的对象。这导致每次从缓存中检索条目时都会进行冗余的 `JSON.parse()` 调用。在缓存库中存储 JSON 字符串确实使得计算内存使用更容易（字符串长度）。它还防止了对缓存对象的意外变异。
- en: Another issue is that parallel incoming requests for the same username will
    result in simultaneous cache misses followed by parallel outgoing requests to
    GitHub. This might not be a big deal, but sometimes it’s nice to use a cache to
    reduce the number of outgoing requests to a third-party API. For example, if you
    send too many requests to GitHub, you’ll start to get rate limited. For this reason
    a more robust solution may be needed.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题是，对同一用户名的并行请求将导致同时的缓存未命中，随后是对 GitHub 的并行出站请求。这可能并不是什么大问题，但有时使用缓存来减少对第三方
    API 的出站请求是很好的。例如，如果向 GitHub 发送过多请求，你将开始被限制速率。因此，可能需要更强大的解决方案。
- en: There are two more issues with this cache that specifically deal with caching
    data inside of the process itself. The first is that if the process is restarted,
    then the cache is lost with it. In a high-throughput environment, a service restart
    will mean that upstream services will then receive a burst of traffic. For example,
    the *web-api* service you previously built could be caching results from the *recipe-api*.
    Once a *web-api* instance restarts, the *recipe-api* instances will receive increased
    traffic until the cache is replenished.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 还有另外两个与此缓存相关的问题，专门处理进程内部的数据缓存。首先是，如果进程重新启动，那么缓存将随之丢失。在高吞吐量环境中，服务重新启动将意味着上游服务将收到突发的流量。例如，你之前构建的
    *web-api* 服务可能正在缓存来自 *recipe-api* 的结果。一旦 *web-api* 实例重新启动，*recipe-api* 实例将接收增加的流量，直到缓存重新填充为止。
- en: 'Another shortcoming is that the cache is only used by a single service instance!
    If you had a fleet of 100 *web-api* instances, each would still need to send a
    request for the same *recipe-api* resource at least once every 10 minutes. Each
    service also contains redundant caches, wasting overall available memory. This
    issue can be seen by running a second instance of the server and making a request
    to that:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个缺点是，该缓存仅由单个服务实例使用！如果你有一组 100 个 *web-api* 实例，每个实例至少每 10 分钟都需要为同一个 *recipe-api*
    资源发送一次请求。每个服务还包含冗余的缓存，浪费了整体可用内存。可以通过运行服务器的第二个实例并对其进行请求来看到这个问题：
- en: '[PRE21]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: In this case, the request to the server instance listening on port 4000 will
    never make use of the other server instance’s cache. The easiest way to fix these
    two issues is to use an external caching service.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，对端口 4000 上监听的服务器实例的请求将永远不会使用另一个服务器实例的缓存。解决这两个问题的最简单方法是使用外部缓存服务。
- en: External Caching with Memcached
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Memcached 进行外部缓存
- en: 'There are many trade-offs when it comes to performing a cache lookup. Speed,
    durability, expiration configurability, and how the cache is shared across services
    are all important concerns. Here’s a quick comparison of three different caching
    strategies:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行缓存查找时存在许多权衡考虑因素。速度、持久性、过期配置能力以及缓存在服务之间的共享方式都是重要问题。以下是三种不同缓存策略的快速比较：
- en: In-memory cache
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 内存缓存
- en: This is the approach examined in the previous section. It’s the fastest approach,
    but the cache is destroyed between crashes and deployments. Data structure changes
    between application versions don’t have side effects. Lookups that happen here
    will probably take less than one millisecond.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在前一节中讨论的方法。这是最快的方法，但是在崩溃和部署之间缓存会被销毁。应用程序版本之间的数据结构更改不会产生副作用。在这里进行的查找可能不到一毫秒。
- en: External cache
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 外部缓存
- en: This is the approach covered in this section. It’s slower than an in-memory
    cache but should be faster than hitting the source of truth. It also prevents
    the cache from being wiped out between crashes and deployments. Data structures
    must be maintained, or cache keys renamed, between application versions. Lookups
    that happen here may take tens of milliseconds.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这是本节中介绍的方法。它比内存中的缓存慢，但应该比直接访问源数据更快。它还防止缓存在崩溃和部署之间被清除。必须在应用程序版本之间维护数据结构，或者重命名缓存键。在这里发生的查找可能需要几十毫秒。
- en: No cache
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 无缓存
- en: In this approach, an application talks directly to the source of truth. It is
    usually the slowest and simplest to implement. There’s no risk of data integrity
    issues because there’s no cached values that can drift from the source of truth.
    Lookups that happen with this strategy could take any amount of time.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种方法中，应用程序直接与真相源进行通信。通常这是最慢和最简单的实现方式。由于没有缓存值可以从真相源漂移，所以不存在数据完整性问题的风险。使用这种策略进行的查找可能需要任意数量的时间。
- en: 'Much like with databases, if a heterogeneous collection of services are allowed
    to read and write to a cache service, bad things may happen. For example, if one
    team inside of an organization owns the *recipe-api* and another team owns the
    *web-api*, those teams may not communicate how the structure of cached data is
    going to change between releases. This can result in conflicting expectations
    and runtime errors. Just think: an API exposed over HTTP is just one API surface;
    if applications are sharing database tables or caches, there are now multiple
    API surfaces!'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 就像数据库一样，如果允许异构的服务集合读写缓存服务，可能会发生一些糟糕的事情。例如，如果组织内的一个团队拥有 *recipe-api*，另一个团队拥有
    *web-api*，这些团队可能没有沟通缓存数据结构在发布期间如何变化的情况。这可能导致冲突的期望和运行时错误。想想看：通过 HTTP 公开的 API 只是一个
    API 表面；如果应用程序共享数据库表或缓存，现在就有了多个 API 表面！
- en: Introducing Memcached
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍 Memcached
- en: One of the most established caching services available is *Memcached*. It’s
    a dependable, no-frills cache, one that can be distributed across multiple machines.
    When instantiating a Memcached instance, you specify the maximum amount of memory
    that the instance may consume, and Memcached automatically purges newly added
    entries following the same LRU approach covered in the previous section.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个最成熟的缓存服务是 *Memcached*。它是一个可靠的、简单的缓存，可以分布在多台机器上。在实例化 Memcached 实例时，您需要指定实例可以消耗的最大内存量，Memcached
    会自动按照上一节中介绍的 LRU 方法清除新添加的条目。
- en: Keys can be up to 250 bytes long, and values can be up to 1MB. Each individual
    key can have its own expiration time set.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 键可以长达 250 字节，值可以长达 1MB。每个单独的键可以设置自己的过期时间。
- en: Memcached provides several commands as part of its API. One of the most obvious
    commands is `set(key, val, expire)`, which will set a key to a value. It has a
    correlating `get(key1[, key2…])` command for retrieving data. There’s also `add(key,
    val, expire)`, which also sets data but it will only succeed if the key doesn’t
    already exist. Both `incr(key, amount)` and `decr(key, amount)` allow you to atomically
    modify numeric values, but only if they already exist. There’s even a `replace(key,
    val, expire)` command that will only set a value if it already exists. The `delete(key)`
    command allows you to delete a single key, and the `flush_all()` command removes
    all keys.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: Memcached 提供了几个命令作为其 API 的一部分。其中一个最明显的命令是 `set(key, val, expire)`，它将一个键设置为一个值。它还有一个对应的
    `get(key1[, key2…])` 命令用于检索数据。还有 `add(key, val, expire)`，它也设置数据，但只有在键不存在时才会成功。`incr(key,
    amount)` 和 `decr(key, amount)` 允许您原子地修改数字值，但只有在它们已经存在时才能操作。甚至有一个 `replace(key,
    val, expire)` 命令，它只会在值已经存在时才设置一个值。`delete(key)` 命令允许您删除单个键，`flush_all()` 命令则移除所有键。
- en: There are two commands for performing string manipulations on the values stored
    in Memcached. The first is `append(key, val, expire)`, and the second is `prepend(key,
    val, expire)`. These commands allow an application to append and prepend a string
    to an existing value.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 有两个命令用于在 Memcached 中执行字符串操作。第一个是 `append(key, val, expire)`，第二个是 `prepend(key,
    val, expire)`。这些命令允许应用程序向现有值追加和前置一个字符串。
- en: There are also two additional commands for making atomic changes where one client
    wants to ensure that another client hasn’t changed entries without it knowing.
    The first is `gets(key)`, which returns both the value of the data and a “CAS”
    (Compare and Set) id. This is an integer that changes with each manipulation to
    the key. This value can then be used with a correlating `cas(key, val, cas_id,
    expire)` command. That command will set a key to a new value but only if the existing
    value has the same CAS id.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 还有两个额外的命令用于进行原子更改，其中一个客户端希望确保另一个客户端在不知情的情况下没有更改条目。第一个是`gets(key)`，它返回数据的值和一个“CAS”（比较和设置）id。这是一个整数，每次对键进行操作时都会更改。然后可以将此值与相关的`cas(key,
    val, cas_id, expire)`命令一起使用。该命令将设置键为新值，但仅当现有值具有相同的CAS id时才会执行。
- en: Various other commands exist for getting statistical information about the server,
    for retrieving the server settings, and for otherwise debugging the cache, though
    your applications probably won’t need to use them.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 存在许多其他命令可用于获取关于服务器的统计信息，检索服务器设置以及其他调试缓存的信息，尽管您的应用程序可能不需要使用它们。
- en: Running Memcached
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行Memcached
- en: Just like most of the servers you’ve worked with, Memcached can be run within
    a Docker container for convenience.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 就像您使用过的大多数服务器一样，Memcached可以在Docker容器中运行以方便使用。
- en: Like many other Docker images, Memcached also includes an Alpine variant to
    consume less resources. When instantiating the Memcached service, there are a
    few flags that can be passed in, including `-d` to daemonize (not required with
    Docker containers), `-m` to set the maximum amount of memory (very useful), and
    `-v` to enable logging (this flag can be repeated to increase verbosity).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 像许多其他Docker镜像一样，Memcached还包括一个Alpine变体，以消耗更少的资源。在实例化Memcached服务时，可以传递几个标志，包括`-d`以守护进程化（在Docker容器中不需要），`-m`以设置最大内存量（非常有用），以及`-v`以启用日志记录（此标志可以重复以增加详细信息）。
- en: 'Run the following command in a terminal window to run Memcached:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在终端窗口中运行以下命令来运行Memcached：
- en: '[PRE22]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This Memcached instance is limited to 64MB of memory and will output a bunch
    of debugging information in your terminal. Port 11211 is the default Memcached
    port. Since the Docker command has the `-it` and `--rm` flags, you’ll be able
    to kill it with Ctrl + C when you’re done and the container will be removed from
    your system.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 此Memcached实例限制为64MB的内存，并将在您的终端中输出大量的调试信息。端口11211是默认的Memcached端口。由于Docker命令具有`-it`和`--rm`标志，当您完成时，可以使用Ctrl
    + C终止它，并且容器将从系统中删除。
- en: When running multiple Memcached instances, the instances themselves aren’t aware
    of each other. Instead, clients connect directly to the different instances and
    use a client-side hashing algorithm to determine which server contains a particular
    key. Ideally, this means each client uses the same server for the same key names,
    but it is possible for different client libraries to decide on different servers
    to store particular keys, which can result in cache misses and data redundancy.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行多个Memcached实例时，实例本身并不知道彼此的存在。相反，客户端直接连接到不同的实例，并使用客户端端哈希算法来确定哪个服务器包含特定的键。理想情况下，这意味着每个客户端对于相同的键名使用相同的服务器，但不同的客户端库可能会决定将特定的键存储在不同的服务器上，这可能会导致缓存未命中和数据冗余。
- en: Caching Data with Memcached
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缓存数据与Memcached
- en: Now that you have your Memcached service running, you’re ready to interact with
    it from a Node.js application. For this example, copy and paste your existing
    *caching/server.js* file that you created in the previous section to *caching/server-ext.js*.
    Next, modify the file to resemble [Example 8-3](#ex_memecached).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您的Memcached服务正在运行，您可以从Node.js应用程序与其进行交互了。对于本示例，请复制并粘贴您在前一节中创建的现有*caching/server.js*文件到*caching/server-ext.js*。接下来，修改文件以类似于[示例 8-3](#ex_memecached)。
- en: Example 8-3\. *caching/server-ext.js*
  id: totrans-186
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例8-3\. *caching/server-ext.js*
- en: '[PRE23]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[![1](assets/1.png)](#co_resilience_CO2-1)'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_resilience_CO2-1)'
- en: Instantiate the Memcached connection.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化Memcached连接。
- en: '[![2](assets/2.png)](#co_resilience_CO2-2)'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_resilience_CO2-2)'
- en: The `.get()` call is now asynchronous.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '`.get()`调用现在也是异步的。'
- en: '[![3](assets/3.png)](#co_resilience_CO2-3)'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_resilience_CO2-3)'
- en: The `.set()` call is also asynchronous.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '`.set()`调用也是异步的。'
- en: A few code changes are needed to migrate the service from an in-memory LRU cache
    to the `memjs` package. The `.get()` and `.set()` arguments for this example follow
    mostly the same signature as the previous LRU cache. The biggest change is that
    the calls are now asynchronous and their results must be awaited. The `.get()`
    method resolves an object with the cached value being a buffer on the `.value`
    property. The `JSON.parse()` method triggers the `.toString()` method on the buffer,
    so an additional data conversion isn’t needed. The `.set()` method requires a
    third, empty *options* object as an argument due to the way the `memjs` package
    performs callback to promise conversion.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 需要对服务进行一些代码更改，以将其从内存LRU缓存迁移到`memjs`包。对于这个例子，`.get()`和`.set()`方法的参数基本与之前的LRU缓存相同。最大的变化在于现在这些调用是异步的，并且它们的结果必须被等待。`.get()`方法解析一个对象，缓存的值在`.value`属性上为一个缓冲区。`JSON.parse()`方法触发缓冲区的`.toString()`方法，因此不需要额外的数据转换。`.set()`方法需要作为参数的第三个空*options*对象，因为`memjs`包执行回调到Promise的转换方式。
- en: 'Now that you have your new service ready, execute two copies of the service
    in two separate terminals. In the first terminal, use the default port of 3000,
    and in the second terminal, override the port to be 4000, like so:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您的新服务已经准备好，在两个单独的终端中执行两个服务的副本。在第一个终端中，使用默认端口3000，在第二个终端中，覆盖端口为4000，如下所示：
- en: '[PRE24]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Next, make a request to both of the services again. Hit the first service twice,
    and then hit the second service:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，再次向这两个服务发出请求。先对第一个服务进行两次请求，然后再对第二个服务进行请求：
- en: '[PRE25]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: In this example, the first request results in a cache miss. The service makes
    the outbound request to GitHub and then fills the cache and returns. In my case,
    this takes about 300ms. Next, the second request to the first service will result
    in a cache hit. The operation takes about 30ms in my case, which is a little slower
    than when I had run the process with just an in-memory LRU cache. Finally, the
    third request to the second service will also result in a cache hit, even though
    that service hasn’t made a request to GitHub. This is because both of the services
    use the same shared Memcached cache entry.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，第一个请求导致缓存未命中。服务向GitHub发出出站请求，然后填充缓存并返回。在我的情况下，这大约需要300ms。接下来，对第一个服务的第二次请求将导致缓存命中。在我的情况下，这个操作大约需要30ms，比我只运行内存LRU缓存的过程稍慢一点。最后，对第二个服务的第三次请求也将导致缓存命中，尽管该服务尚未向GitHub发出请求。这是因为这两个服务都使用了同一个共享的Memcached缓存条目。
- en: That’s it for Memcached! Feel free to clean up your running Node.js services
    and the Memcached server by switching to their terminal windows and pressing Ctrl
    + C.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是关于Memcached的全部内容！随时可以通过切换到它们的终端窗口并按Ctrl + C来清理正在运行的Node.js服务和Memcached服务器。
- en: Data Structure Mutations
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据结构变化
- en: 'Since cached resources may change between releases, it’s sometimes necessary
    to prefix the name of a key with a version number to signify the version of the
    data structure being cached. For example, consider an application that stores
    the following object in a cache:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 由于缓存的资源可能会在发布版本之间发生变化，有时需要在键的名称前缀中加上版本号，以表示被缓存的数据结构的版本。例如，考虑一个将以下对象存储在缓存中的应用程序：
- en: '[PRE26]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Perhaps this representation of the cached entry is used by several different
    versions/releases of an application. Let’s refer to those as *r1..r5*. However,
    for the *r6* release of the application, an engineer decides to change the shape
    of the cached object to be more efficient and to deal with an anticipated migration
    of account IDs from numbers to strings.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 或许这种缓存条目的表示方式被应用程序的几个不同版本/发布所使用。我们将这些版本称为*r1..r5*。然而，对于应用程序的*r6*版本，一个工程师决定改变缓存对象的形状，以使其更高效，并处理账户ID从数字到字符串的预期迁移。
- en: 'The engineer chooses to represent the cached entries like so:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 工程师选择这样表示缓存条目：
- en: '[PRE27]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: In this case, the superfluous wrapper has been removed and the data type of
    the `id` attribute has been changed to a string. By changing the representation
    of the cached entries, something bad will likely happen!
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，多余的包装已被移除，并且`id`属性的数据类型已更改为字符串。通过改变缓存条目的表示方式，可能会发生一些不好的事情！
- en: As an example, assume that the key names of these records in the cache follow
    the pattern `account-info-<ACCOUNT_ID>`. In the case of these two versions of
    the objects, the key would then be `account-info-7`.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设这些记录在缓存中的关键名称遵循模式`account-info-<ACCOUNT_ID>`。在这两个对象版本的情况下，关键名称将是`account-info-7`。
- en: 'The code that reads from the cache in releases *r1..r5* of the application
    looks like this:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 读取应用程序版本 *r1..r5* 中的缓存的代码如下：
- en: '[PRE28]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'However, for release *r6* and onward of the application, the code will have
    been changed slightly to work with the new cached entry:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在应用程序的发布 *r6* 及以后版本中，代码将略有改动以适应新的缓存条目：
- en: '[PRE29]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: This means that when release *r6* of the application is deployed, it will read
    the cache and throw an error stating `account.balance` is undefined. This is because
    existing entries in the cache still have the wrapper object present. In this case,
    you might be tempted to clear the cache before deploying the new release. Unfortunately
    there’s still the risk of *r5* instances writing to the cache after it has been
    cleared and before *r6* instances have been deployed.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着当应用程序的发布 *r6* 部署时，它将读取缓存并抛出错误，声明 `account.balance` 未定义。这是因为缓存中现有条目仍然具有包装对象存在。在这种情况下，您可能会考虑在部署新发布之前清除缓存。不幸的是，在
    *r6* 实例部署之前，仍然存在 *r5* 实例写入缓存的风险。
- en: The easiest way to survive this situation is to modify the names of the cache
    entries to contain a version number representing the object representation version.
    This version number need not resemble the release version of the application.
    In fact, it shouldn’t, because an application is likely to retain the same data
    structure for most objects across most releases. Instead, each resource type should
    get its own new version whenever its representation is changed.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，最简单的生存方式是修改缓存条目的名称，以包含表示对象版本的版本号。这个版本号不需要与应用程序的发布版本相似。事实上，它不应该相似，因为应用程序可能在大多数发布中保持相同的数据结构。相反，每种资源类型在其表示更改时应该获得自己的新版本。
- en: As an example of this, the key name could change from `account-info-<ACCOUNT_ID>`
    to `account-info-<VERSION>-<ACCOUNT_ID>`. In the case of the application release
    changing from *r5* to *r6*, the `account-info` object version may change from
    *v1* to *v2*. This would result in two separate cached entries, one named `account-info-v1-7`
    and one named `account-info-v2-7`. This is convenient because no matter how slow
    the deployment is, two separate application releases won’t have conflicting cache
    data. Unfortunately, it now means that all of the `account-info` objects in the
    cache need to be looked up again.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，键名可以从 `account-info-<ACCOUNT_ID>` 变更为 `account-info-<VERSION>-<ACCOUNT_ID>`。在应用程序从
    *r5* 更改到 *r6* 的情况下，`account-info` 对象版本可能会从 *v1* 变更为 *v2*。这将导致两个单独的缓存条目，一个名为 `account-info-v1-7`，另一个名为
    `account-info-v2-7`。这很方便，因为无论部署多慢，两个单独的应用程序发布不会有冲突的缓存数据。不幸的是，现在意味着需要重新查找缓存中的所有
    `account-info` 对象。
- en: Another solution, instead of changing key names and losing cached values, is
    to “migrate” the data from the old form to the new form. This allows different
    application releases to deal with different representations of cached objects.
    [“Schema Migrations with Knex”](#ch_resilience_sec_migrations) covers this concept
    of migrations in more detail, albeit from the perspective of a relational database.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种解决方案，而不是更改键名并丢失缓存值，是将数据从旧形式“迁移”到新形式。这允许不同的应用程序发布处理缓存对象的不同表示。["Knex 中的模式迁移"](#ch_resilience_sec_migrations)更详细地介绍了这种迁移概念，尽管是从关系数据库的角度来看。
- en: Database Connection Resilience
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据库连接弹性
- en: Node.js applications often maintain a long-lived connection to one or more databases
    so that they may remain stateless. Database connections are usually made through
    a TCP network connection. Unfortunately, those connections will occasionally go
    down. Many different situations can cause connections to drop, such as database
    upgrades, network changes, or even temporary network outages.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: Node.js 应用程序通常维护与一个或多个数据库的长连接，以使其保持无状态。数据库连接通常通过 TCP 网络连接进行。不幸的是，这些连接偶尔会中断。许多不同的情况会导致连接断开，例如数据库升级、网络变更或甚至是暂时的网络中断。
- en: When a connection drops, your application might be dead in the water. Perhaps
    there are some actions that the service can still perform. For example, if there
    is an endpoint to retrieve a resource and the application is still able to connect
    to a caching service but not to the database, then it’s reasonable that requests
    for cached resources should succeed.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 当连接断开时，您的应用程序可能会瘫痪。也许服务仍然可以执行一些操作。例如，如果有一个用于检索资源的端点，并且应用程序仍然可以连接到缓存服务但无法连接到数据库，那么缓存资源的请求应该是合理成功的。
- en: However, when a connection isn’t available, and data must be written to or read
    from the database, your application is going to be in a tricky situation. At this
    point, it might make sense to simply fail the request, such as with a 503 Service
    Unavailable error if using HTTP.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当连接不可用且必须向数据库写入或读取数据时，你的应用程序将陷入棘手的境地。此时，简单地拒绝请求可能是合理的，比如使用 HTTP 503 服务不可用错误。
- en: Running PostgreSQL
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行 PostgreSQL
- en: 'In this section you’re going to use the *PostgreSQL* database. Most of the
    techniques covered herein are supported by other SQL and NoSQL databases alike.
    Postgres is a very powerful and popular database system that you’re likely to
    work with during your career, so it will make for a great guinea pig. Run the
    following command to get Postgres running via Docker:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，你将使用 *PostgreSQL* 数据库。这里介绍的大部分技术同样适用于其他 SQL 和 NoSQL 数据库。Postgres 是一个非常强大和流行的数据库系统，在你的职业生涯中很可能会使用，因此它将成为一个很好的试验对象。运行以下命令通过
    Docker 启动 Postgres：
- en: '[PRE30]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Automatic Reconnection
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动重新连接
- en: The first topic you’re going to work with regarding database connection resilience
    is that of automatically reconnecting to the database. Unfortunately, connections
    will fail from time to time, and it’s convenient for the application to automatically
    reconnect when a failure does happen.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 你将首先学习与数据库连接恢复能力相关的第一个主题，即自动重新连接到数据库。不幸的是，连接有时会失败，当失败发生时，应用程序自动重新连接将是非常方便的。
- en: Theoretically, if a database connection were to fail, then your application
    could terminate itself. Assuming you have infrastructure set up to detect such
    a termination, for example, a health check endpoint, then your Node.js process
    could be automatically restarted. That said, such infrastructure isn’t always
    available to an organization. Another thing to consider is that the overall application
    health isn’t necessarily any better by doing this. For example, if a process terminates
    and takes 10 seconds to fail a health check, then those are 10 seconds’ worth
    of failed requests. If an application loses connection to the database but is
    able to reconnect, that represents a potentially shorter period of downtime. For
    these reasons, developers often choose to implement reconnection logic.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，如果数据库连接失败，你的应用程序可能会终止自身。假设你设置了检测此类终止的基础设施，例如健康检查端点，那么你的 Node.js 进程可以自动重新启动。尽管如此，这样的基础设施并非每个组织都有。另一个需要考虑的是，这样做并不一定会提升整体应用程序的健康状况。例如，如果一个进程终止并花费
    10 秒来失败健康检查，那么这些是失败请求的 10 秒。如果一个应用程序失去了与数据库的连接但能够重新连接，那将代表一个潜在的更短的停机时间。因此，开发者通常选择实现重新连接逻辑。
- en: Not every database package provides the ability to reconnect to a database,
    but the principle is generally the same everywhere. In this section you will build
    out a reconnection module for the `pg` package in a way that can be applied to
    other packages as well.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 并非每个数据库包都提供重新连接到数据库的能力，但原理在各处基本相同。在本节中，你将为 `pg` 包构建一个重新连接模块，这种方式也适用于其他包。
- en: First, you’re going to need to create an application file. This file will resemble
    a fairly typical web application, one that sends SQL queries as part of a request
    handler. But instead of requiring the database package directly, it instead requires
    the reconnection module. Create a new file named *dbconn/reconnect.js* and start
    it off with the content from [Example 8-4](#ex_reconnection_server_1).
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要创建一个应用程序文件。这个文件将类似于一个相当典型的 Web 应用程序，其中一个请求处理程序发送 SQL 查询。但是，它不直接需要数据库包，而是需要重新连接模块。创建一个名为
    *dbconn/reconnect.js* 的新文件，并从 [示例 8-4](#ex_reconnection_server_1) 开始编写其内容。
- en: Example 8-4\. *dbconn/reconnect.js*, part one of two
  id: totrans-229
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-4\. *dbconn/reconnect.js*，第一部分（共两部分）
- en: '[PRE31]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[![1](assets/1.png)](#co_resilience_CO3-1)'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_resilience_CO3-1)'
- en: This loads the `DatabaseReconnection` module from the *db.js* file.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 这加载了来自 *db.js* 文件的 `DatabaseReconnection` 模块。
- en: '[![2](assets/2.png)](#co_resilience_CO3-2)'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_resilience_CO3-2)'
- en: This call kicks off the database connection.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 这个调用启动数据库连接。
- en: '[![3](assets/3.png)](#co_resilience_CO3-3)'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_resilience_CO3-3)'
- en: These overly verbose event listeners are for educational purposes.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 这些过于冗长的事件侦听器仅供教育目的使用。
- en: This file starts off like many applications you have likely written. The `DatabaseReconnection`
    class accepts the same configuration settings that are used by the `pg` package.
    In fact, it passes the connection settings along blindly. The `retry` value is
    specifically going to be used by the reconnection logic that you’ll soon write.
    In this case, it’s configured to retry the database connection every second until
    it succeeds.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 这个文件开始得像您可能已经编写过的许多应用程序一样。`DatabaseReconnection`类接受与`pg`包使用的相同配置设置。实际上，它会盲目地传递连接设置。`retry`值将专门用于您即将编写的重新连接逻辑。在这种情况下，它被配置为每秒重试一次数据库连接，直到成功。
- en: The big list of event listeners isn’t necessary for a production application,
    though the *error* event of course needs to be handled, or else an error will
    be thrown. These are provided to later illustrate how the module goes through
    the reconnection flow.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 对于生产应用程序来说，不需要大量的事件监听器列表，尽管当然需要处理*error*事件，否则将抛出错误。这些事件监听器稍后将用于说明模块如何通过重新连接流程。
- en: The file isn’t quite ready yet as you still need to add some request handlers.
    Add the content from [Example 8-5](#ex_reconnection_server_2) to the file.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 该文件还不完全准备好，因为您仍然需要添加一些请求处理程序。将[示例 8-5](#ex_reconnection_server_2)中的内容添加到文件中。
- en: Example 8-5\. *dbconn/reconnect.js*, part two of two
  id: totrans-240
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-5\. *dbconn/reconnect.js*，第二部分（共两部分）
- en: '[PRE32]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[![1](assets/1.png)](#co_resilience_CO4-1)'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_resilience_CO4-1)'
- en: Basic parameterized query without a table
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 没有表的基本参数化查询
- en: '[![2](assets/2.png)](#co_resilience_CO4-2)'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_resilience_CO4-2)'
- en: An example health endpoint
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 一个示例健康端点
- en: Your web server now has two different HTTP endpoints registered in it. The first
    one, `GET /foo/:foo_id`, makes use of the database connection. In this case, it’s
    running an example query that doesn’t require a table, chosen so that you don’t
    have to create a schema. All it does is show that the database connection is working.
    Within this handler, if the query fails, the call to `db.query()` will reject,
    and the handler will return the error. However, if the database query succeeds,
    it’ll return an object with a `time` and `echo` property.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 您的 Web 服务器现在注册了两个不同的 HTTP 端点。第一个端点`GET /foo/:foo_id`利用了数据库连接。在这种情况下，它运行一个不需要表的示例查询，选择了一个不需要创建模式的示例。它只是展示数据库连接是否正常工作。在此处理程序中，如果查询失败，`db.query()`的调用将被拒绝，并且处理程序将返回错误。但是，如果数据库查询成功，它将返回一个带有`time`和`echo`属性的对象。
- en: The second request handler for `GET /health` is a health endpoint. In this case,
    the endpoint makes use of a property on the `DatabaseReconnection` class instance
    called `.connected`. This is a Boolean property declaring if the connection is
    working or not. In this case, the health endpoint will fail if the connection
    is down and will pass if the connection is up.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 用于`GET /health`的第二个请求处理程序是一个健康端点。在这种情况下，端点利用了`DatabaseReconnection`类实例上的一个属性，称为`.connected`。这是一个布尔属性，声明连接是否正常工作。在这种情况下，如果连接断开，健康端点将失败；如果连接正常，健康端点将通过。
- en: With this, Kubernetes could be configured to hit the health endpoint, perhaps
    every few seconds, and also be configured to restart the service if the endpoint
    fails three times in a row. This would give the application enough time to reestablish
    a connection, allowing the instance to remain running. On the other hand, if the
    connection cannot be established in time, Kubernetes would then kill the instance.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种方法，Kubernetes可以配置以每隔几秒钟击中健康端点，并且还可以配置在端点连续失败三次时重新启动服务。这将给应用足够的时间重新建立连接，使实例保持运行。另一方面，如果连接无法及时建立，Kubernetes将终止该实例。
- en: Once you’ve made these changes to the application file you’re now ready to work
    on the `DatabaseReconnection` class. Create a second file named *dbconn/db.js*
    and start it off by adding the content from [Example 8-6](#ex_reconnection_library_1)
    to it.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您对应用程序文件进行了这些更改，您现在可以开始处理`DatabaseReconnection`类。创建一个名为*dbconn/db.js*的第二个文件，并从[示例
    8-6](#ex_reconnection_library_1)中添加内容开始。
- en: Example 8-6\. *dbconn/db.js*, part one of three
  id: totrans-250
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-6\. *dbconn/db.js*，第一部分（共三部分）
- en: '[PRE33]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The first part of this file isn’t too exciting. Since the module wraps the `pg`
    package, it needs to first require it. A `DatabaseReconnection` class instance
    is an instance of an `EventEmitter`, so the built-in `events` module is loaded
    and extended.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 该文件的第一部分并不是太激动人心。由于该模块包装了`pg`包，因此需要首先引入它。`DatabaseReconnection`类实例是`EventEmitter`的一个实例，因此加载并扩展了内置的`events`模块。
- en: The class depends on four properties. The first three are private properties.
    The first, `client`, is an instance of the `pg.Client` class. This is what handles
    the actual database connection and dispatches queries. The second property is
    `conn`. It contains the database connection object and needs to be stored because
    new connections will need to be created with it. The third property, `kill`, is
    set when the application wants to disconnect from the database server. It’s used
    so that an intentionally closing connection doesn’t attempt to reestablish another
    connection. The final public property, `connected`, tells the outside world if
    the database is connected or not. It won’t necessarily be 100% accurate, because
    a downed connection might not immediately cause the value to change, but it’s
    useful for the health endpoint.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 类依赖于四个属性。前三个是私有属性。第一个是`client`，它是`pg.Client`类的一个实例。这是处理实际数据库连接和分发查询的对象。第二个属性是`conn`。它包含数据库连接对象，并且需要存储，因为新连接将需要使用它。第三个属性是`kill`，当应用程序希望从数据库服务器断开连接时设置。它用于确保意图关闭的连接不会尝试重新建立另一个连接。最后一个公共属性是`connected`，告诉外部世界数据库是否连接。它可能不会百分之百准确，因为断开的连接可能不会立即导致值的变化，但对于健康端点是有用的。
- en: The constructor method accepts the connection object, instantiates the event
    emitter, and then sets the private property. The exciting part won’t happen until
    the connection is actually kicked off.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 构造方法接受连接对象，实例化事件发射器，然后设置私有属性。令人兴奋的部分要等到连接实际启动时才会发生。
- en: Once you’ve finished adding the first set of content to the file, you’re ready
    to move on. Now add the content from [Example 8-7](#ex_reconnection_library_2)
    to the file.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您完成了向文件添加第一组内容，您就可以继续。现在将来自[示例 8-7](#ex_reconnection_library_2)的内容添加到文件中。
- en: Example 8-7\. *dbconn/db.js*, part two of three
  id: totrans-256
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-7。*dbconn/db.js*，三部分之二
- en: '[PRE34]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[![1](assets/1.png)](#co_resilience_CO5-1)'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_resilience_CO5-1)'
- en: Terminate any existing connections.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 终止任何现有连接。
- en: '[![2](assets/2.png)](#co_resilience_CO5-2)'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_resilience_CO5-2)'
- en: Attempt to reconnect when a connection ends.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 当连接结束时尝试重新连接。
- en: This section of the file defines a single `connect()` method and is the most
    complex part of the `DatabaseReconnection` class. Many whitespace atrocities have
    been committed to squeeze the functionality into a small space; feel free to add
    newlines where appropriate.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 文件的这一部分定义了一个名为`connect()`的方法，并且是`DatabaseReconnection`类中最复杂的部分。为了将功能压缩到一个小空间中，已经做了许多空白字符的滥用；在适当的位置添加新行。
- en: When the `connect()` method runs, it first checks to see if a client already
    exists. If so, it ends an existing connection. Next, it checks to see if the `kill`
    flag has been set. This flag is set later within the `disconnect()` method and
    is used to prevent the class from reconnecting after being manually disconnected.
    If the flag is set, then the method returns and no additional work is done.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 当`connect()`方法运行时，首先检查是否已经存在客户端。如果是，则终止现有连接。接下来，它检查是否已设置`kill`标志。此标志稍后在`disconnect()`方法中设置，并用于防止在手动断开连接后重新连接。如果标志已设置，则方法返回，不执行其他工作。
- en: Next, a new database connection is instantiated and set to a variable named
    `client`. The `client.on('error')` call hoists any error calls from the database
    connection to the wrapping class so that the application can listen for them.
    The class also listens for the `end` event. That event is triggered any time the
    database connection closes, including when the connection is manually terminated,
    when there’s a network blip, or when the database dies. In this event handler,
    a `disconnect` event is emitted, the `connection` flag is set to false, and if
    the connection isn’t being manually killed, the `connect()` method is called again
    after the retry period has passed.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，实例化一个新的数据库连接，并将其设置为名为`client`的变量。`client.on('error')`调用将来自数据库连接的任何错误调用提升到包装类，以便应用程序可以监听它们。该类还监听`end`事件。该事件在数据库连接关闭时触发，包括手动终止连接、网络中断或数据库死机时。在此事件处理程序中，会发出`disconnect`事件，将`connection`标志设置为false，并且如果连接不是手动杀死的，将在重试周期过后再次调用`connect()`方法。
- en: After that, the database connection is attempted. The `connected` flag is set
    to true if the connection succeeds and false if it fails. It also emits a `connect`
    event upon success. The underlying `pg` package emits an `end` event if the connection
    fails to be made, which is why this event handler doesn’t call the `connect()`
    method.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 随后，尝试数据库连接。如果连接成功，则设置`connected`标志为true，失败则为false。同时在成功时会触发一个`connect`事件。如果连接失败，底层的`pg`包会发出一个`end`事件，这就是为什么这个事件处理程序不调用`connect()`方法的原因。
- en: Finally, the `client` is assigned as a class attribute, and the `reconnect`
    event is emitted.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`client`被分配为类属性，并发出了`reconnect`事件。
- en: Once you’ve saved those changes, you’re ready for the final part of the file.
    Add [Example 8-8](#ex_reconnection_library_3) to the end of the file.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 保存这些更改后，你已经准备好文件的最后部分了。在文件末尾添加 [示例 8-8](#ex_reconnection_library_3)。
- en: Example 8-8\. *dbconn/db.js*, part three of three
  id: totrans-268
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-8\. *dbconn/db.js*，三部分中的第三部分
- en: '[PRE35]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: This part of the file exposes two more methods. The first one is the `query()`
    method, which for the most part passes the query along to the encapsulated `pg.Client`
    instance. However, if it knows the connection isn’t ready, or if it knows the
    connection is being killed, it will reject the call with an error. Note that this
    method doesn’t properly support the entire `pg.Client#query()` interface; be sure
    to spruce it up if you use it in a real project.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 文件的这一部分暴露了另外两个方法。第一个是`query()`方法，大部分情况下将查询传递给封装的`pg.Client`实例。然而，如果它知道连接没有准备好，或者知道连接正在被关闭，它将拒绝带有错误的调用。请注意，这个方法并没有完全支持整个`pg.Client#query()`接口；如果在实际项目中使用，请加以改进。
- en: The `disconnect()` method sets the `kill` flag on the class and also instructs
    the underlying `pg.Client` connection to terminate by calling its `.end()` method.
    That `kill` flag is needed to distinguish between the `end` event triggered by
    this manual disconnection versus an `end` event triggered by a connection failure.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '`disconnect()`方法设置类的`kill`标志，并通过调用其`.end()`方法指示底层的`pg.Client`连接终止。这个`kill`标志需要区分手动断开连接触发的`end`事件与连接失败触发的`end`事件。'
- en: Finally the class is exported. Note that if you were to build such a reconnection
    library for other database packages, then it would make sense to expose any other
    methods the application needs to access.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，类被导出。请注意，如果你要为其他数据库包构建这样的重新连接库，那么暴露应用程序需要访问的任何其他方法都是有意义的。
- en: Note
  id: totrans-273
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: This database reconnection module isn’t necessarily ready for production. Depending
    on the package you use it to encapsulate, there may be other error conditions
    as well. As with any database connection library, it would be wise to experiment
    and reproduce many of the different failure cases.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据库重连模块不一定适用于生产环境。根据你用它封装的包，可能还有其他错误情况。与任何数据库连接库一样，最好进行实验并复现许多不同的失败情况。
- en: 'Once the file is complete, be sure to initialize a new npm project and to install
    the required dependencies. Then, execute the *reconnect.js* Node.js service. Once
    your service is running, you may send it a request to confirm that it is connected
    to the database:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦文件完成，确保初始化一个新的 npm 项目并安装所需的依赖项。然后，执行 *reconnect.js* Node.js 服务。一旦服务运行起来，你可以发送请求确认它连接到了数据库：
- en: '[PRE36]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: In this case, you should get a successful response back from the server. The
    result I receive is printed on the second line. That timestamp was calculated
    by the Postgres service, not the Node.js application.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，你应该从服务器那里得到一个成功的响应。我收到的结果打印在第二行。该时间戳由 Postgres 服务计算，而不是 Node.js 应用程序。
- en: Now that you’ve confirmed your Node.js service is able to speak to the database,
    it’s time to sever the connection. In this case, you’re going to take down the
    entire Postgres database. Switch to the terminal window running Postgres and kill
    it by pressing Ctrl + C.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 现在确认了你的 Node.js 服务能够与数据库通信，是时候断开连接了。在这种情况下，你要关闭整个 Postgres 数据库。切换到运行 Postgres
    的终端窗口，按 Ctrl + C 来关闭它。
- en: 'You should now see the following messages in the terminal running your Node.js
    service:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你应该在运行 Node.js 服务的终端看到以下消息：
- en: '[PRE37]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: The first connected message was displayed when the process first started. The
    two error messages and the disconnected message are displayed immediately after
    the Node.js service detected the disconnection. Finally, the reconnecting messages
    are displayed, once per second, as the service attempts to reconnect.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 当进程首次启动时，显示了第一个连接成功的消息。当Node.js服务检测到断开连接时，立即显示了两个错误消息和断开连接的消息。最后，重连消息每秒显示一次，因为服务尝试重新连接。
- en: 'At this point, your application is in a degraded state. But the service is
    still running. Make two new requests to the service, the first to the same endpoint
    and the second to the health endpoint:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，您的应用程序处于降级状态。但服务仍在运行。向服务发出两个新请求，第一个请求相同的端点，第二个请求健康端点：
- en: '[PRE38]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: In this case, both of the endpoints are failing. The first endpoint fails when
    it attempts to make a database query, and the second fails since the `connected`
    flag on the database connection is set to false. However, if the application supported
    other endpoints that didn’t rely on the database connection, they could still
    succeed.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，两个端点都失败了。第一个端点在尝试进行数据库查询时失败，第二个端点因为数据库连接的`connected`标志被设置为假而失败。然而，如果应用程序支持不依赖于数据库连接的其他端点，它们仍然可以成功。
- en: 'Finally, switch back to the terminal window where you killed the Postgres database
    and start it again. The container should start relatively quickly since the Docker
    images have already been downloaded to your machine. Once the Postgres database
    is back up, your Node.js service should establish a new connection. The logs that
    are displayed when I run the service looks like this:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，切换回您杀死Postgres数据库的终端窗口，并重新启动它。由于Docker镜像已经下载到您的机器上，容器应该会相对快速地启动。一旦Postgres数据库恢复正常，您的Node.js服务应该建立一个新的连接。运行服务时显示的日志如下：
- en: '[PRE39]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: In this case, my Node.js service was able to reconnect to the Postgres database
    again. Run the `curl` commands a final time and you should get passing responses
    again.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我的Node.js服务能够重新连接到Postgres数据库。最后再次运行`curl`命令，您应该会再次获得通过的响应。
- en: Connection Pooling
  id: totrans-288
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 连接池
- en: Another way to increase the resilience of your application’s database connection
    is to use more than one connection, or as it’s better known, use a pool of connections.
    With regards to resilience, if a single one of the connections were to fail, then
    another connection would remain open.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 提高应用程序数据库连接的弹性的另一种方法是使用多个连接，或者更为人熟知的连接池。在弹性方面，如果其中一个连接失败，那么另一个连接仍将保持打开状态。
- en: When configured to use connection pools, an application will typically try to
    maintain a certain number of connections. When a connection goes down, the application
    attempts to create a new connection to compensate. When the application chooses
    to run a database query, it will then pick one of the available connections in
    the pool to pass the query through.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 当配置使用连接池时，应用程序通常会尝试维护一定数量的连接。当一个连接断开时，应用程序会尝试创建一个新连接来进行补偿。当应用程序选择运行数据库查询时，它会从连接池中选择一个可用的连接来传递查询。
- en: Most database packages seem to support some form of connection pooling by default.
    The popular `pg` package used in these examples is no exception. The `pg.Pool`
    class is available and can mostly be swapped out with `pg.Client`, though it does
    have a few different configuration options and exposes some new properties.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数数据库包似乎默认支持某种形式的连接池。这些示例中使用的流行`pg`包也不例外。`pg.Pool`类可用，并且大多数情况下可以与`pg.Client`交换，尽管它具有一些不同的配置选项并公开一些新属性。
- en: Create a new file named *dbconn/pool.js* and add the content in [Example 8-9](#ex_pooling_server)
    to it.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个名为*dbconn/pool.js*的新文件，并将[示例 8-9](#ex_pooling_server)的内容添加到其中。
- en: Example 8-9\. *dbconn/pool.js*
  id: totrans-293
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-9\. *dbconn/pool.js*
- en: '[PRE40]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The connection establishment is mostly the same, but in this case, a property
    named `max` has been added. This property represents the maximum number of connections
    that the process should have to the Postgres database. In this case, it’s pulling
    the value from the `MAX_CONN` environment variable or falling back to 10 if it’s
    missing. Internally, the `pg.Pool` class also defaults to a connection pool size
    of 10.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 连接建立在大多数情况下是相同的，但在这种情况下，添加了一个名为`max`的属性。该属性表示进程应该与Postgres数据库建立的最大连接数。在这种情况下，它从`MAX_CONN`环境变量中获取值，如果缺少则默认为10。在内部，`pg.Pool`类也默认使用大小为10的连接池。
- en: How many connections should your application use? The best way to determine
    that is to run some real-world benchmarks in a production setting, generating
    traffic at a certain request rate and seeing how many connections it takes to
    maintain your desired throughput. Perhaps you’ll find that the default 10 works
    for you. At any rate, you should try to use the lowest number of database connections
    that will work to reach your performance needs. Keeping this number low is important
    for a few reasons.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序应该使用多少连接？确定最佳方式是在生产环境中运行一些真实的基准测试，以某种请求速率生成流量，并查看维持所需吞吐量所需的连接数量。也许你会发现默认的
    10 个连接对你来说有效。无论如何，你应该尽量使用最少数量的数据库连接来满足性能需求。保持这个数字低对于几个原因都很重要。
- en: One reason to minimize database connections is that there is a finite number
    of connections that a database will accept. In fact, the default number of connections
    that a Postgres database will accept is 100\. This number can be configured per
    database server. Managed Postgres installations like AWS RDS have different connection
    limitations based on tier.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 减少数据库连接的一个原因是，数据库能够接受的连接数量是有限的。事实上，Postgres 数据库默认接受的连接数量是 100。这个数字可以针对每个数据库服务器进行配置。像
    AWS RDS 这样的托管 Postgres 安装根据服务等级有不同的连接限制。
- en: 'If you go over the number of available connections, then the Postgres database
    server will refuse subsequent connections. This is something that you can simulate
    locally. The Postgres server that you’re running in Docker should be configured
    to have a maximum of 100 connections. Run the following commands in two separate
    terminal windows. The first will run the *dbconn/pool.js* service using up to
    100 connections, and the second will hit the service with so many requests that
    it’ll be forced to use the entire connection pool:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 如果超过可用连接数，那么 Postgres 数据库服务器将拒绝后续连接。这是你可以在本地模拟的情况。你正在 Docker 中运行的 Postgres 服务器应配置为最多
    100 个连接。在两个单独的终端窗口中运行以下命令。第一个将使用多达 100 个连接运行 *dbconn/pool.js* 服务，第二个将向服务发送如此多的请求，以至于它将被迫使用整个连接池：
- en: '[PRE41]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Keep an eye on the terminal window where you’re running Postgres. While the
    tests run, you shouldn’t see anything bad happening.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 注意运行 Postgres 的终端窗口。在测试运行时，不应该看到任何不良反应。
- en: 'Kill the Node.js service once the Autocannon test is complete. Next, run the
    *dbconn/pool.js* service a second time, but this time using a pool size greater
    than what the server is configured to handle, and run the same Autocannon benchmark
    again:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 完成 Autocannon 测试后终止 Node.js 服务。接下来，再次运行 *dbconn/pool.js* 服务，但这次使用比服务器配置的池大小更大，并再次运行相同的
    Autocannon 基准测试：
- en: '[PRE42]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'This time, you should see the Postgres server complain with “FATAL: sorry,
    too many clients already” errors. Once the Autocannon test is complete, you should
    even see that the throughput is slightly lower.'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '这次，你应该看到 Postgres 服务器出现“FATAL: sorry, too many clients already”错误。一旦 Autocannon
    测试完成，甚至可能会发现吞吐量略有下降。'
- en: 'If you would like to know how many connections a particular Postgres database
    is configured to handle (for example, when using a managed instance) run the following
    query:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想知道特定 Postgres 数据库配置为处理多少连接（例如在使用托管实例时），运行以下查询：
- en: '[PRE43]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The maximum number of connections can be increased, but there is at least a
    small amount of overhead required for the server to handle the connections. If
    not, the default would be infinity. When choosing a connection count, you’ll probably
    need to make sure the number of connections used per process multiplied by the
    number of processes running at once is less than half of the number of connections
    the Postgres server can handle. This half part is important because if you deploy
    a new set of processes to replace the old processes, then there’s a small amount
    of time where both the new and old instances need to run with overlap.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 最大连接数可以增加，但服务器处理连接需要至少一定的开销。如果不这样，那么默认将是无限制的。选择连接数量时，你可能需要确保每个进程使用的连接数乘以同时运行的进程数量小于
    Postgres 服务器可以处理的连接数的一半。这一半很重要，因为如果部署新的进程集来替换旧的进程，则新旧实例需要重叠运行的时间非常短。
- en: 'So, if your server has a maximum of 100 connections available and you’re running
    6 service instances, then the maximum number of connections each process can make
    is 8:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的服务器最多允许 100 个连接，并且你运行了 6 个服务实例，那么每个进程可以使用的最大连接数是 8：
- en: '[PRE44]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: One tactic I’ve seen at companies is that they’ll scale up beyond this maximum
    number of processes (like scaling up to 10 processes consuming a total of 80 connections).
    But when it’s time to do a deployment, they’ll scale back down the safe number
    of instances (6 in this case) during off periods, do a deployment, and then scale
    back up. While I can’t necessarily recommend this approach, I’d be lying if I
    said I wasn’t guilty of it myself.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 我在一些公司见过的一种策略是，它们会超过最大进程数量（比如扩展到使用总共 80 个连接的 10 个进程）。但在部署时，他们会在低谷期间将实例的安全数量缩减回来（在本例中为
    6），进行部署，然后再扩展。虽然我不能完全推荐这种方法，但如果说我从未做过这样的事情，那我就是在说谎。
- en: Note
  id: totrans-310
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: One thing to be careful of, especially with Node.js projects, is requiring a
    database singleton module. In my experience, it’s pretty common to have a file
    require a database package, make the connection, and export the database instance.
    It’s also very easy for a spiderweb of `require()` statements to require such
    a module. This can result in sidecar processes making unnecessary connections
    with no visibility that such a connection was made.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是在 Node.js 项目中，有一件需要小心的事情就是要求一个数据库单例模块。根据我的经验，有一个文件需要一个数据库包，建立连接，并导出数据库实例是很常见的。`require()`语句非常容易形成一个这样的模块的蜘蛛网。这可能导致旁路进程进行不必要的连接，而且无法看到进行了这样的连接。
- en: Connection pooling isn’t just about resilience; it’s also about performance.
    The Postgres database, for example, isn’t able to handle multiple queries sent
    through the same connection at the same time. Instead, each query needs to finish
    before the following query can be sent, serially.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 连接池不仅仅关乎弹性，也关乎性能。例如，Postgres 数据库无法处理通过同一连接发送的多个查询。相反，每个查询都需要在下一个查询发送之前完成，逐个串行处理。
- en: This serial processing of queries can be seen in [Example 8-10](#ex_database_serial).
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 这种查询的串行处理可以在[示例 8-10](#ex_database_serial)中看到。
- en: Example 8-10\. *dbconn/serial.js*
  id: totrans-314
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-10\. *dbconn/serial.js*
- en: '[PRE45]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[![1](assets/1.png)](#co_resilience_CO6-1)'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_resilience_CO6-1)'
- en: Two slow queries are sent at the same time.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 同时发送两个较慢的查询。
- en: This application makes a single connection to the Postgres database and then
    sends two requests at the same time. Each of the requests is making use of the
    `pg_sleep()` function, which, in this case, will cause the connection to pause
    for two seconds, simulating a slow query. When I run this application locally,
    I get the message “took 4.013 seconds” as a response.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 该应用程序首先与 Postgres 数据库建立单个连接，然后同时发送两个请求。每个请求都使用`pg_sleep()`函数，这在本例中将导致连接暂停两秒，模拟较慢的查询。当我在本地运行该应用程序时，我会得到“耗时
    4.013 秒”的响应消息。
- en: Modify the [Example 8-10](#ex_database_serial) code by replacing the two occurrences
    of `Client` with `Pool` and run the application again. This results in a pool
    with a maximum size of 10\. The `pg` package uses two of those connections to
    run the two queries. On my machine, the program now prints the message “took 2.015
    seconds.”
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将两个`Client`替换为`Pool`并重新运行应用程序来修改[示例 8-10](#ex_database_serial)代码。这将导致一个最大大小为10的连接池。`pg`包使用这两个连接来运行两个查询。在我的机器上，程序现在打印出消息“耗时
    2.015 秒”。
- en: Schema Migrations with Knex
  id: totrans-320
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Knex 进行模式迁移
- en: Knex is a popular SQL query builder package. It’s relied upon by many higher-level
    ORM (Object-Relational Mapping) packages. If you’ve worked on a few Node.js projects
    that interact with an SQL database, then chances are good that you have come into
    contact with Knex at some point.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: Knex 是一个流行的 SQL 查询构建器包。它被许多高级 ORM（对象关系映射）包所依赖。如果您曾经在与 SQL 数据库交互的几个 Node.js 项目上工作过，那么很可能您曾经接触过
    Knex。
- en: While Knex is usually heralded for its ability to generate SQL queries (reducing
    the need to dangerously concatenate SQL strings together), the functionality covered
    in this section is that of its lesser-known [schema migration](https://knexjs.org/#Migrations)
    features.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 Knex 通常以其生成 SQL 查询的能力而闻名（减少危险地连接 SQL 字符串的需求），但本节介绍的功能是其较少人知的[模式迁移](https://knexjs.org/#Migrations)特性。
- en: A *schema migration* is a change that is made to a database schema in a way
    that is incremental, reversible, and can be represented using code that can be
    checked into version control. Since application data storage requirements change
    all the time, such schema migrations need to be incremental. Each new feature
    may be represented by one or more migrations. Since application changes occasionally
    need to be rolled back, these schema migrations must be reversible as well. Finally,
    since a repository should be the source of truth for representing an application,
    it’s incredibly convenient to check in schema migrations.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '*模式迁移*是以一种递增、可逆和可以使用代码表示的方式对数据库模式进行的更改。由于应用程序数据存储需求不断变化，这些模式迁移需要是递增的。每个新功能可能由一个或多个迁移表示。由于偶尔需要回滚应用程序更改，这些模式迁移也必须是可逆的。最后，由于存储库应该是表示应用程序的真实来源，因此将模式迁移检入存储库非常方便。'
- en: 'Each schema migration ultimately executes SQL queries to alter the state of
    the database. Often a later migration will build upon a change made in an earlier
    migration. For this reason, the order in which database migrations are applied
    matters greatly. The most basic approach to building out database migrations could
    be to maintain a list of numbered SQL files and to execute them one after another,
    with paired SQL files for reversing the changes:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 每个模式迁移最终都会执行SQL查询来改变数据库的状态。通常，后续的迁移会在先前迁移中所做的更改基础上构建。因此，数据库迁移的应用顺序非常重要。构建数据库迁移的最基本方法可能是维护一个编号的SQL文件列表，并依次执行它们，配对的SQL文件用于撤销更改：
- en: '[PRE46]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: One problem with this approach is that the filenames aren’t all that descriptive.
    Which file accidentally turned all users into administrators? Another problem
    is a race condition between two people making code changes. When two engineers
    create a file named *000004.sql* in two separate pull requests, the second branch
    to be merged needs to modify the commit to rename the file to *000005.sql*.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的一个问题是文件名并不十分描述性。哪个文件不小心把所有用户变成了管理员？另一个问题是两个人同时进行代码更改可能导致的竞争条件。当两个工程师在两个单独的拉取请求中创建了名为*000004.sql*的文件时，后合并的分支需要修改提交以将文件重命名为*000005.sql*。
- en: 'A common migration approach, the same employed by Knex, is to instead use a
    timestamp and a feature name as the name of the file. This maintains order, solves
    the issue with name collisions, gives the file a descriptive name, and even lets
    the developer know when the schema migration was first conceived. Wrapping the
    queries in a non-SQL file allows for combining the migration and reverse migration.
    These migration filenames end up looking like this:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常见的迁移方法，与Knex采用相同的方式，是使用时间戳和特征名称作为文件名。这样做可以保持顺序，解决名称冲突的问题，给文件起一个描述性的名称，甚至让开发者知道模式迁移最初的概念时间。将查询包装在非SQL文件中允许结合迁移和反向迁移。这些迁移文件名看起来像这样：
- en: '[PRE47]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: An entire list of migrations doesn’t need to be applied every time a new version
    of the application is checked out. Instead, only migrations that are newer than
    the last migration that was run need to be applied. Knex, and most other schema
    migration tools, tracks which migrations are run in a special database table.
    The only thing that makes the table special is that the application itself will
    probably never touch it. Such a table can be as simple as a single row with a
    “last schema filename run” column or as complex as containing meta information
    about each time migrations are run. The important part is that it maintains some
    sort of reference to the last-run migration. The default name of this table in
    Knex is `knex_migrations`.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 每次检出应用程序的新版本时，并不需要应用整个迁移列表。相反，只需要应用比上次运行的迁移更新的迁移。Knex和大多数其他模式迁移工具在一个特殊的数据库表中跟踪运行的迁移。使表格特殊的唯一之处是应用程序本身可能永远不会触及它。这样的表格可以简单到只有一行，包含“上次运行的模式文件名”列，也可以复杂到包含每次运行迁移的元信息。重要的是它保持对最后一次运行迁移的某种引用。在Knex中，这个表的默认名称是`knex_migrations`。
- en: When doing development as part of a team for an application that uses database
    migrations, the workflow often requires that you frequently pull source code from
    the central repository. If any changes are committed to a schema migration directory,
    you’ll then need to apply some schema modifications. If you don’t do that, then
    the newer application code may be incompatible with your older database schema,
    resulting in runtime errors. Once you apply the migrations locally, you’re then
    free to make modifications of your own.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发团队中作为使用数据库迁移的应用程序的一部分进行开发时，工作流程通常要求您经常从中央仓库拉取源代码。如果对模式迁移目录提交了任何更改，那么您随后需要应用一些模式修改。如果不这样做，那么更新后的应用程序代码可能与旧的数据库模式不兼容，导致运行时错误。一旦在本地应用了迁移，您就可以自由进行自己的修改了。
- en: Now that you’re familiar with the theory behind schema migrations, you’re ready
    to write some of your own.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经了解了模式迁移背后的理论，可以开始编写您自己的模式迁移了。
- en: Configuring Knex
  id: totrans-332
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置Knex
- en: 'First, create a new directory named *migrations/* to represent a new application
    that will use migrations and initialize a new npm project. Next, install the `knex`
    package in this directory. For ease of running the migration scripts, you also
    need `knex` installed as a global package—this isn’t required for a regular application
    where you might wrap the locally installed Knex with *package.json* scripts, but
    it will make things more convenient for now.^([6](ch08.html#idm46291177027288))
    Finally, initialize a Knex project, which creates a configuration file for you.
    This can all be done by running the following commands:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，创建一个名为*migrations/*的新目录，表示将使用迁移的新应用程序，并初始化一个新的npm项目。接下来，在此目录中安装`knex`包。为了方便运行迁移脚本，您还需要将`knex`作为全局包安装——这在常规应用程序中并非必需，您可以在本地安装的Knex周围使用*package.json*脚本包装它，但目前这样做会更方便。^([6](ch08.html#idm46291177027288))
    最后，初始化一个Knex项目，这将为您创建一个配置文件。您可以通过运行以下命令来完成所有这些操作：
- en: '[PRE48]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Knex created a file for you named *knexfile.js*, which is used by the `knex`
    CLI utility to connect to your database. The file contains configuration and could
    be represented with a declarative format like YAML, but it’s common to pull in
    environment variables, which is why JavaScript is the default format. Open the
    file with a text editor to view its content. The file currently exports a single
    object with keys representing environment names and values representing configuration.
    By defaul, the *development* environment uses *SQLite*, while the *staging* and
    *production* databases are set to Postgres.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: Knex为您创建了一个名为*knexfile.js*的文件，该文件被`knex` CLI实用程序用于连接数据库。该文件包含配置，并且可以用像YAML这样的声明格式来表示，但通常会引入环境变量，这就是为什么JavaScript是默认格式的原因。打开文本编辑器查看文件内容。该文件当前导出一个表示环境名称的键和表示配置的值的单个对象。默认情况下，*development*环境使用SQLite，而*staging*和*production*数据库设置为Postgres。
- en: By having different environments defined within *knexfile.js*, you’re able to
    apply migrations to database servers across those different environments. For
    this project, you’re only going to use a single *development* configuration. Modify
    your *migrations/knexfile.js* file to resemble [Example 8-11](#ex_migration_knexfile).
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在*knexfile.js*中定义不同的环境，您可以将迁移应用到这些不同环境的数据库服务器上。对于此项目，您只会使用单个*development*配置。修改您的*migrations/knexfile.js*文件，使其类似于[示例 8-11](#ex_migration_knexfile)。
- en: Example 8-11\. *migrations/knexfile.js*
  id: totrans-337
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-11\. *migrations/knexfile.js*
- en: '[PRE49]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Once that’s done, you’re ready to test the database connections. Run the following
    command:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，您可以测试数据库连接了。运行以下命令：
- en: '[PRE50]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: The command displays the environment being used. (It defaults to *development*
    but can be overwritten using the `NODE_ENV` environment variable.) It also displays
    the migration version, which in this case is `none`. If you get an error, you
    may need to either modify the connection file or go back and run the Docker command
    to start Postgres, defined in [“Running PostgreSQL”](#ch_resilience_sec_db_subsec_runpg).
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令显示正在使用的环境。（默认为*development*，但可以使用`NODE_ENV`环境变量进行覆盖。）它还显示迁移版本，在本例中为`none`。如果出现错误，您可能需要修改连接文件，或者返回并运行定义在[“运行PostgreSQL”](#ch_resilience_sec_db_subsec_runpg)中的Docker命令以启动Postgres。
- en: Creating a Schema Migration
  id: totrans-342
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建模式迁移
- en: 'Now that you’re able to connect to the database, it’s time to create your first
    schema migration. In this case, the migration is going to create a *users* table
    in the database. Run the following commands to create the migration and then to
    view a list of migrations:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以连接到数据库了，是时候创建你的第一个模式迁移了。在这种情况下，迁移将在数据库中创建一个*users*表。运行以下命令创建迁移，然后查看迁移列表：
- en: '[PRE51]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: The `knex migrate:make` command has created a new *migrations/* directory, which
    is what Knex uses for keeping track of the schema migration files. It also generated
    a schema migration file for you. In my case, the name of the migration file is
    *20200525141008_create_users.js*. Yours will have a more recent date as part of
    the filename.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '`knex migrate:make`命令已经创建了一个新的*migrations/*目录，这是Knex用于跟踪模式迁移文件的目录。它还为你生成了一个模式迁移文件。在我的情况下，迁移文件的名称是*20200525141008_create_users.js*。你的文件名将包含一个更新的日期作为一部分。'
- en: Next, modify your schema migration file to contain the content displayed in
    [Example 8-12](#ex_migration_sql_migrate_up).
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，修改你的模式迁移文件，使其包含在[示例 8-12](#ex_migration_sql_migrate_up)中显示的内容。
- en: Example 8-12\. *migrations/migrations/20200525141008_create_users.js*
  id: totrans-347
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-12\. *migrations/migrations/20200525141008_create_users.js*
- en: '[PRE52]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: By default, schema migrations export two functions, one named `up()` and one
    named `down()`. In this case, you’re still exporting the two functions, albeit
    with slightly more modern JavaScript syntax. The `up()` method is called when
    a schema is being applied, and the `down()` method is called when it’s being “reversed”
    or “rolled back.”
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，模式迁移导出两个函数，一个名为`up()`，另一个名为`down()`。在这种情况下，仍然导出这两个函数，尽管使用了稍微现代化的JavaScript语法。当应用模式时，将调用`up()`方法；当“回滚”或“撤销”模式时，将调用`down()`方法。
- en: The two methods make use of the Knex query builder interface for creating and
    dropping tables. The table being created is named *users* and has two columns,
    *id* and *username*. The query builder syntax used by Knex pretty cleanly maps
    to the underlying SQL query that is sent to the database. The `up()` method also
    inserts three users into the table.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个方法利用Knex查询构建器接口来创建和删除表格。正在创建的表格名为*users*，有两列，*id*和*username*。Knex使用的查询构建器语法相对清晰地映射到发送到数据库的底层SQL查询。`up()`方法还向表格中插入了三个用户。
- en: The `down()` method performs the opposite operation. Technically, since the
    `up()` method performed two operations (creating a table and then adding users),
    the `down()` method should mirror those operations (deleting the users and destroying
    a table). But since dropping a table implicitly destroys the entries in it, the
    `down()` method only needs to drop the *users* table.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: '`down()`方法执行相反的操作。从技术上讲，由于`up()`方法执行了两个操作（创建表和添加用户），`down()`方法应镜像这些操作（删除用户并销毁表）。但由于删除表会隐式销毁其中的条目，因此`down()`方法只需删除*users*表。'
- en: 'Next, run the following command to get a list of the migrations that Knex is
    currently aware of:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，运行以下命令获取Knex当前已知的迁移列表：
- en: '[PRE53]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: In this case, a single migration exists and has not yet been applied.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，存在一个未应用的单一迁移。
- en: Applying a Migration
  id: totrans-355
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用迁移
- en: 'Now that your migration is ready, it’s time to run it. Run the following command
    to apply the migration:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你的迁移准备就绪，是时候运行它了。运行以下命令来应用迁移：
- en: '[PRE54]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: The `knex migrate:up` applies the next migration in line based on the order
    of migration filenames. In this case, there was only a single migration to be
    made.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: '`knex migrate:up`会根据迁移文件名的顺序应用下一个迁移。在这种情况下，只有一个要执行的迁移。'
- en: 'Now that your migration has been executed, you should take a look at the database
    schema to confirm that it worked. Execute the following command to run the `psql`
    command inside of the Postgres Docker container:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，执行以下命令在Postgres Docker容器内部运行`psql`命令，确认你的迁移已经执行：
- en: '[PRE55]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'When prompted, enter the password **`hunter2`** and press enter. Once that’s
    done, you’re now using an interactive Postgres terminal client. Commands entered
    in this client will take place in the *dbconn* database. For now, it would be
    useful to get a list of the tables stored in the database. Within the prompt,
    type **`\dt`** to do just that. When I run that command on my machine, I get the
    following results:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 在提示时，输入密码 **`hunter2`** 然后按回车键。完成后，你现在正在使用一个交互式的Postgres终端客户端。在此客户端中输入的命令将在*dbconn*数据库中执行。现在，获取数据库中存储的表格列表将非常有用。在提示符内，输入
    **`\dt`** 就可以做到这一点。在我的机器上运行该命令时，我得到以下结果：
- en: '[PRE56]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The `users` entry refers to the users table that was created when you ran the
    database migration. Next, to see the entries inside this table, type the command
    **`SELECT * FROM users;`** and press enter again. You should see results like
    these:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: '`users`条目指的是在运行数据库迁移时创建的用户表。接下来，要查看此表内的条目，请键入命令**`SELECT * FROM users;`**，然后再次按回车。您应该看到类似于这样的结果：'
- en: '[PRE57]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: In this case, the three users that were created as part of the migration script
    are displayed.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，作为迁移脚本的一部分创建的三个用户被显示。
- en: 'The Knex query builder has converted the query that you represented by chaining
    JavaScript object methods into an equivalent SQL query. In this case, the table
    that is generated inside of the database could have been created by using the
    following SQL query:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: Knex查询构建器已将您通过链式JavaScript对象方法进行的查询转换为等效的SQL查询。在这种情况下，生成在数据库内部的表可以通过以下SQL查询创建：
- en: '[PRE58]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'While you’re still running the Postgres client, it’s worth taking a look at
    the migrations table that Knex also created. Run another query, **`SELECT * FROM
    knex_migrations;`**, and press enter. On my machine, I get the following results
    back:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 当您仍在运行Postgres客户端时，不妨查看Knex创建的迁移表。再运行另一个查询，**`SELECT * FROM knex_migrations;`**，然后按回车。在我的机器上，我得到了以下结果：
- en: '[PRE59]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: In this case, the *20200525141008_create_users.js* migration is the only migration
    that has been executed. Some additional meta information about the query is also
    stored. Since migration information is stored in a database, any developer would
    be able to run additional migrations for a remote database host, such as a production
    database, without the need to keep track of which migrations had been run previously.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，唯一执行的迁移是*20200525141008_create_users.js*。还存储了有关查询的一些附加元信息。由于迁移信息存储在数据库中，任何开发人员都可以为远程数据库主机（如生产数据库）运行额外的迁移，而无需跟踪先前运行了哪些迁移。
- en: The other table, `knex_migrations_lock`, isn’t as interesting. It’s used to
    create a lock so that multiple people don’t attempt to run migrations simultaneously,
    which could result in a corrupted database.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个表`knex_migrations_lock`则没有那么有趣。它用于创建锁定，以防多人同时尝试运行迁移，这可能会导致数据库损坏。
- en: 'The only thing more exciting than one migration is two migrations, so go ahead
    and create another one. This second migration builds on the changes made in the
    first migration. Again, run a command to create a new migration file:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 令人兴奋的不止一次迁移，你可以创建另一个迁移。第二次迁移建立在第一次迁移的基础之上。再次运行命令创建新的迁移文件：
- en: '[PRE60]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Next, modify the migration file that was created. Make the file resemble the
    code in [Example 8-13](#ex_migration_sql_migrate_up2).
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，修改已创建的迁移文件。使文件类似于[示例 8-13](#ex_migration_sql_migrate_up2)中的代码。
- en: Example 8-13\. *migrations/migrations/20200525172807_create_groups.js*
  id: totrans-375
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-13\. *migrations/migrations/20200525172807_create_groups.js*
- en: '[PRE61]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: This time, raw queries are being executed instead of using the query builder.
    Both approaches are fine when representing schema migrations. In fact, some queries
    may be difficult to represent using the query builder and may be better served
    by using raw query strings.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 这一次，执行的是原始查询，而不是使用查询构建器。在表示架构迁移时，这两种方法都可以。事实上，某些查询可能难以使用查询构建器表示，并且最好通过使用原始查询字符串来处理。
- en: This query creates an additional table named `groups` and also alters the `users`
    table to have a `group_id` column that references the `groups` table. In this
    case, the second migration absolutely depends on the first migration.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 此查询创建了一个名为`groups`的额外表，并且还修改了`users`表，使其具有引用`groups`表的`group_id`列。在这种情况下，第二次迁移绝对依赖于第一次迁移。
- en: 'Now that your second migration is ready, go ahead and apply it. This time,
    you’re going to use a slightly different command:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您的第二次迁移准备就绪，请继续应用它。这一次，您将使用略有不同的命令：
- en: '[PRE62]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: This command tells Knex to run every migration, starting with the migration
    following the current representation of the database, until the final migration.
    In this case, only a single migration is run, specifically the *create_groups*
    migration. In general, you’re likely to run this version of the `migrate` command
    the most frequently, such as whenever you pull from the master branch of a repository.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令告诉Knex运行每个迁移，从当前数据库表示的迁移后开始，直到最终迁移。在这种情况下，仅运行了一个迁移，具体为*create_groups*迁移。一般来说，您可能会频繁运行这个版本的`migrate`命令，例如每当您从仓库的主分支拉取时。
- en: Rolling Back a Migration
  id: totrans-382
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回滚迁移
- en: 'Sometimes an erroneous schema change will make its way into a migration file.
    Perhaps such a schema change is destructive and leads to data loss. Or perhaps
    a schema change adds support for a new feature that ends up getting dropped. In
    any case, such a migration change will need to be reversed. When this happens,
    you can run the following command to undo the last migration:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 有时错误的模式更改会出现在迁移文件中。也许这样的模式更改是破坏性的，并导致数据丢失。或者可能是模式更改添加了对一个新功能的支持，最终这个功能被放弃了。无论如何，这样的迁移更改都需要被撤销。当这种情况发生时，你可以运行以下命令来撤销最后一个迁移：
- en: '[PRE63]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'In my case, when I run this locally, I get the following output:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的情况下，当我在本地运行此命令时，我得到以下输出：
- en: '[PRE64]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: Once this command has been run, the second migration will be rolled back, but
    the first migration will still be present. In this case, the SQL statements in
    the `down()` method of the *create_groups* migration have been executed. Feel
    free to run the **`knex migrate:list`** command at this point if you don’t believe
    me.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦这个命令被运行，第二个迁移将被回滚，但第一个迁移仍然存在。在这种情况下，在*create_groups*迁移的`down()`方法中的SQL语句已经被执行。如果你不相信，请随时运行**`knex
    migrate:list`**命令。
- en: 'There’s no way that Knex can enforce that a down migration will completely
    undo the changes made by an up migration. That is ultimately up to the engineer
    to do. Unfortunately some operations just don’t have a correlating undo. As an
    example of this, imagine the following up and down migrations:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: Knex无法强制要求降级迁移完全撤销升级迁移所做的更改。这最终取决于工程师。不幸的是，有些操作确实没有相应的撤销方法。例如，想象一下以下的升级和降级迁移：
- en: '[PRE65]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: In this case, the up migration drops the *username* column, and the down migration
    adds the *username* column back. But the data that existed in the column has now
    been destroyed, and no amount of reverse migrations is going to get it back, either.
    What’s more, assuming there’s at least one user in the table, the down migration
    will fail because the unique constraint won’t be met—every username will be set
    to a null value!
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，升级迁移会删除*username*列，而降级迁移则会重新添加*username*列。但现在该列中存在的数据已经被破坏，没有任何逆向迁移也无法找回它。更重要的是，假设表中至少有一个用户，降级迁移将失败，因为唯一约束条件无法满足——每个用户名都将被设置为null值！
- en: One way these issues are sometimes discovered is after a code commit has been
    merged. For example, maybe a bad migration was merged and then run against the
    staging environment. At this point, all of the user accounts in the staging database
    have been corrupted and might need to be repaired. Some organizations copy production
    data into staging as part of a nightly task while anonymizing user data. In this
    case, the data will eventually be repaired in staging. Such safeguards aren’t
    always present for production.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 这些问题有时是在代码提交合并后才被发现的。例如，也许一个糟糕的迁移被合并然后在测试环境中运行了。此时，测试数据库中的所有用户账户都已损坏，可能需要修复。一些组织会在每晚的任务中将生产数据复制到测试环境，并对用户数据进行匿名化。在这种情况下，数据最终将在测试环境中得到修复。但并非所有的生产环境都有这样的保护措施。
- en: In these situations, the migration should never be run in production. The way
    Knex works is that it runs each migration serially until the most recent is run.
    One way to fix these situations is to run the appropriate migrate down commands
    anywhere the database has been affected (in this case, the staging environment
    and the developer’s local environment). Next, delete the erroneous migration file
    entirely. This can probably be done in a single revert commit.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情况下，迁移不应该在生产环境中运行。Knex的工作方式是，它将每个迁移依次运行，直到最近的被运行。解决这些问题的一种方法是在数据库受到影响的地方（在这种情况下是测试环境和开发者的本地环境）运行适当的迁移下撤销命令。接下来，完全删除错误的迁移文件。这可能可以在单个回滚提交中完成。
- en: Later, when a future migration is run against the production database, the destructive
    migration won’t be present at all, and the data loss should be avoided.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 后来，当未来的迁移在生产数据库上运行时，破坏性迁移将完全不存在，数据损失应该可以避免。
- en: Live Migrations
  id: totrans-394
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实时迁移
- en: It’s nearly impossible to time a database migration to happen at the exact moment
    that application code changes are deployed. The timing difference between these
    two operations is further complicated by migrations that take a long time to complete,
    like when a database table contains many rows that need to be backfilled, as well
    as due to the need to run multiple service instances, particularly when old and
    new versions overlap during deployment.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎不可能精确计时数据库迁移，使其恰好在应用程序代码更改部署时发生。 这两个操作之间的时间差异进一步复杂化，尤其是在需要运行多个服务实例时，旧版本和新版本在部署期间重叠时，以及当数据库表包含需要回填的大量行时的迁移。
- en: This difference in timing can lead to an application deployment that is momentarily
    broken. [Figure 8-2](#fig_migration_broken) shows how such a situation can occur.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 这种时间差异可能导致应用程序部署瞬间中断。 [图 8-2](#fig_migration_broken) 显示了这种情况的发生方式。
- en: '![First, the database and application are compatible. Next, a database migration
    makes them incompatible. Finally, a deployment makes them compatible again.](assets/dsnj_0802.png)'
  id: totrans-397
  prefs: []
  type: TYPE_IMG
  zh: '![首先，数据库和应用程序兼容。 接下来，数据库迁移使它们不兼容。 最后，部署使它们再次兼容。](assets/dsnj_0802.png)'
- en: Figure 8-2\. Broken migration timeline
  id: totrans-398
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-2\. 中断迁移时间轴
- en: In this case, the application is running just fine at 15:00\. At 15:01, a migration
    is applied, and the application code has become incompatible with the database
    schema. The application is currently broken. Next, a code deployment happens at
    15:02\. Once that happens, the application and schema are now compatible again.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，应用程序在15:00正常运行。 在15:01，应用了一次迁移，应用程序代码与数据库模式不兼容。 应用程序目前处于中断状态。 接下来，在15:02进行代码部署。
    一旦这样做，应用程序和模式现在再次兼容。
- en: One way to mitigate this incompatibility is to put an application in “maintenance
    mode.” In this mode, requests from users are blocked before they can reach the
    application. One way to do this is to configure a reverse proxy to serve a static
    maintenance page, deploy application code and apply database migrations, and then
    disable the maintenance page. If your application is only used during certain
    times of the day and by users in a limited geographical region, then performing
    such a migration during off-hours might be acceptable. But if you receive traffic
    during all hours, then such an approach is going to result in a poor user experience.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 缓解这种不兼容性的一种方法是将应用程序置于“维护模式”。 在这种模式下，用户的请求在到达应用程序之前被阻塞。 一种做法是配置反向代理以提供静态维护页面，部署应用程序代码并应用数据库迁移，然后禁用维护页面。
    如果您的应用程序仅在一天中的某些时间段内使用，并且仅由有限地理区域的用户使用，则在非工作时间进行这种迁移可能是可以接受的。 但是，如果您在全天都有流量，则这种方法将导致用户体验不佳。
- en: A *live migration* is a migration that happens in a way that doesn’t cause the
    application to go offline. Simple operations, such as adding a new optional database
    column, can take place using a single commit. This commit can contain the migration
    to add the column and the code change to read and write to the column, provided
    the migration is run first. More complex migrations, however, take multiple commits,
    each with different combinations of code changes and migration changes, in order
    to prevent a breaking change from happening.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: '*实时迁移* 是一种不会导致应用程序离线的迁移方式。 简单操作，如添加一个新的可选数据库列，可以通过单个提交进行。 该提交可以包含用于添加列和读写该列的代码更改，前提是先运行迁移。
    然而，更复杂的迁移则需要多个提交，每个提交都包含不同的代码更改和迁移更改的组合，以防止发生破坏性变更。'
- en: Live migration scenario
  id: totrans-402
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实时迁移场景
- en: 'As an example of this, pretend that you have the following database table being
    used by your application:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 举例来说，假设您的应用程序正在使用以下数据库表：
- en: '[PRE66]'
  id: totrans-404
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'And the corresponding application code to interact with this table looks like
    this:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 与这个表交互的相应应用程序代码如下：
- en: '[PRE67]'
  id: totrans-406
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: However, one day your company realizes that there are users with names that
    don’t match the first name and last name pattern and that it’s really just better
    for everyone involved to keep track of a single name entry.^([7](ch08.html#idm46291176335720))
    In this situation, you’d like to replace the existing `fname` and `lname` columns
    with a `name` column. You’d also like to copy the existing name columns for use
    with the new name column, all without causing the application to go down.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有一天你的公司意识到存在用户的名字不符合名字和姓氏的模式，对于所有相关人员来说，保持单个名称条目更好。^([7](ch08.html#idm46291176335720))
    在这种情况下，你希望用一个`name`列替换现有的`fname`和`lname`列。你还希望复制现有的名称列以供新名称列使用，而且一切操作不能导致应用程序停机。
- en: This is the perfect scenario for a multistage live migration. In this case,
    the transition from the old schema to the new schema can be represented using
    three commits.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 这是多阶段在线迁移的完美场景。在这种情况下，从旧模式到新模式的过渡可以用三个提交来表示。
- en: 'Commit A: Beginning the transition'
  id: totrans-409
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提交 A：开始过渡
- en: For this first step, you’re going to add the new `name` column and configure
    the application to write to the new column but read from either the old `fname`
    and `lname` columns *or* the new `name` column, whichever has data.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这第一步，你将添加新的`name`列，并配置应用程序将数据写入新列，但从旧的`fname`和`lname`列或新的`name`列中读取数据，无论哪个有数据。
- en: A few migration queries need to be run for this to work. For one thing, the
    new `name` column needs to be added. Even though it will eventually need the same
    `NOT NULL` constraint used by the existing name columns, you can’t add that constraint
    just yet. This is because the columns will start off having no data, and the unmet
    constraint would cause the `ALTER` query to fail.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使这项工作生效，需要运行几个迁移查询。首先，需要添加新的`name`列。尽管最终需要与现有名称列相同的`NOT NULL`约束，但现在不能添加该约束。因为这些列最初将没有数据，并且未满足的约束将导致`ALTER`查询失败。
- en: Another change that needs to be made is that the previous `NOT NULL` constraint
    on the name columns needs to be dropped. This is because newly added rows won’t
    contain data in the old columns.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 需要做的另一个更改是删除以前名称列上的`NOT NULL`约束。这是因为新添加的行不会包含旧列中的数据。
- en: 'Here’s what the migration `up()` queries look like:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是`up()`迁移查询的样子：
- en: '[PRE68]'
  id: totrans-414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: The code should then read from the new column, if present, or fall back to data
    stored in the old column, as well as write to the new `name` column. In this case,
    a `name` column with a null value means that the row has not yet transitioned
    to the new format. As part of this first commit, you’ll also need to refactor
    the application to use a single `name` property instead of the separate `fname`
    and `lname` properties.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，代码应该从新列中读取数据（如果有的话），或者退而求其次，从旧列中读取数据，同时写入新的`name`列。在这种情况下，`name`列的空值表示该行尚未过渡到新格式。作为第一次提交的一部分，你还需要重构应用程序，以使用单个`name`属性，而不是分开的`fname`和`lname`属性。
- en: 'The code changes look like this:'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 代码更改如下所示：
- en: '[PRE69]'
  id: totrans-417
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: At this point, you can combine the migration and the code change into a single
    version control commit. You will, however, need to apply the migration before
    the code changes are deployed. This is because the application code now expects
    the `name` column to be present, as seen in the `setUser()` function.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，你可以将迁移和代码更改合并到一个版本控制提交中。但是，在部署代码更改之前，你需要先应用迁移。这是因为应用程序代码现在期望`name`列是存在的，就像`setUser()`函数中所见。
- en: 'Commit B: Backfill'
  id: totrans-419
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提交 B：回填
- en: Now it’s time to *backfill* the `name` column in the database. A backfill is
    when data that is missing is retroactively provided. In this case, the `name`
    column needs to be set to a combination of the `fname` and `lname` fields.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是在数据库中*回填*`name`列的时候了。回填是指以前缺失的数据被追加进来的过程。在这种情况下，`name`列需要设置为`fname`和`lname`字段的组合。
- en: 'Such an operation can be represented using a single SQL query. In this example,
    the `up()` schema migration might run the following SQL command:'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的操作可以用单个SQL查询来表示。在这个例子中，`up()`模式迁移可能会运行以下SQL命令：
- en: '[PRE70]'
  id: totrans-422
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: If your database has a lot of data, then this query will take a long time and
    will result in many rows being locked. When this happens, certain interactions
    with the database will need to wait for the migration to finish. This effectively
    introduces downtime to your application, the very thing you were trying to avoid
    with a live migration!
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的数据库数据量很大，那么此查询将需要很长时间，并且将导致锁定许多行。当这种情况发生时，与数据库的某些交互将需要等待迁移完成。这实际上给您的应用程序引入了停机时间，而这正是您试图通过实时迁移避免的！
- en: 'To get around this, you may need to break the query up and run it against smaller
    sets of data in the database. For example, you could modify the query to affect
    chunks of 1,000 rows at a time by adding an additional clause to it:'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，您可能需要将查询分解，并针对数据库中较小的数据集运行它。例如，您可以通过添加附加子句，修改查询以每次影响1000行数据块：
- en: '[PRE71]'
  id: totrans-425
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: In this example, the migration is on the 103rd iteration of a loop.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，迁移正在进行第103次迭代的循环。
- en: Other backfill operations may require additional work. For example, if you have
    a column that contains a user’s GitHub numeric ID and you want to add a column
    that contains their GitHub username, then you would need a complex application
    to loop through every record in the database, make a GitHub API request, and then
    write the data back. Such a backfill could take days to run.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 其他回填操作可能需要额外的工作。例如，如果您有一个包含用户GitHub数字ID的列，并且想要添加一个包含他们GitHub用户名的列，那么您需要一个复杂的应用程序来遍历数据库中的每条记录，进行GitHub
    API请求，然后写回数据。这样的回填可能需要几天的时间才能完成。
- en: No application code changes are needed to accompany this commit, so your application
    shouldn’t require a deployment.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 不需要更改应用程序代码以配合此提交，因此您的应用程序不应该需要进行部署。
- en: 'Commit C: Finishing the transition'
  id: totrans-429
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提交C：完成过渡
- en: Finally, you’re ready to add the constraints to the new column and to drop the
    old columns. The application code can also be modified to only look at the new
    column and to disregard the previous names.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您可以添加新列的约束并删除旧列。还可以修改应用程序代码，只查看新列并忽略先前的名称。
- en: 'The `up()` migration to complete this process will involve the following queries:'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: '`up()`迁移以完成此过程将涉及以下查询：'
- en: '[PRE72]'
  id: totrans-432
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Within this same commit, you can also finish the transition of the `getUser()`
    method to no longer contain the fallback for the now-missing `fname` and `lname`
    columns:'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一个提交中，您还可以完成将`getUser()`方法转换为不再包含现在已丢失的`fname`和`lname`列的后备操作：
- en: '[PRE73]'
  id: totrans-434
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: The `setUser()` method in this case doesn’t need any changes since it’s already
    writing to the new column. The migration can run either before or after the deployment
    in this case.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，`setUser()`方法不需要任何更改，因为它已经写入新列。在这种情况下，迁移可以在部署之前或之后运行。
- en: The timeline for this multistage live migration now resembles [Figure 8-3](#fig_migration_fixed).
    While it’s certainly more complex than before, it does lead to a situation where
    the application is always compatible with the database.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 这个多阶段实时迁移的时间线现在类似于[图8-3](#fig_migration_fixed)。虽然比以前复杂得多，但确实导致应用程序始终与数据库兼容。
- en: '![The application is now always compatible with the database.](assets/dsnj_0803.png)'
  id: totrans-437
  prefs: []
  type: TYPE_IMG
  zh: '![应用程序现在始终与数据库兼容。](assets/dsnj_0803.png)'
- en: Figure 8-3\. Working migration timeline
  id: totrans-438
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-3\. 工作迁移时间线
- en: In this case, the application is running just fine at 15:00\. At 15:01 the first
    migration is run. The application is still compatible with the schema since there’s
    just a new column being added that the application is ignoring. Next, around 15:02,
    deployment A happens. The application is still compatible with the schema, and
    it’s now writing to the new column and reading from all columns. At 15:03 migration
    B happens and data gets backfilled. The code is still compatible and encounters
    rows that either have a `name` column with data or an empty `name` column. Around
    15:04 another deployment happens where the code is only reading from the new `name`
    column. Finally, around 15:05, the final schema migration happens.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，应用程序在15:00运行正常。在15:01时运行第一个迁移。由于只是添加了应用程序忽略的新列，应用程序仍然与模式兼容。接下来，在15:02左右，发生了A部署。应用程序仍然与模式兼容，现在正在向新列写入数据并从所有列读取数据。在15:03进行迁移B并进行数据回填。代码仍然兼容，并且遇到具有数据的`name`列或空的`name`列的行。大约在15:04进行另一个部署，代码只从新的`name`列中读取。最后，在15:05左右，进行最终的模式迁移。
- en: This is just an example of one form of live migration. As you perform other
    mutations to your database, you’ll need to change the steps and the queries involved.
    One rule of thumb is to always test migrations locally or in a staging environment
    before performing them in production. Test suites often aren’t designed with schema
    mutations in mind, and it can be difficult to spot migration failures.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是一种实时迁移的示例。当您对数据库执行其他变更时，您需要修改涉及的步骤和查询。一个经验法则是在生产环境执行迁移之前始终在本地或分段环境中进行测试。测试套件通常并未考虑架构变更，因此很难发现迁移失败。
- en: Idempotency and Messaging Resilience
  id: totrans-441
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 幂等性和消息弹性
- en: Clients need to know the outcome of a write operation carried out by a server;
    there’s a reason why they requested the write to happen, after all. For example,
    if a web server that a user is interacting with sends a message to an account
    server to make a purchase, then the web server will need to provide the result
    of the operation to the user agent. If the purchase fails, then the user may want
    to try again, or they may want to purchase something else. If it succeeds, then
    the user will expect to have less money in their account. But what does the web
    server do if it doesn’t know the result of the account server’s write operation?
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端需要知道服务器执行的写操作结果；毕竟，他们请求执行写操作是有原因的。例如，如果用户正在与之交互的 Web 服务器发送消息到帐户服务器以进行购买，则
    Web 服务器需要向用户代理提供操作结果。如果购买失败，那么用户可能希望再试一次，或者他们可能想购买其他物品。如果成功，那么用户期望在其帐户中少有一些钱。但是，如果
    Web 服务器不知道帐户服务器的写操作结果，该怎么办呢？
- en: Distributed applications communicate by sending messages to one another over
    a network. Not only are applications unreliable—a Node.js server may throw while
    processing a request—but the very network over which they communicate is also
    unreliable. Generally there are two types of errors that need to be dealt with
    in these scenarios. The first has to do with the lower-level protocol being used,
    such as an inability to communicate with a remote host via TCP. The second has
    to deal with whatever higher-level protocol is being used, like a 500 error via
    HTTP.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式应用程序通过网络相互发送消息进行通信。应用程序不仅不可靠——Node.js 服务器在处理请求时可能会抛出异常——它们通信的网络本身也不可靠。通常在这些情况下需要处理两种类型的错误。第一种与使用的底层协议有关，例如无法通过
    TCP 与远程主机通信。第二种与使用的更高级别协议有关，例如通过 HTTP 发生的 500 错误。
- en: High-level errors are usually easier to deal with. When an operation fails,
    the server provides information to the client about that failure over HTTP. The
    client can then use this information to make an informed decision. For example,
    a 404 response means that the resource being acted upon does not exist. Depending
    on the work being performed by the client, this might not be a big deal, like
    if a client is polling to see if a resource has been created yet, or it might
    be a huge deal, like if someone is checking to see if they’re still employed.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 处理高级错误通常更容易。操作失败时，服务器通过 HTTP 向客户端提供有关该失败的信息。然后客户端可以使用这些信息做出明智的决定。例如，404 响应意味着正在操作的资源不存在。根据客户端执行的工作，这可能不是什么大问题，例如，如果客户端正在轮询以查看资源是否已创建，或者这可能是一个很大的问题，例如，如果有人正在检查自己是否仍在职。
- en: Low-level errors require more work. These errors usually involve a communication
    breakdown, and it’s not always possible to know if the server received the message
    or not. If it did receive the message, it’s not possible to tell if the server
    processed the message or not. [Figure 8-4](#fig_protocol_errors) shows how these
    different scenarios play out.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 低级错误需要更多工作。这些错误通常涉及通信中断，而且无法总是知道服务器是否收到消息。如果确实收到消息，也无法确定服务器是否处理了消息。[图 8-4](#fig_protocol_errors)展示了这些不同情景的处理方式。
- en: '![A high-level protocol error happens when a client and server communicate.
    A low level protocol happens when the request or response is lost. It''s impossible
    to tell if a server received the message in these situations.](assets/dsnj_0804.png)'
  id: totrans-446
  prefs: []
  type: TYPE_IMG
  zh: '![客户端和服务器通信时会发生高级协议错误。请求或响应丢失时会发生低级协议错误。在这些情况下，无法确定服务器是否接收到消息。](assets/dsnj_0804.png)'
- en: Figure 8-4\. Protocol errors
  id: totrans-447
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-4\. 协议错误
- en: In the first example, a high-level error has occurred. In this case, the request/response
    lifecycle successfully completed and the high-level HTTP protocol error was communicated
    to the client. In the second example, the server did receive and process the request
    (like making a database change), but the client didn’t receive a response. In
    the third example, the server neither received nor processed the request. In this
    case, the client can’t necessarily distinguish between the second and third scenarios.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一个示例中，发生了高级别的错误。在这种情况下，请求/响应生命周期成功完成，并向客户端传达了高级别的 HTTP 协议错误。在第二个示例中，服务器确实接收并处理了请求（例如进行了数据库更改），但客户端没有收到响应。在第三个示例中，服务器既没有接收也没有处理请求。在这种情况下，客户端不能必然区分第二种和第三种情况。
- en: There is a finite number of [errors](https://nodejs.org/api/errors.html) that
    are surfaced to application code from the underlying Node.js network APIs. These
    errors are applicable regardless of which higher-level protocol is used, such
    as HTTP or gRPC. [Table 8-3](#table_network_errors) contains a list of these errors
    and what they mean. These error codes are provided as an `Error#code` property
    and are exposed via error callbacks, event emitter error events, and promise rejections.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 从底层的 Node.js 网络 API 向应用程序代码提供了一系列有限的[错误](https://nodejs.org/api/errors.html)。这些错误适用于使用的高级协议，如
    HTTP 或 gRPC。[表 8-3](#table_network_errors) 包含了这些错误及其含义的列表。这些错误代码通过 `Error#code`
    属性提供，并通过错误回调、事件发射器错误事件和承诺拒绝进行公开。
- en: Table 8-3\. Node.js network errors
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8-3\. Node.js 网络错误
- en: '| Error | Context | Ambiguous | Meaning |'
  id: totrans-451
  prefs: []
  type: TYPE_TB
  zh: '| 错误 | 上下文 | 歧义 | 含义 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-452
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| `EACCES` | Server | N/A | Cannot listen on port due to permissions |'
  id: totrans-453
  prefs: []
  type: TYPE_TB
  zh: '| `EACCES` | 服务器 | 不适用 | 由于权限问题无法监听端口 |'
- en: '| `EADDRINUSE` | Server | N/A | Cannot listen on port since another process
    has it |'
  id: totrans-454
  prefs: []
  type: TYPE_TB
  zh: '| `EADDRINUSE` | 服务器 | 不适用 | 由于另一个进程已占用，无法监听端口 |'
- en: '| `ECONNREFUSED` | Client | No | Client unable to connect to server |'
  id: totrans-455
  prefs: []
  type: TYPE_TB
  zh: '| `ECONNREFUSED` | 客户端 | 否 | 客户端无法连接到服务器 |'
- en: '| `ENOTFOUND` | Client | No | DNS lookup for the server failed |'
  id: totrans-456
  prefs: []
  type: TYPE_TB
  zh: '| `ENOTFOUND` | 客户端 | 否 | 服务器的 DNS 查找失败 |'
- en: '| `ECONNRESET` | Client | Yes | Server closed connection with client |'
  id: totrans-457
  prefs: []
  type: TYPE_TB
  zh: '| `ECONNRESET` | 客户端 | 是 | 服务器关闭了与客户端的连接 |'
- en: '| `EPIPE` | Client | Yes | Connection to server has closed |'
  id: totrans-458
  prefs: []
  type: TYPE_TB
  zh: '| `EPIPE` | 客户端 | 是 | 与服务器的连接已关闭 |'
- en: '| `ETIMEDOUT` | Client | Yes | Server didn’t respond in time |'
  id: totrans-459
  prefs: []
  type: TYPE_TB
  zh: '| `ETIMEDOUT` | 客户端 | 是 | 服务器未及时响应 |'
- en: The first two errors, `EACCESS` and `EADDRINUSE`, usually happen early in the
    lifetime of a process when a server attempts to listen. `EACCESS` means that the
    user running the process doesn’t have permission to listen on a port and is often
    the case when a non-root user listens to a low port, meaning 1024 and below. `EADDRINUSE`
    happens when another process is already listening on the specified port and interface.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个错误，`EACCESS` 和 `EADDRINUSE`，通常在进程生命周期的早期发生，当服务器尝试进行监听时。`EACCESS` 表示运行进程的用户没有权限在端口上进行监听，通常是非
    root 用户尝试监听低端口（即 1024 及以下）时的情况。`EADDRINUSE` 则是在另一个进程已经在指定的端口和接口上进行监听时发生。
- en: The other errors are applicable to the client and message resiliency. `ECONNREFUSED`
    and `ENOTFOUND` happen early in the network connection process. They can precede
    every individual message, like an HTTP request made without a keep alive connection.
    Or they can happen early on during a long-lived connection like gRPC. Notably,
    these errors happen before a message is sent to the server, so when they’re surfaced,
    there isn’t ambiguity about whether or not the server received and processed the
    message.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 其他的错误适用于客户端和消息的弹性处理。`ECONNREFUSED` 和 `ENOTFOUND` 发生在网络连接过程的早期阶段。它们可以出现在每个单独的消息之前，例如没有保持活动连接的
    HTTP 请求。或者它们可以在长期连接的早期阶段，如 gRPC 中发生。值得注意的是，这些错误发生在消息发送到服务器之前，因此当它们被显示时，不会存在关于服务器是否接收并处理了消息的歧义。
- en: The final three errors can happen during the middle of a network conversation
    and come with message delivery ambiguity. They can happen before or after the
    server receives and processes a message, leading to the third situation in [Figure 8-4](#fig_protocol_errors).
    With these errors, it’s not possible to tell if a message was received.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 最后三个错误可能发生在网络会话中间，并且带有消息传递的歧义性。它们可以在服务器接收和处理消息之前或之后发生，导致 [Figure 8-4](#fig_protocol_errors)
    中第三种情况的发生。对于这些错误，不可能确定是否接收到了消息。
- en: Depending on the situation, and the properties of the message being sent, the
    client may attempt subsequent deliveries of the message.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 根据情况和消息发送的属性，客户端可以尝试后续交付消息。
- en: HTTP Retry Logic
  id: totrans-464
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: HTTP 重试逻辑
- en: '[“Request and Response with HTTP”](ch02.html#ch_protocols_sec_http) already
    covers some details about HTTP, but in this section, further consideration is
    given to resiliency of messages, in particular the conditions in which a request
    can be repeated. [Figure 8-5](#fig_http_retry_flowchart) contains a flowchart
    that you can follow when designing your own retry logic.'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: '[“HTTP 请求与响应”](ch02.html#ch_protocols_sec_http)已经涵盖了有关 HTTP 的一些细节，但在本节中，特别考虑了消息的弹性，尤其是可以重复请求的条件。[图 8-5](#fig_http_retry_flowchart)包含了一个流程图，您可以在设计自己的重试逻辑时参考。'
- en: '![A flowchart of HTTP retry logic](assets/dsnj_0805.png)'
  id: totrans-466
  prefs: []
  type: TYPE_IMG
  zh: '![一个 HTTP 重试逻辑的流程图](assets/dsnj_0805.png)'
- en: Figure 8-5\. HTTP retry flowchart
  id: totrans-467
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-5\. HTTP 重试流程图
- en: First, the low-level errors from [Table 8-3](#table_network_errors) still apply.
    If an HTTP request results in a network error of `ECONNREFUSED` or `ENOTFOUND`,
    then the client is free to attempt the request again. However, the network errors
    `ECONNRESET`, `EPIPE`, and `ETIMEDOUT`, as well as HTTP errors in the 5XX range,
    require some further consideration. If the request is considered idempotent, then
    it may be retried; otherwise, the request should be considered a failure at that
    point. If an HTTP 4XX error is received, then the message should also fail. And
    if no HTTP error is received, then the request was successfully sent and the process
    is complete.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，来自[表 8-3](#table_network_errors)的低级错误仍然适用。如果一个 HTTP 请求导致 `ECONNREFUSED` 或
    `ENOTFOUND` 的网络错误，那么客户端可以自由地尝试再次请求。然而，网络错误 `ECONNRESET`、`EPIPE` 以及 HTTP 的 5XX
    范围内的错误，需要进一步考虑。如果请求被视为幂等，那么可以重试；否则，在此时应该将请求视为失败。如果收到 HTTP 4XX 错误，则消息也应该失败。如果没有收到
    HTTP 错误，则请求成功发送，流程完成。
- en: '[Table 8-4](#table_idempotency) contains a list of the popular HTTP methods
    often supported by HTTP APIs, as well as details about the methods such as if
    they’re idempotent or potentially destructive.'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 8-4](#table_idempotency)包含经常由 HTTP API 支持的流行 HTTP 方法列表，以及这些方法的详细信息，例如它们是否幂等或可能具有破坏性。'
- en: Table 8-4\. HTTP method matrix
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8-4\. HTTP 方法矩阵
- en: '| Method | Idempotent | Destructive | Safe | 4XX | 5XX | Ambiguous | Purpose
    |'
  id: totrans-471
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 幂等性 | 破坏性 | 安全性 | 4XX | 5XX | 不明确 | 目的 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-472
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| `GET` | Yes | No | Yes | No Retry | Retry | Retry | Retrieve resource(s)
    |'
  id: totrans-473
  prefs: []
  type: TYPE_TB
  zh: '| `GET` | 是 | 否 | 是 | 不重试 | 重试 | 重试 | 检索资源 |'
- en: '| `POST` | No | No | No | No Retry | No Retry | No Retry | Create resource
    |'
  id: totrans-474
  prefs: []
  type: TYPE_TB
  zh: '| `POST` | 否 | 否 | 否 | 不重试 | 不重试 | 不重试 | 创建资源 |'
- en: '| `PUT` | Yes | Yes | No | No Retry | Retry | Retry | Create or modify resource
    |'
  id: totrans-475
  prefs: []
  type: TYPE_TB
  zh: '| `PUT` | 是 | 是 | 否 | 不重试 | 重试 | 重试 | 创建或修改资源 |'
- en: '| `PATCH` | No | Yes | No | No Retry | Retry | Retry | Modify resource |'
  id: totrans-476
  prefs: []
  type: TYPE_TB
  zh: '| `PATCH` | 否 | 是 | 否 | 不重试 | 重试 | 重试 | 修改资源 |'
- en: '| `DELETE` | Yes | Yes | No | No Retry | Retry | Retry | Remove resource |'
  id: totrans-477
  prefs: []
  type: TYPE_TB
  zh: '| `DELETE` | 是 | 是 | 否 | 不重试 | 重试 | 重试 | 移除资源 |'
- en: This table is based on many assumptions and requires that an HTTP API adheres
    to HTTP standards, like those defined in [RFC7231](https://tools.ietf.org/html/rfc7231).
    For example, a `GET` request shouldn’t modify any data (perhaps a write to a secondary
    system is made for tracking rate limits or analytics, but otherwise, the primary
    data store should not be affected). If the HTTP standards are violated by an API,
    then it’s no longer possible to make any assumptions about retry safety.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 此表基于许多假设，并要求 HTTP API 遵循 HTTP 标准，如[RFC7231](https://tools.ietf.org/html/rfc7231)中定义的那些标准。例如，`GET`
    请求不应修改任何数据（也许会对辅助系统进行写入，以跟踪速率限制或分析，但否则，主要数据存储不应受到影响）。如果 API 违反了 HTTP 标准，那么不能再对重试安全性做任何假设。
- en: A request can be repeated multiple times without side effect if it is idempotent.
    For example, if a client requests `DELETE /recipes/42`, then the record will be
    deleted. If this is repeated, then the record isn’t any more or less deleted.
    Even though the first request might succeed with a 200 status and future requests
    might fail with a 404 status, the request itself is still idempotent. This is
    based on the assumption that a URL represents a specific resource, and that other
    resources can’t reuse a URL.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个请求是幂等的，可以多次重复而不产生副作用。例如，如果客户端请求 `DELETE /recipes/42`，则记录将被删除。如果重复这个请求，记录不会被多次删除或少次删除。即使第一个请求可能以
    200 状态成功，后续请求可能以 404 状态失败，请求本身仍然是幂等的。这基于一个假设，即 URL 代表一个特定资源，并且其他资源不能复用该 URL。
- en: A message is destructive if it can lead to loss of data. For example, a `PUT`
    and a `PATCH` request may overwrite data that was recently set by another client’s
    request, and a `DELETE` will definitely destroy data. In these situations, a server
    may choose to implement the `ETag` and `If-Match` [HTTP headers](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/ETag)
    to provide additional semantics to avoid data clobbering. This is similar to the
    Memcached CAS concept mentioned in [“Introducing Memcached”](#ch_resilience_sec_memcached_subsec_intro).
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一条消息可能导致数据丢失，则称其为破坏性消息。例如，`PUT` 和 `PATCH` 请求可能会覆盖另一个客户端请求最近设置的数据，而 `DELETE`
    则肯定会销毁数据。在这些情况下，服务器可以选择实现 `ETag` 和 `If-Match` [HTTP 头部](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/ETag)，以提供额外的语义来避免数据覆盖。这类似于
    [“引入 Memcached”](#ch_resilience_sec_memcached_subsec_intro) 中提到的 Memcached CAS
    概念。
- en: A message is safe if it doesn’t modify resources. In this list, only the `GET`
    method is safe.
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一条消息不修改资源，则称其为安全消息。在这个列表中，只有 `GET` 方法是安全的。
- en: Any message that results in a 4XX HTTP error should not be retried. In this
    situation, the client has made some sort of mistake with the request (such as
    providing data of the wrong type). Re-attempting the same request should always
    result in failure.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 任何导致 4XX HTTP 错误的消息都不应重试。在这种情况下，客户端可能在请求中犯了一些错误（例如提供了错误类型的数据）。再次尝试相同的请求应始终失败。
- en: To further complicate things, depending on which specific 5XX error is encountered,
    the client may technically be able to assume that the server did receive the message
    but did not attempt to process it. For example, a 503 Service Unavailable error
    might mean that the server received the message but did not have a connection
    to a database. Perhaps you can get away with such assumptions when dealing with
    an internal service. However, when dealing with 5XX errors generally, especially
    ones from external services, it is safest to assume that the state of the server
    is unknown.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步复杂化的是，根据遇到的具体 5XX 错误，客户端可能在技术上可以假设服务器已收到消息，但未尝试处理它。例如，503 Service Unavailable
    错误可能意味着服务器已接收到消息，但未连接到数据库。也许在处理内部服务时，你可以得出这样的假设。然而，通常情况下，特别是来自外部服务的 5XX 错误，最安全的做法是假设服务器的状态是未知的。
- en: A mechanism that a server may choose to implement that makes every request idempotent
    is an *idempotency key*. An idempotency key is metadata that is provided by the
    client when making a request to a server. In the case of the [Stripe API](https://stripe.com/docs/api/idempotent_requests),
    clients may send a `Idempotency-Key` header, and with the [PayPal API](https://developer.paypal.com/docs/platforms/develop/idempotency/),
    clients can provide a `PayPal-Request-Id` header. When the server receives a request
    with this key, it first checks a cache for the presence of the key. If the entry
    is present in the cache, then the server immediately replies with the cached entry.
    If the entry is missing in the cache, the server carries out the request as usual
    and then writes the response to the cache and replies to the request. Entries
    in the cache can then be cleared out after a set amount of time (Stripe clears
    after 24 hours) since repeat requests after a long time are rare (retries should
    realistically happen over the course of minutes). Consider supporting idempotency
    keys in your API if the side effect of duplicated requests can be costly.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器可能选择实现的一种机制，使每个请求都具有幂等性，称为*幂等性键*。幂等性键是客户端在向服务器发出请求时提供的元数据。在 [Stripe API](https://stripe.com/docs/api/idempotent_requests)
    中，客户端可以发送 `Idempotency-Key` 头部；在 [PayPal API](https://developer.paypal.com/docs/platforms/develop/idempotency/)
    中，客户端可以提供 `PayPal-Request-Id` 头部。当服务器收到带有这个键的请求时，它首先检查缓存中是否存在该键的条目。如果缓存中存在条目，则服务器立即使用缓存条目回复。如果缓存中不存在条目，则服务器按常规执行请求，然后将响应写入缓存并回复请求。由于长时间后重复请求很少发生（重试应在几分钟内完成），因此可以在一定时间后清除缓存中的条目（Stripe
    在 24 小时后清除）。如果重复请求的副作用可能很昂贵，请考虑在你的 API 中支持幂等性键。
- en: Circuit Breaker Pattern
  id: totrans-485
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 断路器模式
- en: Sometimes, a message or two gets lost over the network. Other times, a service
    is just down. Try as it might, a client won’t be able to contact a fallen server.
    In these situations, it’s often better for a client to give up for a while. By
    giving up, the client is able to fail incoming requests quicker (if appropriate),
    less wasted requests will flood the network, and an overwhelmed server may be
    free to successfully respond to other incoming requests. This approach of not
    making outbound requests when a server is perceived to be down is called the *circuit
    breaker* pattern.
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，网络丢失了一两条消息。其他时候，服务真的是停机了。无论客户端如何尝试，都无法联系到失效的服务器。在这些情况下，客户端通常最好放弃一段时间。放弃后，客户端能够更快地失败传入的请求（如果适当的话），减少网络中的请求浪费，并且过载的服务器可能会成功地响应其他传入的请求。这种在服务器被认为是停机状态时不进行出站请求的方法称为*断路器模式*。
- en: Clients have many options to choose from for determining when a client is down.
    For example, they may choose to define a threshold before flipping the circuit
    breaker, such as if ten 500 errors are encountered within 60 seconds. Other approaches
    might involve checking the response time of a service, considering one to be down
    if it takes longer than 200 milliseconds to reply.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 客户在确定客户端是否处于停机状态时有许多选择。例如，他们可以选择在触发断路器之前定义阈值，比如在60秒内遇到十次500错误。其他方法可能涉及检查服务的响应时间，如果响应时间超过200毫秒，则认为服务已停机。
- en: Things get more tricky when it comes to differentiating services from one another.
    For example, when you worked with Kubernetes, you created a Service object that
    abstracted the individual service instances away from you. In that situation it’s
    impossible to differentiate a faulty service instance from a healthy service instance.
    Luckily, Kubernetes may handle the health checks and can clean up a service automatically.
    With other technologies, such as Consul by HashiCorp, it’s possible to build a
    system where applications maintain an in-memory list of host and port combinations
    representing service instances. In that situation it’s possible to apply a circuit
    breaker on an individual-instance basis.
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 在区分各种服务时情况会更加棘手。例如，在使用 Kubernetes 时，您创建了一个 Service 对象，将个别服务实例抽象化了。在这种情况下，无法区分故障的服务实例和健康的服务实例。幸运的是，Kubernetes
    可能会处理健康检查并可以自动清理服务。对于其他技术，例如 HashiCorp 的 Consul，可以构建一个系统，在该系统中应用程序维护一个维护服务实例的内存列表。在这种情况下，可以按个别实例应用断路器。
- en: When it comes to communicating with outside services, such as the GitHub API,
    you’ll probably never know which underlying service instance is responding to
    a request; you just know that “the GitHub API is down.” In these situations, you
    may need to circuit-break the entire third-party API. This can be done by keeping
    a failure counter in a fast, in-memory database like Redis. When the number of
    500 errors or `ECONNREFUSED` errors reaches a threshold, your services will then
    give up making requests and will instead fail immediately.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及与外部服务的通信，例如 GitHub API 时，您可能永远不会知道哪个底层服务实例在响应请求；您只知道“GitHub API 停机了”。在这些情况下，您可能需要对整个第三方
    API 进行断路处理。这可以通过在像 Redis 这样的快速内存数据库中保持故障计数器来完成。当500错误或`ECONNREFUSED`错误的数量达到阈值时，您的服务将放弃发出请求，而是立即失败。
- en: Exponential Backoff
  id: totrans-490
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 指数退避
- en: The naive approach for having a client retry a request to an external service
    is to simply have it make the request again as soon as the failure happens. Then,
    if that retry fails, make another one immediately. This approach may not help
    requests succeed and may also exacerbate the problem.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个客户端重试向外部服务发出请求的朴素方法，即在失败发生后立即再次发出请求。然后，如果重试失败，立即再次尝试。这种方法可能无法帮助请求成功，还可能加剧问题。
- en: '[Figure 8-6](#fig_no_exponential_backoff) contains an example of a client using
    immediate retries. In this diagram, service instance A crashes. All the while,
    a client is making requests to the service. Once the client starts receiving failures,
    it begins sending requests much more rapidly. When this happens the client ends
    up working harder than it should, and the network is flooded with wasteful requests.
    Even once the new service instance B does start, it still needs to go through
    a startup phase where it may continue to fail any requests that it receives. When
    this happens the service may work harder than it needs to in order to respond
    to requests.'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 8-6](#fig_no_exponential_backoff)展示了一个客户端使用即时重试的示例。在这个图示中，服务实例 A 崩溃了。与此同时，客户端正在向服务发出请求。一旦客户端开始收到失败响应，它就会开始更快地发送请求。这时客户端会比必要的工作更加努力，网络会被无用的请求淹没。即使新的服务实例
    B 启动后，它仍然需要经历一个启动阶段，可能会继续拒绝任何接收到的请求。在这种情况下，服务可能会比必要的更加努力来响应请求。'
- en: '![Without exponential backoff, a client will barrage a server with requests](assets/dsnj_0806.png)'
  id: totrans-493
  prefs: []
  type: TYPE_IMG
  zh: '![没有指数回退，客户端会用请求轰炸服务器](assets/dsnj_0806.png)'
- en: Figure 8-6\. Without exponential backoff
  id: totrans-494
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-6\. 没有指数回退
- en: When you worked with Kubernetes, you might have noticed that a common theme
    within the cluster is that it takes time for applications to reach a desired state.
    For one reason, it takes time for an application to start and for it to establish
    connections to external services such as databases. Another reason is that it
    takes time for Kubernetes to notice that a health check is failing and to restart
    a service. Because such deployments and restarts take time, request re-attempts
    should also take time.
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 当你使用 Kubernetes 时，你可能会注意到集群中一个常见的主题是应用程序达到所需状态需要时间。一个原因是应用程序启动和建立到数据库等外部服务的连接需要时间。另一个原因是
    Kubernetes 需要时间来注意到健康检查失败并重新启动服务。因为这些部署和重新启动需要时间，请求的重试也应该花费一些时间。
- en: Often, when there’s a problem communicating with a service, it might just be
    a temporary blip. For example, a single network message might be dropped within
    the span of 1ms. Other times, the service might be down for a longer amount of
    time. For example, it might have lost a connection to the database and will need
    to re-establish a new connection, taking a second or two. Still, in other situations,
    the amount of time it takes for the server to come back is even longer, like when
    a health check fails and an instance is rebooted, taking up to a minute. Finally,
    sometimes a service can be down for hours, like when a DNS misconfiguration is
    deployed and an engineer needs to manually roll back.
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，当与服务通信出现问题时，可能只是暂时性问题。例如，一个网络消息可能在 1 毫秒内丢失。其他时候，服务可能会长时间处于停机状态。例如，它可能已经丢失了与数据库的连接，需要重新建立连接，需要一两秒钟的时间。还有时候，服务器恢复的时间更长，例如当健康检查失败并重新启动实例时，可能需要长达一分钟。最后，有时服务可能会长达数小时处于停机状态，例如当部署了
    DNS 配置错误并需要工程师手动回滚时。
- en: 'Because of this wide range of time that a service might be down, and the cost
    incurred by making failed requests, a different approach needs to be taken for
    retrying requests. Currently, the industry standard is called an *exponential
    backoff*. With this approach, the client starts by making retry attempts quickly
    but then slows down over time. For example, a service might choose to make request
    retries using the following schedule:'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 由于服务可能会长时间处于停机状态，以及由于失败请求而产生的成本，需要采用一种不同的重试请求方法。目前，行业标准称为*指数回退*。使用这种方法，客户端开始时会快速进行重试尝试，然后随着时间的推移减慢速度。例如，一个服务可能选择以下的请求重试时间表：
- en: '[PRE74]'
  id: totrans-498
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: In this case, the first retry happens in 100 milliseconds, the second at 250
    milliseconds, and so on, until it reaches 5 seconds, at which point it continues
    to retry at a rate of once every 5 seconds. Of course, this approach isn’t exactly
    exponential. It is, however, easy to reason about, being rounded to values familiar
    to humans. Once the application gets to the point where it’s making requests every
    5 seconds, it’s very unlikely to overwhelm any service.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，第一次重试在 100 毫秒后进行，第二次在 250 毫秒后进行，依此类推，直到达到 5 秒，此后每隔 5 秒重试一次。当然，这种方法并不完全是指数的。但这种方法易于理解，因为它使用了人类熟悉的值进行四舍五入。一旦应用程序达到每
    5 秒发起一次请求的阶段，它几乎不太可能会超载任何服务。
- en: 'This approach can be used with the `ioredis` package that you previously worked
    with. The `ioredis` package has retry support built into the package. Here’s an
    example of how to adapt this connection retry schedule:'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法可以与之前使用过的 `ioredis` 包一起使用。`ioredis` 包内置了重试支持。以下是如何调整此连接重试计划的示例：
- en: '[PRE75]'
  id: totrans-501
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: In this case, the `retrySchedule()` method accepts an argument, which is the
    current reattempt number. The method then returns a value, which is the amount
    of time to wait before reconnecting in milliseconds. The function itself tries
    to grab a value from the retry schedule, falling back to a default value if missing
    in the schedule.
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，`retrySchedule()` 方法接受一个参数，即当前的重新尝试次数。然后该方法返回一个值，即重新连接前等待的毫秒数。该函数本身尝试从重试计划中获取一个值，如果在计划中找不到则返回默认值。
- en: 'Depending on the operation, it may make sense to choose a different retry schedule.
    For example, for a service that depends on a database connection to function,
    this schedule might be fine. Once the application reaches the five second mark,
    it will continue to try to reconnect to the database forever. However, for other
    requests, like an HTTP request to an upstream service made as part of an incoming
    request from a downstream service, it wouldn’t be helpful to keep the incoming
    request open for too long. In that case, it might make sense to have a finite
    schedule containing three retries. When performance is more important, it also
    makes sense that the retries fire much quicker. For example, an HTTP retry schedule
    might look more like this:'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 根据操作的不同，选择不同的重试计划可能是有意义的。例如，对于一个依赖数据库连接的服务来说，这种计划可能是合适的。一旦应用程序达到五秒的标记，它将继续尝试无限期地重新连接到数据库。然而，对于其他请求，例如从下游服务收到的入站请求中作为上游服务的HTTP请求，保持入站请求打开时间过长并不有益。在这种情况下，使用包含三次重试的有限计划可能是有意义的。在性能更重要时，重试应更快地触发。例如，HTTP
    重试计划可能更像这样：
- en: '[PRE76]'
  id: totrans-504
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: While exponential backoff seems like a great solution to the retry problem,
    it can cause some other problems when used with internal services. For example,
    say that there is a fleet of 10 clients communicating with a single server. Each
    of the clients sends the server a steady stream of requests. Then, the service
    dies for several seconds before being started again. When this happens, each of
    the clients will probably notice that the service is down at the same time. They’ll
    then start re-attempting requests to the server with the exponential backoff schedule.
    But this means that each of the clients is now making requests at the same time.
    When the server finally does come back up, it will receive a barrage of requests
    all at the same time! This may cause the server to receive waves of traffic, where
    the server is doing no work for some periods of time and overwhelmed at other
    periods of time. This is a phenomenon known as the *thundering herd*. [Figure 8-7](#fig_thundering_herd)
    shows an example of this happening.
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管指数回退看起来是解决重试问题的好方法，但在与内部服务一起使用时可能会引发一些其他问题。例如，假设有一组 10 个客户端与单个服务器通信。每个客户端向服务器发送稳定的请求流。然后，服务在几秒钟内死机，然后重新启动。当这种情况发生时，每个客户端可能会同时注意到服务已经关闭。然后，它们将根据指数回退计划重新尝试向服务器发送请求。但这意味着每个客户端现在都在同时发出请求。当服务器最终重新启动时，它将同时接收一波波的请求！这可能导致服务器在某些时段不工作并在其他时段不堪重负。这种现象被称为*集中请求现象*。[图
    8-7](#fig_thundering_herd) 展示了这种情况的示例。
- en: '![Multiple clients will send waves of requests to a service when it comes back
    up](assets/dsnj_0807.png)'
  id: totrans-506
  prefs: []
  type: TYPE_IMG
  zh: '![多个客户端在服务恢复时会发送请求波浪](assets/dsnj_0807.png)'
- en: Figure 8-7\. Thundering herd
  id: totrans-507
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-7\. 集中请求现象
- en: To overcome this issue, you may want to introduce *jitter* to your applications.
    Jitter is random variance, such as an increase or decrease of request timing of
    ±10%. When this happens, some clients end up quicker and some end up slower. This
    helps spread out the message retries over time and may eventually reach a request
    rate that is evenly distributed across all clients.
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 要解决这个问题，您可能希望在应用程序中引入*jitter*。抖动是随机变化，例如请求时间增加或减少±10%。当这种情况发生时，一些客户端可能会更快地完成请求，而另一些则可能更慢。这有助于随时间分散消息重试，并最终达到一个在所有客户端上均匀分布的请求速率。
- en: 'Random jitter can be introduced to the previous example like so:'
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 随机抖动可以像下面这样引入到前面的示例中：
- en: '[PRE77]'
  id: totrans-510
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: The concept of jitter is useful in other situations as well. For example, an
    application may need to buffer stats in memory and flush it to a database every
    minute. This can be pulled off by making a `setInterval(fn, 60_000)` call once
    when the application starts. However, the same thundering herd problem exists.
    Applications are often deployed in a fleet all at once. This can mean that when
    deploying 10 applications, 10 flushes will happen at the same time every minute,
    periodically overwhelming the database.
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 抖动的概念在其他情况下也很有用。例如，一个应用程序可能需要在内存中缓冲统计数据，并每分钟将其刷新到数据库。可以通过在应用程序启动时调用`setInterval(fn,
    60_000)`来实现。然而，同样存在雷霆兽问题。应用程序通常会同时部署在一组中。这意味着当部署 10 个应用程序时，每分钟会同时进行 10 次刷新，定期使数据库不堪重负。
- en: 'Instead, jitter can be calculated randomly on a per-process basis when the
    process starts, where the jitter value is a number between zero and the interval
    of time. For example, when calculating an interval for an operation happening
    every minute, you might write code that looks like this:'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，在进程启动时可以基于每个进程随机计算抖动，其中抖动值是介于零和时间间隔之间的数字。例如，当计算每分钟发生的操作的间隔时，可以编写如下代码：
- en: '[PRE78]'
  id: totrans-513
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'With this approach, instance A might get an offset of 17 seconds, instance
    B an offset of 42 seconds, and instance C an offset of 11 seconds. This would
    then result in a request schedule like the following:'
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种方法，实例 A 可能会得到 17 秒的偏移量，实例 B 得到 42 秒的偏移量，实例 C 得到 11 秒的偏移量。然后，请求时间表会如下所示：
- en: '[PRE79]'
  id: totrans-515
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'But without jitter, the request timeline would instead look like this:'
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 但是如果没有抖动，请求时间表将会像这样：
- en: '[PRE80]'
  id: totrans-517
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: Resilience Testing
  id: totrans-518
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 弹性测试
- en: As an engineer it’s far too easy to treat error scenarios as a second-class
    citizen. Engineers may only test the happy paths of an application, both when
    it comes to interacting with a new feature via a UI as well as writing unit tests.
    When only the successful uses of a feature are tested, an application is left
    wide open for failure when it’s no longer run on a developer’s laptop and is shipped
    to production. Failure in a distributed environment can be further compounded
    because an error in one application can lead to errors in other applications—usually
    without the original stack trace to debug with.
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 作为工程师，很容易将错误场景视为二等公民。工程师可能仅测试应用程序的正常路径，无论是通过 UI 与新功能交互，还是编写单元测试。当仅测试功能的成功使用时，一旦应用程序不再在开发者的笔记本上运行并且部署到生产环境时，应用程序容易出现故障。在分布式环境中，故障可能会进一步加剧，因为一个应用程序中的错误可能导致其他应用程序出错——通常没有原始的堆栈跟踪用于调试。
- en: One philosophy for enforcing that such errors are dealt with is called *chaos
    engineering*. This is an approach where failures are introduced randomly into
    an environment. By turning what are usually rare failures into an everyday occurrence,
    engineers are forced to deal with them sooner rather than later, lest they face
    the wrath of the midnight pager. This approach to testing failures is something
    that you may consider using within your organization, though it requires a very
    disciplined collection of developers to achieve.
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 一个用于确保处理此类错误的哲学称为*混沌工程*。这是一种方法，通过在环境中随机引入故障，将通常是罕见的故障变成日常事件。工程师被迫尽早处理这些问题，以免在半夜的报警声中受苦。这种对故障进行测试的方法是您可能考虑在组织内使用的一种方法，尽管它需要一支非常纪律严明的开发团队才能实现。
- en: The first thing you’ll need to consider when introducing chaos into an organization
    is in which environments the chaos should be enabled. While introducing chaos
    to production may be the ultimate test of a system’s ability to be resilient to
    failure, starting with the staging environment is going to be much easier to get
    management buy-in.
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 在引入混沌到组织中时，首先需要考虑在哪些环境中启用混沌。虽然在生产环境引入混沌可能是测试系统抵御故障能力的最终测试，但从演练环境开始会更容易获得管理层的支持。
- en: Another thing that needs to be considered is what types of chaos should be introduced
    into a system. When it comes to planning, it’s important to consider realistic
    failure situations within a real-world application. Here are some examples of
    the types of chaos that can be introduced into a Node.js application based on
    some of the common failure boundaries I’ve encountered within the applications
    I’ve worked on.
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要考虑的事情是应该向系统引入什么类型的混乱。在规划时，考虑到真实世界应用程序中的实际故障情况非常重要。以下是一些关于基于我在工作中遇到的应用程序中一些常见故障边界的Node.js应用程序中可以引入的混乱类型的示例。
- en: Random Crashes
  id: totrans-523
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 随机崩溃
- en: One of the themes that has been repeated throughout this book is that process
    instances will die. Because of this it’s important to keep state outside of the
    application instance. It’s also important that when a client gets a failure when
    communicating with a server, the client attempts to retry the request when appropriate.
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中反复出现的一个主题是进程实例会死亡。因此，重要的是将状态保持在应用程序实例外部。当客户端与服务器通信时遇到故障时，客户端重试请求是非常重要的。
- en: '[Example 8-14](#ex_chaos_crash) is an example of how you might introduce random
    crashes into an application.'
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 8-14](#ex_chaos_crash) 是如何在应用程序中引入随机崩溃的示例。'
- en: Example 8-14\. Random crash chaos
  id: totrans-526
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-14\. 随机崩溃混乱
- en: '[PRE81]'
  id: totrans-527
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: The first thing this example does is check what environment it’s running in.
    In this case, the chaos is only introduced if run within the staging environment.
    Next, a lifespan for the process is calculated. In this case, the number is calculated
    to be some time between 0 and 30 hours of time. Next, a function is scheduled
    to fire once that amount of time has been met. Once the timer fires, the application
    will exit. In this example, the exit status is set to 99, and a message is also
    printed to *stderr*. This is helpful for debugging the reason for a crash; without
    it, an engineer might waste a bunch of time trying to fix an application that
    crashed intentionally.
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例首先检查它正在运行的环境。在这种情况下，只有在测试环境中才会引入混乱。接下来，计算了进程的寿命。在这种情况下，计算出的数字是介于0和30小时之间的某个时间。然后，安排一个函数在达到该时间后触发。一旦计时器触发，应用程序将退出。在此示例中，退出状态设置为99，并且还打印了一条消息到*stderr*。这对于调试崩溃的原因非常有帮助；如果没有它，工程师可能会浪费大量时间试图修复有意崩溃的应用程序。
- en: Assuming your application is being run in an environment where some sort of
    supervisor is keeping an eye on it (such as Kubernetes), the process should be
    restarted once it crashes. Once it crashes, there will be a period of time when
    requests made to the service will fail. It’s now up to the client in those situations
    to implement retry logic. Consider tweaking the amount of time between crashes
    depending on your environment; maybe it should crash every two minutes on a development
    laptop, every few hours in staging, and once a week in production.
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你的应用程序正在由某种监管程序（如Kubernetes）监视的环境中运行，一旦崩溃，应该重新启动进程。一旦崩溃，服务收到的请求将会失败一段时间。此时客户端需要在这些情况下实施重试逻辑。考虑根据你的环境调整崩溃之间的时间间隔；也许在开发笔记本上应该每两分钟崩溃一次，在测试环境中每几小时一次，在生产环境中每周一次。
- en: Event Loop Pauses
  id: totrans-530
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 事件循环暂停
- en: When the event loop in your JavaScript-based Node.js application pauses, the
    entire application comes to a standstill. During this time it is unable to process
    requests. Interesting race conditions with asynchronous timers can also sometimes
    appear when this happens. Assuming the process is incapable of responding to requests
    for long enough, it might even fail a health check and be considered for recycling.
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: 当你的基于JavaScript的Node.js应用程序中的事件循环暂停时，整个应用程序将停止运行。在此期间，它无法处理请求。有趣的是，当发生这种情况时，异步定时器可能会出现竞争条件。假设进程无法在足够长的时间内响应请求，甚至可能会失败健康检查并被考虑重新启动。
- en: '[Example 8-15](#ex_chaos_pause) demonstrates how to introduce random pauses
    to your application.'
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 8-15](#ex_chaos_pause) 展示了如何向你的应用程序引入随机暂停。'
- en: Example 8-15\. Random event loop pauses
  id: totrans-533
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-15\. 随机事件循环暂停
- en: '[PRE82]'
  id: totrans-534
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: In this case, the application runs a timer randomly between 0 and 100 seconds,
    randomly rescheduling to be run again until the process dies. When the timer fires,
    it performs a Fibonacci calculation for a million iterations. The Fibonacci calculation
    will take some amount of time depending on the version of the V8 engine being
    used and the speed of the CPU that the application is running on. Consider finding
    a number, or a random range of numbers, that will cause your application to freeze
    for multiple seconds.
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，应用程序随机运行一个计时器，时间介于0到100秒之间，随机重新安排运行，直到进程终止。当计时器触发时，它会执行一个一百万次迭代的斐波那契计算。斐波那契计算将根据使用的V8引擎版本和应用程序运行的CPU速度而需花费一定时间。请考虑查找一个数字，或者一个随机范围的数字，可以导致您的应用程序冻结多秒钟。
- en: Random Failed Async Operations
  id: totrans-536
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 随机失败的异步操作
- en: One of the most common failure scenarios is when asynchronous operations are
    made. Errors are fairly common when an HTTP request is made, a file is read, or
    a database is accessed. Unlike the previous two examples, which run globally,
    this example requires some slight modifications to application code. In this case,
    a new function is added at the boundary where the application communicates with
    the underlying library.
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的故障场景之一是进行异步操作时。在进行HTTP请求、读取文件或访问数据库时，错误是相当常见的。与前两个例子不同，这个例子需要对应用程序代码进行一些轻微的修改。在这种情况下，在应用程序与底层库通信的边界处添加了一个新函数。
- en: '[Example 8-16](#ex_chaos_async) shows how to introduce random failures to asynchronous
    calls in your application.'
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 8-16](#ex_chaos_async) 展示了如何在应用程序中引入对异步调用的随机失败。'
- en: Example 8-16\. Random async failures
  id: totrans-539
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例8-16\. 随机异步失败
- en: '[PRE83]'
  id: totrans-540
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: This particular example provides a new method, `chaosQuery()`, which can be
    used as a replacement for an existing package that exposes a `db.query()` method.
    In this example, approximately 1 out of every 10,000 database queries will result
    in an error. This simple asynchronous method wrapper can be applied in other situations
    as well, like when making HTTP calls with the `node-fetch` package.
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 此特定示例提供了一个新方法`chaosQuery()`，可以用作替代已暴露`db.query()`方法的现有包。在此示例中，大约每10,000个数据库查询中就会出现一个错误。这个简单的异步方法包装器也可以应用于其他情况，比如使用`node-fetch`包进行HTTP调用。
- en: ^([1](ch08.html#idm46291180517368-marker)) An exit status can also be set by
    assigning a code to `process.exitStatus` and then calling `process.exit()` without
    an argument.
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch08.html#idm46291180517368-marker)) 通过将代码分配给`process.exitStatus`，然后在没有参数的情况下调用`process.exit()`，也可以设置退出状态。
- en: ^([2](ch08.html#idm46291180506840-marker)) There’s also a `process.abort()`
    method available. Calling it immediately terminates the process, prints some memory
    locations, and writes a core dump file to disk if the OS is configured to do so.
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch08.html#idm46291180506840-marker)) 还有一个可用的`process.abort()`方法。调用它会立即终止进程，打印一些内存位置，并在操作系统配置为这样做时将核心转储文件写入磁盘。
- en: ^([3](ch08.html#idm46291180061896-marker)) The deprecated internal `domain`
    module provides a way to capture `error` events from many `EventEmitter` instances.
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch08.html#idm46291180061896-marker)) 废弃的内部`domain`模块提供了一种从许多`EventEmitter`实例捕获`error`事件的方法。
- en: ^([4](ch08.html#idm46291179692920-marker)) I reported this issue to the package
    author two years ago. Fingers crossed!
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch08.html#idm46291179692920-marker)) 我两年前向包作者报告了这个问题。祈祷！
- en: ^([5](ch08.html#idm46291179566392-marker)) Languages like Rust and C++ allow
    for extremely accurate memory calculations; with JavaScript, we can only work
    with approximations.
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch08.html#idm46291179566392-marker)) 像Rust和C++这样的语言允许进行极其精确的内存计算；而JavaScript只能使用近似值进行工作。
- en: ^([6](ch08.html#idm46291177027288-marker)) You can also avoid globally installing
    `knex` by prefixing each of the commands with `npx`, such as `npx knex init`.
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch08.html#idm46291177027288-marker)) 您还可以通过在每个命令前加上`npx`来避免全局安装`knex`，例如`npx
    knex init`。
- en: ^([7](ch08.html#idm46291176335720-marker)) Some systems think that my first
    name is “Thomas Hunter” and my last name is “II.”
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](ch08.html#idm46291176335720-marker)) 一些系统认为我的名字是“托马斯·亨特”，姓氏是“二世”。
